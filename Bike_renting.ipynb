{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.grid_search import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import randint as sp_randint\n",
    "from scipy.stats import uniform as sp_uniform\n",
    "from tensorflow.contrib import skflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data read successfully!\n"
     ]
    }
   ],
   "source": [
    "# Getting Dataset\n",
    "\n",
    "bike_data = pd.read_csv(\"day.csv\")\n",
    "\n",
    "print \"Data read successfully!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature column(s):\n",
      "Index([u'instant', u'dteday', u'season', u'yr', u'mnth', u'holiday',\n",
      "       u'weekday', u'workingday', u'weathersit', u'temp', u'atemp', u'hum',\n",
      "       u'windspeed'],\n",
      "      dtype='object')\n",
      "\n",
      "Target column:\n",
      "cnt\n"
     ]
    }
   ],
   "source": [
    "# Extracting\n",
    "\n",
    "feature_cols = bike_data.columns[:-3]  # all columns but last are features\n",
    "target_col = bike_data.columns[-1]  # last column is the target\n",
    "print \"Feature column(s):\\n{}\\n\".format(feature_cols)\n",
    "print \"Target column:\\n{}\".format(target_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Data values:\n",
      "   instant      dteday  season  yr  mnth  holiday  weekday  workingday  \\\n",
      "0        1  2011-01-01       1   0     1        0        6           0   \n",
      "1        2  2011-01-02       1   0     1        0        0           0   \n",
      "2        3  2011-01-03       1   0     1        0        1           1   \n",
      "3        4  2011-01-04       1   0     1        0        2           1   \n",
      "4        5  2011-01-05       1   0     1        0        3           1   \n",
      "\n",
      "   weathersit      temp     atemp       hum  windspeed  casual  registered  \\\n",
      "0           2  0.344167  0.363625  0.805833   0.160446     331         654   \n",
      "1           2  0.363478  0.353739  0.696087   0.248539     131         670   \n",
      "2           1  0.196364  0.189405  0.437273   0.248309     120        1229   \n",
      "3           1  0.200000  0.212122  0.590435   0.160296     108        1454   \n",
      "4           1  0.226957  0.229270  0.436957   0.186900      82        1518   \n",
      "\n",
      "    cnt  \n",
      "0   985  \n",
      "1   801  \n",
      "2  1349  \n",
      "3  1562  \n",
      "4  1600  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instant</th>\n",
       "      <th>season</th>\n",
       "      <th>yr</th>\n",
       "      <th>mnth</th>\n",
       "      <th>holiday</th>\n",
       "      <th>weekday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weathersit</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>casual</th>\n",
       "      <th>registered</th>\n",
       "      <th>cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>731.000000</td>\n",
       "      <td>731.000000</td>\n",
       "      <td>731.000000</td>\n",
       "      <td>731.000000</td>\n",
       "      <td>731.000000</td>\n",
       "      <td>731.000000</td>\n",
       "      <td>731.000000</td>\n",
       "      <td>731.000000</td>\n",
       "      <td>731.000000</td>\n",
       "      <td>731.000000</td>\n",
       "      <td>731.000000</td>\n",
       "      <td>731.000000</td>\n",
       "      <td>731.000000</td>\n",
       "      <td>731.000000</td>\n",
       "      <td>731.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>366.000000</td>\n",
       "      <td>2.496580</td>\n",
       "      <td>0.500684</td>\n",
       "      <td>6.519836</td>\n",
       "      <td>0.028728</td>\n",
       "      <td>2.997264</td>\n",
       "      <td>0.683995</td>\n",
       "      <td>1.395349</td>\n",
       "      <td>0.495385</td>\n",
       "      <td>0.474354</td>\n",
       "      <td>0.627894</td>\n",
       "      <td>0.190486</td>\n",
       "      <td>848.176471</td>\n",
       "      <td>3656.172367</td>\n",
       "      <td>4504.348837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>211.165812</td>\n",
       "      <td>1.110807</td>\n",
       "      <td>0.500342</td>\n",
       "      <td>3.451913</td>\n",
       "      <td>0.167155</td>\n",
       "      <td>2.004787</td>\n",
       "      <td>0.465233</td>\n",
       "      <td>0.544894</td>\n",
       "      <td>0.183051</td>\n",
       "      <td>0.162961</td>\n",
       "      <td>0.142429</td>\n",
       "      <td>0.077498</td>\n",
       "      <td>686.622488</td>\n",
       "      <td>1560.256377</td>\n",
       "      <td>1937.211452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.059130</td>\n",
       "      <td>0.079070</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022392</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>22.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>183.500000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.337083</td>\n",
       "      <td>0.337842</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.134950</td>\n",
       "      <td>315.500000</td>\n",
       "      <td>2497.000000</td>\n",
       "      <td>3152.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>366.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.498333</td>\n",
       "      <td>0.486733</td>\n",
       "      <td>0.626667</td>\n",
       "      <td>0.180975</td>\n",
       "      <td>713.000000</td>\n",
       "      <td>3662.000000</td>\n",
       "      <td>4548.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>548.500000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.655417</td>\n",
       "      <td>0.608602</td>\n",
       "      <td>0.730209</td>\n",
       "      <td>0.233214</td>\n",
       "      <td>1096.000000</td>\n",
       "      <td>4776.500000</td>\n",
       "      <td>5956.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>731.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.861667</td>\n",
       "      <td>0.840896</td>\n",
       "      <td>0.972500</td>\n",
       "      <td>0.507463</td>\n",
       "      <td>3410.000000</td>\n",
       "      <td>6946.000000</td>\n",
       "      <td>8714.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          instant      season          yr        mnth     holiday     weekday  \\\n",
       "count  731.000000  731.000000  731.000000  731.000000  731.000000  731.000000   \n",
       "mean   366.000000    2.496580    0.500684    6.519836    0.028728    2.997264   \n",
       "std    211.165812    1.110807    0.500342    3.451913    0.167155    2.004787   \n",
       "min      1.000000    1.000000    0.000000    1.000000    0.000000    0.000000   \n",
       "25%    183.500000    2.000000    0.000000    4.000000    0.000000    1.000000   \n",
       "50%    366.000000    3.000000    1.000000    7.000000    0.000000    3.000000   \n",
       "75%    548.500000    3.000000    1.000000   10.000000    0.000000    5.000000   \n",
       "max    731.000000    4.000000    1.000000   12.000000    1.000000    6.000000   \n",
       "\n",
       "       workingday  weathersit        temp       atemp         hum   windspeed  \\\n",
       "count  731.000000  731.000000  731.000000  731.000000  731.000000  731.000000   \n",
       "mean     0.683995    1.395349    0.495385    0.474354    0.627894    0.190486   \n",
       "std      0.465233    0.544894    0.183051    0.162961    0.142429    0.077498   \n",
       "min      0.000000    1.000000    0.059130    0.079070    0.000000    0.022392   \n",
       "25%      0.000000    1.000000    0.337083    0.337842    0.520000    0.134950   \n",
       "50%      1.000000    1.000000    0.498333    0.486733    0.626667    0.180975   \n",
       "75%      1.000000    2.000000    0.655417    0.608602    0.730209    0.233214   \n",
       "max      1.000000    3.000000    0.861667    0.840896    0.972500    0.507463   \n",
       "\n",
       "            casual   registered          cnt  \n",
       "count   731.000000   731.000000   731.000000  \n",
       "mean    848.176471  3656.172367  4504.348837  \n",
       "std     686.622488  1560.256377  1937.211452  \n",
       "min       2.000000    20.000000    22.000000  \n",
       "25%     315.500000  2497.000000  3152.000000  \n",
       "50%     713.000000  3662.000000  4548.000000  \n",
       "75%    1096.000000  4776.500000  5956.000000  \n",
       "max    3410.000000  6946.000000  8714.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exploration\n",
    "\n",
    "print \"\\n Data values:\"\n",
    "print bike_data.head()  # print the first 5 rows\n",
    "\n",
    "bike_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data is already normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Pre-processing\n",
    "\n",
    "X = bike_data[feature_cols.drop(['dteday'],['instant'])] # feature values \n",
    "y = bike_data[target_col]  # corresponding targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)# test size is set to 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Visulazation\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "plt.figure(1)\n",
    "      \n",
    "plt.plot(bike_data.cnt,'bo')\n",
    "\n",
    "plt.title('Number of bikes rented per day')\n",
    "plt.xlabel('days')\n",
    "plt.ylabel('Number of bikes')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# source: http://matplotlib.org/examples/showcase/bachelors_degrees_by_gender.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
       "  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training SVR\n",
    "\n",
    "svr = SVR()\n",
    "svr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score SVR: -0.005700\n"
     ]
    }
   ],
   "source": [
    "# Validation SVR\n",
    "\n",
    "svr_pred = svr.predict(X_test)\n",
    "\n",
    "# score_svr = mean_squared_error(y_test, svr_pred)\n",
    "score_svr = r2_score(y_test, svr_pred)\n",
    "\n",
    "print(\"Score SVR: %f\" % score_svr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV(cv=None, error_score='raise',\n",
      "       estimator=SVR(C=1, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
      "  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False),\n",
      "       fit_params={}, iid=True, n_jobs=1,\n",
      "       param_grid=[{'kernel': ['linear', 'rbf'], 'C': [0.0001, 0.001, 0.01]}],\n",
      "       pre_dispatch='2*n_jobs', refit=True, scoring='r2', verbose=0)\n",
      "\n",
      "Best parameter from grid search: {'kernel': 'linear', 'C': 0.001}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Tuning SVR\n",
    "\n",
    "tuned_parameters = [{'C': [0.0001, 0.001, 0.01], 'kernel': ['linear', 'rbf']}]\n",
    "\n",
    "#svr_tuned = GridSearchCV(SVR (C=1), param_grid = tuned_parameters, scoring = 'mean_squared_error') #default 3-fold cross-validation, score method of the estimator\n",
    "svr_tuned = GridSearchCV(SVR (C=1), param_grid = tuned_parameters, scoring = 'r2') #default 3-fold cross-validation, score method of the estimator\n",
    "\n",
    "svr_tuned.fit(X_train, y_train)\n",
    "\n",
    "print (svr_tuned)\n",
    "print ('\\n' \"Best parameter from grid search: \" + str(svr_tuned.best_params_) +'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score SVR tuned: 0.400572\n",
      "Score SVR: -0.005700\n"
     ]
    }
   ],
   "source": [
    "# Validation SVR tuned \n",
    "\n",
    "svr_tuned_pred = svr_tuned.predict(X_test)\n",
    "\n",
    "#score_svr_tuned = mean_squared_error(y_test, svr_tuned_pred)\n",
    "score_svr_tuned = r2_score(y_test, svr_tuned_pred)\n",
    "\n",
    "\n",
    "print(\"Score SVR tuned: %f\" % score_svr_tuned)\n",
    "print(\"Score SVR: %f\" % score_svr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step #99, avg. train loss: 3206671.00000\n",
      "Step #199, avg. train loss: 1737768.12500\n",
      "Step #299, avg. train loss: 2154542.00000\n",
      "Step #399, avg. train loss: 2722572.50000\n",
      "Step #499, avg. train loss: 1610008.12500\n",
      "Step #600, epoch #1, avg. train loss: 2673119.75000\n",
      "Step #700, epoch #1, avg. train loss: 2827053.00000\n",
      "Step #800, epoch #1, avg. train loss: 2676612.50000\n",
      "Step #900, epoch #1, avg. train loss: 2390319.25000\n",
      "Step #1000, epoch #1, avg. train loss: 1499091.37500\n",
      "Step #1100, epoch #2, avg. train loss: 1429564.12500\n",
      "Step #1200, epoch #2, avg. train loss: 1994841.75000\n",
      "Step #1300, epoch #2, avg. train loss: 2186806.00000\n",
      "Step #1400, epoch #2, avg. train loss: 1463334.12500\n",
      "Step #1500, epoch #2, avg. train loss: 2174727.75000\n",
      "Step #1600, epoch #2, avg. train loss: 2712177.00000\n",
      "Step #1700, epoch #3, avg. train loss: 1835243.25000\n",
      "Step #1800, epoch #3, avg. train loss: 1958615.25000\n",
      "Step #1900, epoch #3, avg. train loss: 2170248.50000\n",
      "Step #2000, epoch #3, avg. train loss: 2039713.50000\n",
      "Step #2100, epoch #3, avg. train loss: 1796987.50000\n",
      "Step #2200, epoch #4, avg. train loss: 2424065.00000\n",
      "Step #2300, epoch #4, avg. train loss: 2444860.25000\n",
      "Step #2400, epoch #4, avg. train loss: 1822141.87500\n",
      "Step #2500, epoch #4, avg. train loss: 2321233.50000\n",
      "Step #2600, epoch #4, avg. train loss: 1599029.00000\n",
      "Step #2700, epoch #4, avg. train loss: 1805553.62500\n",
      "Step #2800, epoch #5, avg. train loss: 2672316.00000\n",
      "Step #2900, epoch #5, avg. train loss: 1724171.00000\n",
      "Step #3000, epoch #5, avg. train loss: 2312135.25000\n",
      "Step #3100, epoch #5, avg. train loss: 1492805.25000\n",
      "Step #3200, epoch #5, avg. train loss: 1269330.75000\n",
      "Step #3300, epoch #6, avg. train loss: 2744942.50000\n",
      "Step #3400, epoch #6, avg. train loss: 2360591.00000\n",
      "Step #3500, epoch #6, avg. train loss: 2084088.37500\n",
      "Step #3600, epoch #6, avg. train loss: 1847798.25000\n",
      "Step #3700, epoch #6, avg. train loss: 1437702.12500\n",
      "Step #3800, epoch #6, avg. train loss: 1865979.00000\n",
      "Step #3900, epoch #7, avg. train loss: 2160117.50000\n",
      "Step #4000, epoch #7, avg. train loss: 2688196.25000\n",
      "Step #4100, epoch #7, avg. train loss: 1421879.00000\n",
      "Step #4200, epoch #7, avg. train loss: 1470191.87500\n",
      "Step #4300, epoch #7, avg. train loss: 1892023.37500\n",
      "Step #4400, epoch #8, avg. train loss: 1736164.50000\n",
      "Step #4500, epoch #8, avg. train loss: 1981251.62500\n",
      "Step #4600, epoch #8, avg. train loss: 1849821.12500\n",
      "Step #4700, epoch #8, avg. train loss: 1740440.00000\n",
      "Step #4800, epoch #8, avg. train loss: 2225398.50000\n",
      "Step #4900, epoch #8, avg. train loss: 2145024.75000\n",
      "Step #5000, epoch #9, avg. train loss: 1330434.00000\n",
      "Score: 0.050748\n"
     ]
    }
   ],
   "source": [
    "#  Copyright 2015-present The Scikit Flow Authors. All Rights Reserved.\n",
    "#\n",
    "#  Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "#  you may not use this file except in compliance with the License.\n",
    "#  You may obtain a copy of the License at\n",
    "#\n",
    "#   http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "#  Unless required by applicable law or agreed to in writing, software\n",
    "#  distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "#  See the License for the specific language governing permissions and\n",
    "#  limitations under the License.\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# Build 2 layer fully connected DNN with 10, 10 units respectively.\n",
    "regressor = skflow.TensorFlowDNNRegressor(hidden_units=[10,10], steps=5000, learning_rate=0.1, batch_size=1)\n",
    "\n",
    "# Fit\n",
    "regressor.fit(X_train, y_train)\n",
    "\n",
    "# Predict and score\n",
    "#score_regressor = metrics.mean_squared_error( y_test, regressor.predict(X_test))\n",
    "score_regressor = r2_score(y_test, regressor.predict(X_test))\n",
    "\n",
    "print('Score: {0:f}'.format(score_regressor))\n",
    "\n",
    "# source https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/skflow/boston.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step #100, epoch #20, avg. train loss: 3340203.50000\n",
      "Step #200, epoch #40, avg. train loss: 1700708.62500\n",
      "Step #100, epoch #20, avg. train loss: 4074067.75000\n",
      "Step #200, epoch #40, avg. train loss: 1442584.00000\n",
      "Step #100, epoch #20, avg. train loss: 3884142.00000\n",
      "Step #200, epoch #40, avg. train loss: 1548484.00000\n",
      "Step #100, epoch #33, avg. train loss: 3375316.25000\n",
      "Step #200, epoch #66, avg. train loss: 1571986.12500\n",
      "Step #100, epoch #33, avg. train loss: 3090409.00000\n",
      "Step #200, epoch #66, avg. train loss: 1478086.50000\n",
      "Step #100, epoch #33, avg. train loss: 2677062.50000\n",
      "Step #200, epoch #66, avg. train loss: 2006786.12500\n",
      "Step #100, epoch #33, avg. train loss: 2615371.25000\n",
      "Step #200, epoch #66, avg. train loss: 1541998.75000\n",
      "Step #100, epoch #33, avg. train loss: 2393077.25000\n",
      "Step #200, epoch #66, avg. train loss: 1568316.75000\n",
      "Step #100, epoch #33, avg. train loss: 2460542.00000\n",
      "Step #200, epoch #66, avg. train loss: 1642864.50000\n",
      "Step #100, epoch #50, avg. train loss: 2202374.50000\n",
      "Step #200, epoch #100, avg. train loss: 1619331.87500\n",
      "Step #100, epoch #50, avg. train loss: 2106611.75000\n",
      "Step #200, epoch #100, avg. train loss: 1572494.87500\n",
      "Step #100, epoch #50, avg. train loss: 2209531.50000\n",
      "Step #200, epoch #100, avg. train loss: 1560847.50000\n",
      "Step #100, epoch #100, avg. train loss: 2276277.50000\n",
      "Step #200, epoch #200, avg. train loss: 1702736.62500\n",
      "Step #100, epoch #100, avg. train loss: 2213108.25000\n",
      "Step #200, epoch #200, avg. train loss: 1628009.62500\n",
      "Step #100, epoch #100, avg. train loss: 2271573.25000\n",
      "Step #200, epoch #200, avg. train loss: 1705614.25000\n",
      "Step #100, epoch #100, avg. train loss: 2070549.12500\n",
      "Step #200, epoch #200, avg. train loss: 1579425.75000\n",
      "Step #100, epoch #100, avg. train loss: 1994803.25000\n",
      "Step #200, epoch #200, avg. train loss: 1502305.25000\n",
      "Step #100, epoch #100, avg. train loss: 2085064.50000\n",
      "Step #200, epoch #200, avg. train loss: 1595549.87500\n",
      "Step #100, epoch #100, avg. train loss: 2451859.75000\n",
      "Step #200, epoch #200, avg. train loss: 1546494.50000\n",
      "Step #100, epoch #100, avg. train loss: 2351066.50000\n",
      "Step #200, epoch #200, avg. train loss: 1525689.12500\n",
      "Step #100, epoch #100, avg. train loss: 2468089.25000\n",
      "Step #200, epoch #200, avg. train loss: 1525534.75000\n",
      "Step #100, epoch #100, avg. train loss: 2833023.75000\n",
      "Step #200, epoch #200, avg. train loss: 1534037.25000\n",
      "Step #100, epoch #100, avg. train loss: 2738772.50000\n",
      "Step #200, epoch #200, avg. train loss: 1606067.62500\n",
      "Step #100, epoch #100, avg. train loss: 2872693.75000\n",
      "Step #200, epoch #200, avg. train loss: 1497990.25000\n",
      "Step #100, epoch #7, avg. train loss: 2182289.00000\n",
      "Step #200, epoch #14, avg. train loss: 1726507.87500\n",
      "Step #100, epoch #7, avg. train loss: 2187041.50000\n",
      "Step #200, epoch #14, avg. train loss: 1571912.12500\n",
      "Step #100, epoch #7, avg. train loss: 2214671.00000\n",
      "Step #200, epoch #14, avg. train loss: 1628010.12500\n",
      "Step #100, epoch #50, avg. train loss: 2162935.50000\n",
      "Step #200, epoch #100, avg. train loss: 1578702.87500\n",
      "Step #100, epoch #50, avg. train loss: 2092306.12500\n",
      "Step #200, epoch #100, avg. train loss: 1499963.87500\n",
      "Step #100, epoch #50, avg. train loss: 2200017.50000\n",
      "Step #200, epoch #100, avg. train loss: 1553514.87500\n",
      "Step #100, epoch #50, avg. train loss: 2372890.50000\n",
      "Step #200, epoch #100, avg. train loss: 1481554.75000\n",
      "Step #100, epoch #50, avg. train loss: 2256608.75000\n",
      "Step #200, epoch #100, avg. train loss: 1457597.25000\n",
      "Step #100, epoch #50, avg. train loss: 2366855.00000\n",
      "Step #200, epoch #100, avg. train loss: 1488916.50000\n",
      "Step #100, epoch #50, avg. train loss: 2161395.75000\n",
      "Step #200, epoch #100, avg. train loss: 1636918.50000\n",
      "Step #100, epoch #50, avg. train loss: 2075769.12500\n",
      "Step #200, epoch #100, avg. train loss: 1543235.00000\n",
      "Step #100, epoch #50, avg. train loss: 2174839.00000\n",
      "Step #200, epoch #100, avg. train loss: 1585745.50000\n",
      "Step #100, epoch #100, avg. train loss: 2606290.50000\n",
      "Step #200, epoch #200, avg. train loss: 1718032.00000\n",
      "Step #100, epoch #100, avg. train loss: 2556494.75000\n",
      "Step #200, epoch #200, avg. train loss: 1624646.50000\n",
      "Step #100, epoch #100, avg. train loss: 2593990.75000\n",
      "Step #200, epoch #200, avg. train loss: 1740497.50000\n",
      "Step #100, epoch #33, avg. train loss: 2660712.00000\n",
      "Step #200, epoch #66, avg. train loss: 1612717.87500\n",
      "Step #100, epoch #33, avg. train loss: 2634357.00000\n",
      "Step #200, epoch #66, avg. train loss: 1631696.75000\n",
      "Step #100, epoch #33, avg. train loss: 2646672.25000\n",
      "Step #200, epoch #66, avg. train loss: 1595205.62500\n",
      "Step #100, epoch #14, avg. train loss: 2856553.50000\n",
      "Step #200, epoch #28, avg. train loss: 1534524.62500\n",
      "Step #100, epoch #14, avg. train loss: 2675025.25000\n",
      "Step #200, epoch #28, avg. train loss: 1458291.37500\n",
      "Step #100, epoch #14, avg. train loss: 2860176.00000\n",
      "Step #200, epoch #28, avg. train loss: 1646803.62500\n",
      "Step #100, epoch #100, avg. train loss: 2468408.25000\n",
      "Step #200, epoch #200, avg. train loss: 1547418.75000\n",
      "Step #100, epoch #100, avg. train loss: 2394060.00000\n",
      "Step #200, epoch #200, avg. train loss: 1483971.00000\n",
      "Step #100, epoch #100, avg. train loss: 2472441.75000\n",
      "Step #200, epoch #200, avg. train loss: 1505252.75000\n",
      "Step #100, epoch #100, avg. train loss: 2175217.00000\n",
      "Step #200, epoch #200, avg. train loss: 1515171.62500\n",
      "Step #100, epoch #100, avg. train loss: 2111567.75000\n",
      "Step #200, epoch #200, avg. train loss: 1442401.25000\n",
      "Step #100, epoch #100, avg. train loss: 2195208.00000\n",
      "Step #200, epoch #200, avg. train loss: 1525635.62500\n",
      "Step #100, epoch #100, avg. train loss: 2050901.50000\n",
      "Step #200, epoch #200, avg. train loss: 1524339.87500\n",
      "Step #100, epoch #100, avg. train loss: 1969679.50000\n",
      "Step #200, epoch #200, avg. train loss: 1479846.37500\n",
      "Step #100, epoch #100, avg. train loss: 2061783.50000\n",
      "Step #200, epoch #200, avg. train loss: 1508885.75000\n",
      "Step #100, epoch #50, avg. train loss: 2218518.25000\n",
      "Step #200, epoch #100, avg. train loss: 1616477.50000\n",
      "Step #100, epoch #50, avg. train loss: 2105352.00000\n",
      "Step #200, epoch #100, avg. train loss: 1507048.50000\n",
      "Step #100, epoch #50, avg. train loss: 2201775.25000\n",
      "Step #200, epoch #100, avg. train loss: 1529364.75000\n",
      "Step #100, epoch #50, avg. train loss: 2909508.50000\n",
      "Step #200, epoch #100, avg. train loss: 1511351.62500\n",
      "Step #100, epoch #50, avg. train loss: 3065341.00000\n",
      "Step #200, epoch #100, avg. train loss: 1553780.75000\n",
      "Step #100, epoch #50, avg. train loss: 2806696.00000\n",
      "Step #200, epoch #100, avg. train loss: 1568193.87500\n",
      "Step #100, epoch #100, avg. train loss: 2183099.75000\n",
      "Step #200, epoch #200, avg. train loss: 1721306.87500\n",
      "Step #100, epoch #100, avg. train loss: 2119160.75000\n",
      "Step #200, epoch #200, avg. train loss: 1667191.37500\n",
      "Step #100, epoch #100, avg. train loss: 2192495.25000\n",
      "Step #200, epoch #200, avg. train loss: 1744957.50000\n",
      "Step #100, epoch #50, avg. train loss: 2632387.75000\n",
      "Step #200, epoch #100, avg. train loss: 1576939.87500\n",
      "Step #100, epoch #50, avg. train loss: 3181374.50000\n",
      "Step #200, epoch #100, avg. train loss: 1598080.62500\n",
      "Step #100, epoch #50, avg. train loss: 2517011.75000\n",
      "Step #200, epoch #100, avg. train loss: 1613871.37500\n",
      "Step #100, epoch #5, avg. train loss: 10551280.00000\n",
      "Step #200, epoch #11, avg. train loss: 7057742.00000\n",
      "Step #100, epoch #5, avg. train loss: 10930089.00000\n",
      "Step #200, epoch #11, avg. train loss: 7269641.50000\n",
      "Step #100, epoch #5, avg. train loss: 10254098.00000\n",
      "Step #200, epoch #11, avg. train loss: 6862016.50000\n",
      "Step #100, epoch #50, avg. train loss: 2166040.25000\n",
      "Step #200, epoch #100, avg. train loss: 1692111.87500\n",
      "Step #100, epoch #50, avg. train loss: 2084884.37500\n",
      "Step #200, epoch #100, avg. train loss: 1529859.50000\n",
      "Step #100, epoch #50, avg. train loss: 2194525.50000\n",
      "Step #200, epoch #100, avg. train loss: 1558989.87500\n",
      "Step #100, epoch #100, avg. train loss: 2879127.00000\n",
      "Step #200, epoch #200, avg. train loss: 1503201.75000\n",
      "Step #100, epoch #100, avg. train loss: 2838358.50000\n",
      "Step #200, epoch #200, avg. train loss: 1487314.50000\n",
      "Step #100, epoch #100, avg. train loss: 2872175.00000\n",
      "Step #200, epoch #200, avg. train loss: 1474290.87500\n",
      "Step #100, epoch #33, avg. train loss: 2561392.75000\n",
      "Step #200, epoch #66, avg. train loss: 1598913.62500\n",
      "Step #100, epoch #33, avg. train loss: 2493429.50000\n",
      "Step #200, epoch #66, avg. train loss: 1623461.00000\n",
      "Step #100, epoch #33, avg. train loss: 2586685.00000\n",
      "Step #200, epoch #66, avg. train loss: 1573222.75000\n",
      "Step #100, epoch #100, avg. train loss: 2207830.25000\n",
      "Step #200, epoch #200, avg. train loss: 1701103.00000\n",
      "Step #100, epoch #100, avg. train loss: 2134271.50000\n",
      "Step #200, epoch #200, avg. train loss: 1608166.75000\n",
      "Step #100, epoch #100, avg. train loss: 2213333.00000\n",
      "Step #200, epoch #200, avg. train loss: 1705334.75000\n",
      "Step #100, epoch #33, avg. train loss: 2303419.75000\n",
      "Step #200, epoch #66, avg. train loss: 1531944.00000\n",
      "Step #100, epoch #33, avg. train loss: 2201663.25000\n",
      "Step #200, epoch #66, avg. train loss: 1437941.00000\n",
      "Step #100, epoch #33, avg. train loss: 2297467.25000\n",
      "Step #200, epoch #66, avg. train loss: 1545437.50000\n",
      "Step #100, epoch #100, avg. train loss: 3171279.75000\n",
      "Step #200, epoch #200, avg. train loss: 1532630.12500\n",
      "Step #100, epoch #100, avg. train loss: 3459467.50000\n",
      "Step #200, epoch #200, avg. train loss: 1469769.25000\n",
      "Step #100, epoch #100, avg. train loss: 3171793.50000\n",
      "Step #200, epoch #200, avg. train loss: 1574651.50000\n",
      "Step #100, epoch #100, avg. train loss: 2971299.00000\n",
      "Step #200, epoch #200, avg. train loss: 1502896.62500\n",
      "Step #100, epoch #100, avg. train loss: 2894620.75000\n",
      "Step #200, epoch #200, avg. train loss: 1481690.37500\n",
      "Step #100, epoch #100, avg. train loss: 2752316.50000\n",
      "Step #200, epoch #200, avg. train loss: 1494502.75000\n",
      "Step #100, epoch #25, avg. train loss: 2675095.75000\n",
      "Step #200, epoch #50, avg. train loss: 1547244.00000\n",
      "Step #100, epoch #25, avg. train loss: 2815334.50000\n",
      "Step #200, epoch #50, avg. train loss: 1520208.75000\n",
      "Step #100, epoch #25, avg. train loss: 2711797.50000\n",
      "Step #200, epoch #50, avg. train loss: 1484353.87500\n",
      "Step #100, epoch #100, avg. train loss: 2927140.25000\n",
      "Step #200, epoch #200, avg. train loss: 1533684.00000\n",
      "Step #100, epoch #100, avg. train loss: 2867807.25000\n",
      "Step #200, epoch #200, avg. train loss: 1463689.62500\n",
      "Step #100, epoch #100, avg. train loss: 2934940.50000\n",
      "Step #200, epoch #200, avg. train loss: 1500742.25000\n",
      "Step #100, epoch #50, avg. train loss: 2105714.75000\n",
      "Step #200, epoch #100, avg. train loss: 1649202.75000\n",
      "Step #100, epoch #50, avg. train loss: 2043565.12500\n",
      "Step #200, epoch #100, avg. train loss: 1548617.25000\n",
      "Step #100, epoch #50, avg. train loss: 2113247.75000\n",
      "Step #200, epoch #100, avg. train loss: 1621346.12500\n",
      "Step #100, epoch #33, avg. train loss: 2574055.75000\n",
      "Step #200, epoch #66, avg. train loss: 1780225.62500\n",
      "Step #100, epoch #33, avg. train loss: 2512406.50000\n",
      "Step #200, epoch #66, avg. train loss: 1680301.87500\n",
      "Step #100, epoch #33, avg. train loss: 2572516.00000\n",
      "Step #200, epoch #66, avg. train loss: 1784537.00000\n",
      "Step #100, epoch #100, avg. train loss: 2897210.25000\n",
      "Step #200, epoch #200, avg. train loss: 1633014.37500\n",
      "Step #100, epoch #100, avg. train loss: 2824467.75000\n",
      "Step #200, epoch #200, avg. train loss: 1534878.37500\n",
      "Step #100, epoch #100, avg. train loss: 2881743.00000\n",
      "Step #200, epoch #200, avg. train loss: 1530329.25000\n",
      "Step #100, epoch #100, avg. train loss: 2529078.00000\n",
      "Step #200, epoch #200, avg. train loss: 1674942.75000\n",
      "Step #100, epoch #100, avg. train loss: 2561770.50000\n",
      "Step #200, epoch #200, avg. train loss: 1648805.62500\n",
      "Step #100, epoch #100, avg. train loss: 2401403.75000\n",
      "Step #200, epoch #200, avg. train loss: 1588857.50000\n",
      "Step #100, epoch #33, avg. train loss: 10691983.00000\n",
      "Step #200, epoch #66, avg. train loss: 7800432.50000\n",
      "Step #100, epoch #33, avg. train loss: 10992408.00000\n",
      "Step #200, epoch #66, avg. train loss: 8036054.50000\n",
      "Step #100, epoch #33, avg. train loss: 10401249.00000\n",
      "Step #200, epoch #66, avg. train loss: 7603126.50000\n",
      "Step #100, epoch #50, avg. train loss: 8071747.00000\n",
      "Step #200, epoch #100, avg. train loss: 3085082.50000\n",
      "Step #100, epoch #50, avg. train loss: 8287297.50000\n",
      "Step #200, epoch #100, avg. train loss: 3136447.25000\n",
      "Step #100, epoch #50, avg. train loss: 7844170.00000\n",
      "Step #200, epoch #100, avg. train loss: 3022056.75000\n",
      "Step #100, epoch #25, avg. train loss: 2145333.00000\n",
      "Step #200, epoch #50, avg. train loss: 1523907.62500\n",
      "Step #100, epoch #25, avg. train loss: 2084313.12500\n",
      "Step #200, epoch #50, avg. train loss: 1476397.12500\n",
      "Step #100, epoch #25, avg. train loss: 2164952.75000\n",
      "Step #200, epoch #50, avg. train loss: 1555539.37500\n",
      "Step #100, epoch #100, avg. train loss: 2051310.25000\n",
      "Step #200, epoch #200, avg. train loss: 1570266.87500\n",
      "Step #100, epoch #100, avg. train loss: 1978490.37500\n",
      "Step #200, epoch #200, avg. train loss: 1508289.00000\n",
      "Step #100, epoch #100, avg. train loss: 2054187.62500\n",
      "Step #200, epoch #200, avg. train loss: 1526185.00000\n",
      "Step #100, epoch #33, avg. train loss: 2626886.50000\n",
      "Step #200, epoch #66, avg. train loss: 1598918.37500\n",
      "Step #100, epoch #33, avg. train loss: 2551148.75000\n",
      "Step #200, epoch #66, avg. train loss: 1642206.37500\n",
      "Step #100, epoch #33, avg. train loss: 2618127.25000\n",
      "Step #200, epoch #66, avg. train loss: 1580047.87500\n",
      "Step #100, epoch #50, avg. train loss: 3012131.75000\n",
      "Step #200, epoch #100, avg. train loss: 1459389.87500\n",
      "Step #100, epoch #50, avg. train loss: 2989577.25000\n",
      "Step #200, epoch #100, avg. train loss: 1496924.37500\n",
      "Step #100, epoch #50, avg. train loss: 2713892.75000\n",
      "Step #200, epoch #100, avg. train loss: 1641407.37500\n",
      "Step #100, epoch #100, avg. train loss: 2140860.50000\n",
      "Step #200, epoch #200, avg. train loss: 1508482.87500\n",
      "Step #100, epoch #100, avg. train loss: 2066715.62500\n",
      "Step #200, epoch #200, avg. train loss: 1452397.00000\n",
      "Step #100, epoch #100, avg. train loss: 2132923.00000\n",
      "Step #200, epoch #200, avg. train loss: 1464741.62500\n",
      "Step #100, epoch #50, avg. train loss: 2128719.25000\n",
      "Step #200, epoch #100, avg. train loss: 1588984.62500\n",
      "Step #100, epoch #50, avg. train loss: 2084274.25000\n",
      "Step #200, epoch #100, avg. train loss: 1588353.00000\n",
      "Step #100, epoch #50, avg. train loss: 2214634.50000\n",
      "Step #200, epoch #100, avg. train loss: 1602673.25000\n",
      "Step #100, epoch #50, avg. train loss: 2851810.25000\n",
      "Step #200, epoch #100, avg. train loss: 1620310.75000\n",
      "Step #100, epoch #50, avg. train loss: 2879224.75000\n",
      "Step #200, epoch #100, avg. train loss: 1442391.87500\n",
      "Step #100, epoch #50, avg. train loss: 2967622.50000\n",
      "Step #200, epoch #100, avg. train loss: 1541823.25000\n",
      "Step #100, epoch #100, avg. train loss: 2194179.75000\n",
      "Step #200, epoch #200, avg. train loss: 1598651.50000\n",
      "Step #100, epoch #100, avg. train loss: 2137278.50000\n",
      "Step #200, epoch #200, avg. train loss: 1501177.62500\n",
      "Step #100, epoch #100, avg. train loss: 2197887.25000\n",
      "Step #200, epoch #200, avg. train loss: 1613563.50000\n",
      "Step #100, epoch #20, avg. train loss: 2364944.75000\n",
      "Step #200, epoch #40, avg. train loss: 1551746.50000\n",
      "Step #100, epoch #20, avg. train loss: 2286694.50000\n",
      "Step #200, epoch #40, avg. train loss: 1470526.50000\n",
      "Step #100, epoch #16, avg. train loss: 2340644.50000\n",
      "Step #200, epoch #33, avg. train loss: 1638653.50000\n",
      "Step #100, epoch #50, avg. train loss: 2650306.00000\n",
      "Step #200, epoch #100, avg. train loss: 1486386.75000\n",
      "Step #100, epoch #50, avg. train loss: 2517291.25000\n",
      "Step #200, epoch #100, avg. train loss: 1490350.25000\n",
      "Step #100, epoch #50, avg. train loss: 2627833.50000\n",
      "Step #200, epoch #100, avg. train loss: 1520080.75000\n",
      "Step #100, epoch #100, avg. train loss: 2854384.75000\n",
      "Step #200, epoch #200, avg. train loss: 1627941.75000\n",
      "Step #100, epoch #100, avg. train loss: 2753277.50000\n",
      "Step #200, epoch #200, avg. train loss: 1484922.12500\n",
      "Step #100, epoch #100, avg. train loss: 2839931.00000\n",
      "Step #200, epoch #200, avg. train loss: 1504715.87500\n",
      "Step #100, epoch #50, avg. train loss: 2222230.75000\n",
      "Step #200, epoch #100, avg. train loss: 1596299.37500\n",
      "Step #100, epoch #50, avg. train loss: 2109179.50000\n",
      "Step #200, epoch #100, avg. train loss: 1592596.75000\n",
      "Step #100, epoch #50, avg. train loss: 2243809.25000\n",
      "Step #200, epoch #100, avg. train loss: 1707879.37500\n",
      "Step #100, epoch #50, avg. train loss: 2895393.50000\n",
      "Step #200, epoch #100, avg. train loss: 1516142.25000\n",
      "Step #100, epoch #50, avg. train loss: 2829873.25000\n",
      "Step #200, epoch #100, avg. train loss: 1460519.37500\n",
      "Step #100, epoch #50, avg. train loss: 2847358.50000\n",
      "Step #200, epoch #100, avg. train loss: 1574028.12500\n",
      "Step #100, epoch #100, avg. train loss: 2914482.25000\n",
      "Step #200, epoch #200, avg. train loss: 1756903.25000\n",
      "Step #100, epoch #100, avg. train loss: 2887371.50000\n",
      "Step #200, epoch #200, avg. train loss: 1671954.87500\n",
      "Step #100, epoch #100, avg. train loss: 2888940.25000\n",
      "Step #200, epoch #200, avg. train loss: 1775474.50000\n",
      "Step #100, epoch #50, avg. train loss: 2117943.75000\n",
      "Step #200, epoch #100, avg. train loss: 1535717.75000\n",
      "Step #100, epoch #50, avg. train loss: 2055430.75000\n",
      "Step #200, epoch #100, avg. train loss: 1515432.12500\n",
      "Step #100, epoch #50, avg. train loss: 2142817.50000\n",
      "Step #200, epoch #100, avg. train loss: 1515520.75000\n",
      "Step #100, epoch #100, avg. train loss: 2047417.00000\n",
      "Step #200, epoch #200, avg. train loss: 1540555.50000\n",
      "Step #100, epoch #100, avg. train loss: 1978426.12500\n",
      "Step #200, epoch #200, avg. train loss: 1465438.37500\n",
      "Step #100, epoch #100, avg. train loss: 2069742.87500\n",
      "Step #200, epoch #200, avg. train loss: 1561430.12500\n",
      "Step #100, epoch #100, avg. train loss: 2118016.50000\n",
      "Step #200, epoch #200, avg. train loss: 1554415.25000\n",
      "Step #100, epoch #100, avg. train loss: 2039835.50000\n",
      "Step #200, epoch #200, avg. train loss: 1478337.50000\n",
      "Step #100, epoch #100, avg. train loss: 2128083.75000\n",
      "Step #200, epoch #200, avg. train loss: 1547310.87500\n",
      "Step #100, epoch #50, avg. train loss: 2214698.75000\n",
      "Step #200, epoch #100, avg. train loss: 1699108.12500\n",
      "Step #100, epoch #50, avg. train loss: 2174051.00000\n",
      "Step #200, epoch #100, avg. train loss: 1634413.62500\n",
      "Step #100, epoch #50, avg. train loss: 2239797.50000\n",
      "Step #200, epoch #100, avg. train loss: 1751832.37500\n",
      "Step #100, epoch #50, avg. train loss: 2140948.25000\n",
      "Step #200, epoch #100, avg. train loss: 1557554.37500\n",
      "Step #100, epoch #50, avg. train loss: 2080509.00000\n",
      "Step #200, epoch #100, avg. train loss: 1523469.87500\n",
      "Step #100, epoch #50, avg. train loss: 2155236.75000\n",
      "Step #200, epoch #100, avg. train loss: 1518491.37500\n",
      "Step #100, epoch #25, avg. train loss: 4542254.00000\n",
      "Step #200, epoch #50, avg. train loss: 1830878.87500\n",
      "Step #100, epoch #25, avg. train loss: 4692986.00000\n",
      "Step #200, epoch #50, avg. train loss: 1743164.37500\n",
      "Step #100, epoch #25, avg. train loss: 4466817.50000\n",
      "Step #200, epoch #50, avg. train loss: 1837136.37500\n",
      "Step #100, epoch #10, avg. train loss: 2228537.00000\n",
      "Step #200, epoch #20, avg. train loss: 1752489.75000\n",
      "Step #100, epoch #10, avg. train loss: 2104195.75000\n",
      "Step #200, epoch #20, avg. train loss: 1644115.25000\n",
      "Step #100, epoch #10, avg. train loss: 2193585.50000\n",
      "Step #200, epoch #20, avg. train loss: 1811678.87500\n",
      "Step #100, epoch #8, avg. train loss: 2361537.00000\n",
      "Step #200, epoch #16, avg. train loss: 1708396.62500\n",
      "Step #100, epoch #8, avg. train loss: 2249358.00000\n",
      "Step #200, epoch #16, avg. train loss: 1575394.87500\n",
      "Step #100, epoch #8, avg. train loss: 2190616.75000\n",
      "Step #200, epoch #16, avg. train loss: 1633721.00000\n",
      "Step #100, epoch #100, avg. train loss: 2493541.50000\n",
      "Step #200, epoch #200, avg. train loss: 1677374.25000\n",
      "Step #100, epoch #100, avg. train loss: 2913091.50000\n",
      "Step #200, epoch #200, avg. train loss: 1540636.50000\n",
      "Step #100, epoch #100, avg. train loss: 2595387.25000\n",
      "Step #200, epoch #200, avg. train loss: 1450161.75000\n",
      "Step #100, epoch #50, avg. train loss: 2673592.75000\n",
      "Step #200, epoch #100, avg. train loss: 1515700.00000\n",
      "Step #100, epoch #50, avg. train loss: 2589033.00000\n",
      "Step #200, epoch #100, avg. train loss: 1531630.75000\n",
      "Step #100, epoch #50, avg. train loss: 2735316.25000\n",
      "Step #200, epoch #100, avg. train loss: 1536697.75000\n",
      "Step #100, epoch #50, avg. train loss: 2356949.00000\n",
      "Step #200, epoch #100, avg. train loss: 1758452.00000\n",
      "Step #100, epoch #50, avg. train loss: 2286962.50000\n",
      "Step #200, epoch #100, avg. train loss: 1676866.25000\n",
      "Step #100, epoch #50, avg. train loss: 2354775.75000\n",
      "Step #200, epoch #100, avg. train loss: 1794556.62500\n",
      "Step #100, epoch #33, avg. train loss: 2899100.75000\n",
      "Step #200, epoch #66, avg. train loss: 1536013.87500\n",
      "Step #100, epoch #33, avg. train loss: 2811118.50000\n",
      "Step #200, epoch #66, avg. train loss: 1491992.62500\n",
      "Step #100, epoch #33, avg. train loss: 3009678.00000\n",
      "Step #200, epoch #66, avg. train loss: 1447781.25000\n",
      "Step #100, epoch #100, avg. train loss: 2783439.25000\n",
      "Step #200, epoch #200, avg. train loss: 1456647.62500\n",
      "Step #100, epoch #100, avg. train loss: 2752116.25000\n",
      "Step #200, epoch #200, avg. train loss: 1535346.12500\n",
      "Step #100, epoch #100, avg. train loss: 2773367.00000\n",
      "Step #200, epoch #200, avg. train loss: 1509393.50000\n",
      "Step #100, epoch #50, avg. train loss: 2699820.75000\n",
      "Step #200, epoch #100, avg. train loss: 1684045.00000\n",
      "Step #100, epoch #50, avg. train loss: 3013004.75000\n",
      "Step #200, epoch #100, avg. train loss: 1520094.75000\n",
      "Step #100, epoch #50, avg. train loss: 2930635.00000\n",
      "Step #200, epoch #100, avg. train loss: 1508143.87500\n",
      "Step #100, epoch #100, avg. train loss: 2584203.75000\n",
      "Step #200, epoch #200, avg. train loss: 1570895.25000\n",
      "Step #100, epoch #100, avg. train loss: 2502506.00000\n",
      "Step #200, epoch #200, avg. train loss: 1482472.12500\n",
      "Step #100, epoch #100, avg. train loss: 2556829.00000\n",
      "Step #200, epoch #200, avg. train loss: 1525660.75000\n",
      "Step #100, epoch #50, avg. train loss: 2460889.50000\n",
      "Step #200, epoch #100, avg. train loss: 1773922.37500\n",
      "Step #100, epoch #50, avg. train loss: 2400705.50000\n",
      "Step #200, epoch #100, avg. train loss: 1703980.75000\n",
      "Step #100, epoch #50, avg. train loss: 2446573.75000\n",
      "Step #200, epoch #100, avg. train loss: 1795552.12500\n",
      "Step #100, epoch #100, avg. train loss: 2262203.25000\n",
      "Step #200, epoch #200, avg. train loss: 1646865.00000\n",
      "Step #100, epoch #100, avg. train loss: 2207852.50000\n",
      "Step #200, epoch #200, avg. train loss: 1604721.87500\n",
      "Step #100, epoch #100, avg. train loss: 2262759.00000\n",
      "Step #200, epoch #200, avg. train loss: 1684349.50000\n",
      "Step #100, epoch #12, avg. train loss: 2304590.00000\n",
      "Step #200, epoch #25, avg. train loss: 1582353.75000\n",
      "Step #100, epoch #12, avg. train loss: 2174333.50000\n",
      "Step #200, epoch #25, avg. train loss: 1533893.25000\n",
      "Step #100, epoch #12, avg. train loss: 2270065.25000\n",
      "Step #200, epoch #25, avg. train loss: 1553632.50000\n",
      "Step #100, epoch #100, avg. train loss: 2408875.25000\n",
      "Step #200, epoch #200, avg. train loss: 1534031.00000\n",
      "Step #100, epoch #100, avg. train loss: 2326633.00000\n",
      "Step #200, epoch #200, avg. train loss: 1496137.87500\n",
      "Step #100, epoch #100, avg. train loss: 2418378.25000\n",
      "Step #200, epoch #200, avg. train loss: 1569643.00000\n",
      "Step #100, epoch #100, avg. train loss: 3056475.75000\n",
      "Step #200, epoch #200, avg. train loss: 1555449.25000\n",
      "Step #100, epoch #100, avg. train loss: 2985849.50000\n",
      "Step #200, epoch #200, avg. train loss: 1500240.50000\n",
      "Step #100, epoch #100, avg. train loss: 3039147.75000\n",
      "Step #200, epoch #200, avg. train loss: 1585068.75000\n",
      "Step #100, epoch #50, avg. train loss: 2155578.50000\n",
      "Step #200, epoch #100, avg. train loss: 1650695.87500\n",
      "Step #100, epoch #50, avg. train loss: 2187778.00000\n",
      "Step #200, epoch #100, avg. train loss: 1478335.87500\n",
      "Step #100, epoch #50, avg. train loss: 2220415.75000\n",
      "Step #200, epoch #100, avg. train loss: 1676692.00000\n",
      "Step #100, epoch #50, avg. train loss: 2271461.75000\n",
      "Step #200, epoch #100, avg. train loss: 1603804.37500\n",
      "Step #100, epoch #50, avg. train loss: 2217305.50000\n",
      "Step #200, epoch #100, avg. train loss: 1544086.50000\n",
      "Step #100, epoch #50, avg. train loss: 2277483.25000\n",
      "Step #200, epoch #100, avg. train loss: 1499027.00000\n",
      "Step #100, epoch #25, avg. train loss: 2214852.75000\n",
      "Step #200, epoch #50, avg. train loss: 1697485.75000\n",
      "Step #100, epoch #25, avg. train loss: 2227010.75000\n",
      "Step #200, epoch #50, avg. train loss: 1665183.62500\n",
      "Step #100, epoch #25, avg. train loss: 2379754.00000\n",
      "Step #200, epoch #50, avg. train loss: 1775670.87500\n",
      "Step #100, epoch #100, avg. train loss: 2393654.25000\n",
      "Step #200, epoch #200, avg. train loss: 1723243.87500\n",
      "Step #100, epoch #100, avg. train loss: 2330896.25000\n",
      "Step #200, epoch #200, avg. train loss: 1635318.50000\n",
      "Step #100, epoch #100, avg. train loss: 2390793.25000\n",
      "Step #200, epoch #200, avg. train loss: 1736414.37500\n",
      "Step #100, epoch #50, avg. train loss: 3256494.50000\n",
      "Step #200, epoch #100, avg. train loss: 1575401.75000\n",
      "Step #100, epoch #50, avg. train loss: 3358766.50000\n",
      "Step #200, epoch #100, avg. train loss: 1517403.50000\n",
      "Step #100, epoch #50, avg. train loss: 3290574.75000\n",
      "Step #200, epoch #100, avg. train loss: 1497964.00000\n",
      "Step #100, epoch #50, avg. train loss: 3895314.25000\n",
      "Step #200, epoch #100, avg. train loss: 1494082.87500\n",
      "Step #100, epoch #50, avg. train loss: 3647747.25000\n",
      "Step #200, epoch #100, avg. train loss: 1530099.87500\n",
      "Step #100, epoch #50, avg. train loss: 3287295.75000\n",
      "Step #200, epoch #100, avg. train loss: 1750735.37500\n",
      "Step #100, epoch #100, avg. train loss: 2905827.25000\n",
      "Step #200, epoch #200, avg. train loss: 1510475.37500\n",
      "Step #100, epoch #100, avg. train loss: 2861714.00000\n",
      "Step #200, epoch #200, avg. train loss: 1457444.00000\n",
      "Step #100, epoch #100, avg. train loss: 2923100.50000\n",
      "Step #200, epoch #200, avg. train loss: 1481530.37500\n",
      "Step #100, epoch #25, avg. train loss: 2709631.75000\n",
      "Step #200, epoch #50, avg. train loss: 1571570.12500\n",
      "Step #100, epoch #25, avg. train loss: 2583344.25000\n",
      "Step #200, epoch #50, avg. train loss: 1547872.62500\n",
      "Step #100, epoch #25, avg. train loss: 2716267.00000\n",
      "Step #200, epoch #50, avg. train loss: 1544270.12500\n",
      "Step #100, epoch #50, avg. train loss: 2245655.75000\n",
      "Step #200, epoch #100, avg. train loss: 1618766.37500\n",
      "Step #100, epoch #50, avg. train loss: 2145647.75000\n",
      "Step #200, epoch #100, avg. train loss: 1580342.37500\n",
      "Step #100, epoch #50, avg. train loss: 2239841.00000\n",
      "Step #200, epoch #100, avg. train loss: 1635079.25000\n",
      "Step #100, epoch #100, avg. train loss: 2163123.75000\n",
      "Step #200, epoch #200, avg. train loss: 1643414.25000\n",
      "Step #100, epoch #100, avg. train loss: 2082964.62500\n",
      "Step #200, epoch #200, avg. train loss: 1540022.12500\n",
      "Step #100, epoch #100, avg. train loss: 2138641.75000\n",
      "Step #200, epoch #200, avg. train loss: 1526715.50000\n",
      "Step #100, epoch #100, avg. train loss: 2195955.25000\n",
      "Step #200, epoch #200, avg. train loss: 1571186.50000\n",
      "Step #100, epoch #100, avg. train loss: 2128512.75000\n",
      "Step #200, epoch #200, avg. train loss: 1505194.25000\n",
      "Step #100, epoch #100, avg. train loss: 2195158.50000\n",
      "Step #200, epoch #200, avg. train loss: 1536050.87500\n",
      "Step #100, epoch #100, avg. train loss: 2388050.25000\n",
      "Step #200, epoch #200, avg. train loss: 1685981.25000\n",
      "Step #100, epoch #100, avg. train loss: 2330938.00000\n",
      "Step #200, epoch #200, avg. train loss: 1616979.50000\n",
      "Step #100, epoch #100, avg. train loss: 2384767.50000\n",
      "Step #200, epoch #200, avg. train loss: 1717297.25000\n",
      "Step #100, epoch #25, avg. train loss: 2511340.75000\n",
      "Step #200, epoch #50, avg. train loss: 1538595.37500\n",
      "Step #100, epoch #25, avg. train loss: 2402926.25000\n",
      "Step #200, epoch #50, avg. train loss: 1474860.62500\n",
      "Step #100, epoch #25, avg. train loss: 2491872.50000\n",
      "Step #200, epoch #50, avg. train loss: 1536614.50000\n",
      "Step #100, epoch #100, avg. train loss: 6235039.50000\n",
      "Step #200, epoch #200, avg. train loss: 1797136.37500\n",
      "Step #100, epoch #100, avg. train loss: 6399412.50000\n",
      "Step #200, epoch #200, avg. train loss: 1711840.00000\n",
      "Step #100, epoch #100, avg. train loss: 6078307.00000\n",
      "Step #200, epoch #200, avg. train loss: 1821849.12500\n",
      "Step #100, epoch #100, avg. train loss: 2137983.00000\n",
      "Step #200, epoch #200, avg. train loss: 1584626.87500\n",
      "Step #100, epoch #100, avg. train loss: 2054933.87500\n",
      "Step #200, epoch #200, avg. train loss: 1555859.37500\n",
      "Step #100, epoch #100, avg. train loss: 2152192.50000\n",
      "Step #200, epoch #200, avg. train loss: 1571776.62500\n",
      "Step #100, epoch #100, avg. train loss: 2587740.25000\n",
      "Step #200, epoch #200, avg. train loss: 1563825.12500\n",
      "Step #100, epoch #100, avg. train loss: 2544213.00000\n",
      "Step #200, epoch #200, avg. train loss: 1490462.87500\n",
      "Step #100, epoch #100, avg. train loss: 2551870.50000\n",
      "Step #200, epoch #200, avg. train loss: 1516475.87500\n",
      "Step #100, epoch #100, avg. train loss: 2142243.75000\n",
      "Step #200, epoch #200, avg. train loss: 1574186.87500\n",
      "Step #100, epoch #100, avg. train loss: 2063713.50000\n",
      "Step #200, epoch #200, avg. train loss: 1511296.75000\n",
      "Step #100, epoch #100, avg. train loss: 2150686.00000\n",
      "Step #200, epoch #200, avg. train loss: 1566267.50000\n",
      "Step #100, epoch #50, avg. train loss: 2388049.00000\n",
      "Step #200, epoch #100, avg. train loss: 1503821.75000\n",
      "Step #100, epoch #50, avg. train loss: 2343652.50000\n",
      "Step #200, epoch #100, avg. train loss: 1502092.62500\n",
      "Step #100, epoch #50, avg. train loss: 2407250.00000\n",
      "Step #200, epoch #100, avg. train loss: 1531003.50000\n",
      "Step #100, epoch #50, avg. train loss: 2163884.75000\n",
      "Step #200, epoch #100, avg. train loss: 1550391.00000\n",
      "Step #100, epoch #50, avg. train loss: 2102178.75000\n",
      "Step #200, epoch #100, avg. train loss: 1563709.00000\n",
      "Step #100, epoch #50, avg. train loss: 2180487.00000\n",
      "Step #200, epoch #100, avg. train loss: 1534800.37500\n",
      "Step #100, epoch #2, avg. train loss: 2358002.50000\n",
      "Step #200, epoch #5, avg. train loss: 1693661.62500\n",
      "Step #100, epoch #2, avg. train loss: 2397857.50000\n",
      "Step #200, epoch #5, avg. train loss: 1619370.50000\n",
      "Step #100, epoch #2, avg. train loss: 2503564.75000\n",
      "Step #200, epoch #5, avg. train loss: 1665860.12500\n",
      "Step #100, epoch #100, avg. train loss: 2656878.00000\n",
      "Step #200, epoch #200, avg. train loss: 1605533.12500\n",
      "Step #100, epoch #100, avg. train loss: 3267552.00000\n",
      "Step #200, epoch #200, avg. train loss: 1710287.62500\n",
      "Step #100, epoch #100, avg. train loss: 2484712.25000\n",
      "Step #200, epoch #200, avg. train loss: 1715970.25000\n",
      "Step #100, epoch #100, avg. train loss: 2131664.50000\n",
      "Step #200, epoch #200, avg. train loss: 1555412.75000\n",
      "Step #100, epoch #100, avg. train loss: 2058667.37500\n",
      "Step #200, epoch #200, avg. train loss: 1477565.25000\n",
      "Step #100, epoch #100, avg. train loss: 2139796.75000\n",
      "Step #200, epoch #200, avg. train loss: 1545045.75000\n",
      "Step #100, epoch #100, avg. train loss: 2522678.00000\n",
      "Step #200, epoch #200, avg. train loss: 1730488.75000\n",
      "Step #100, epoch #100, avg. train loss: 2481615.00000\n",
      "Step #200, epoch #200, avg. train loss: 1648185.00000\n",
      "Step #100, epoch #100, avg. train loss: 2511418.50000\n",
      "Step #200, epoch #200, avg. train loss: 1750369.62500\n",
      "Step #100, epoch #100, avg. train loss: 2564953.75000\n",
      "Step #200, epoch #200, avg. train loss: 1597408.75000\n",
      "Step #100, epoch #100, avg. train loss: 2472928.75000\n",
      "Step #200, epoch #200, avg. train loss: 1529787.50000\n",
      "Step #100, epoch #100, avg. train loss: 2533226.75000\n",
      "Step #200, epoch #200, avg. train loss: 1516460.75000\n",
      "Step #100, epoch #25, avg. train loss: 2970025.00000\n",
      "Step #200, epoch #50, avg. train loss: 1653168.50000\n",
      "Step #100, epoch #25, avg. train loss: 2915235.75000\n",
      "Step #200, epoch #50, avg. train loss: 1605430.25000\n",
      "Step #100, epoch #25, avg. train loss: 2666147.00000\n",
      "Step #200, epoch #50, avg. train loss: 1629806.25000\n",
      "Step #100, epoch #100, avg. train loss: 2224653.50000\n",
      "Step #200, epoch #200, avg. train loss: 1571445.87500\n",
      "Step #100, epoch #100, avg. train loss: 2153622.75000\n",
      "Step #200, epoch #200, avg. train loss: 1502234.50000\n",
      "Step #100, epoch #100, avg. train loss: 2230933.25000\n",
      "Step #200, epoch #200, avg. train loss: 1579395.62500\n",
      "Step #100, epoch #33, avg. train loss: 3234347.25000\n",
      "Step #200, epoch #66, avg. train loss: 1522846.50000\n",
      "Step #100, epoch #33, avg. train loss: 3148431.00000\n",
      "Step #200, epoch #66, avg. train loss: 1529156.62500\n",
      "Step #100, epoch #33, avg. train loss: 2931444.25000\n",
      "Step #200, epoch #66, avg. train loss: 1616177.62500\n",
      "Step #100, epoch #100, avg. train loss: 2848724.25000\n",
      "Step #200, epoch #200, avg. train loss: 1539318.12500\n",
      "Step #100, epoch #100, avg. train loss: 2833725.50000\n",
      "Step #200, epoch #200, avg. train loss: 1474654.25000\n",
      "Step #100, epoch #100, avg. train loss: 2775580.50000\n",
      "Step #200, epoch #200, avg. train loss: 1526300.75000\n",
      "Step #100, epoch #50, avg. train loss: 2335002.00000\n",
      "Step #200, epoch #100, avg. train loss: 1522216.62500\n",
      "Step #100, epoch #50, avg. train loss: 2454352.75000\n",
      "Step #200, epoch #100, avg. train loss: 1536469.50000\n",
      "Step #100, epoch #50, avg. train loss: 2565882.00000\n",
      "Step #200, epoch #100, avg. train loss: 1997760.75000\n",
      "Step #100, epoch #100, avg. train loss: 2173620.25000\n",
      "Step #200, epoch #200, avg. train loss: 1590645.25000\n",
      "Step #100, epoch #100, avg. train loss: 2095661.50000\n",
      "Step #200, epoch #200, avg. train loss: 1400801.25000\n",
      "Step #100, epoch #100, avg. train loss: 2155021.00000\n",
      "Step #200, epoch #200, avg. train loss: 1516320.75000\n",
      "Step #100, epoch #100, avg. train loss: 4301505.00000\n",
      "Step #200, epoch #200, avg. train loss: 1762957.00000\n",
      "Step #100, epoch #100, avg. train loss: 4352100.00000\n",
      "Step #200, epoch #200, avg. train loss: 1677235.37500\n",
      "Step #100, epoch #100, avg. train loss: 4223578.00000\n",
      "Step #200, epoch #200, avg. train loss: 1788933.75000\n",
      "Step #100, epoch #33, avg. train loss: 2080349.75000\n",
      "Step #200, epoch #66, avg. train loss: 1714104.00000\n",
      "Step #100, epoch #33, avg. train loss: 2112165.50000\n",
      "Step #200, epoch #66, avg. train loss: 1675615.00000\n",
      "Step #100, epoch #33, avg. train loss: 2281609.00000\n",
      "Step #200, epoch #66, avg. train loss: 1774915.50000\n",
      "Step #100, epoch #100, avg. train loss: 2132306.00000\n",
      "Step #200, epoch #200, avg. train loss: 1539351.25000\n",
      "Step #100, epoch #100, avg. train loss: 2054626.75000\n",
      "Step #200, epoch #200, avg. train loss: 1490757.50000\n",
      "Step #100, epoch #100, avg. train loss: 2141732.25000\n",
      "Step #200, epoch #200, avg. train loss: 1565264.50000\n",
      "Step #100, epoch #100, avg. train loss: 2676439.00000\n",
      "Step #200, epoch #200, avg. train loss: 1579081.25000\n",
      "Step #100, epoch #100, avg. train loss: 2589020.75000\n",
      "Step #200, epoch #200, avg. train loss: 1536452.75000\n",
      "Step #100, epoch #100, avg. train loss: 2676413.75000\n",
      "Step #200, epoch #200, avg. train loss: 1582294.37500\n",
      "Step #100, epoch #11, avg. train loss: 2219607.25000\n",
      "Step #200, epoch #22, avg. train loss: 1712561.25000\n",
      "Step #100, epoch #11, avg. train loss: 2092470.12500\n",
      "Step #200, epoch #22, avg. train loss: 1654431.00000\n",
      "Step #100, epoch #11, avg. train loss: 2203280.25000\n",
      "Step #200, epoch #22, avg. train loss: 1683542.12500\n",
      "Step #100, epoch #100, avg. train loss: 3572249.00000\n",
      "Step #200, epoch #200, avg. train loss: 1542336.75000\n",
      "Step #100, epoch #100, avg. train loss: 3629105.00000\n",
      "Step #200, epoch #200, avg. train loss: 1467926.87500\n",
      "Step #100, epoch #100, avg. train loss: 3572327.25000\n",
      "Step #200, epoch #200, avg. train loss: 1506853.12500\n",
      "Step #100, epoch #100, avg. train loss: 2079531.37500\n",
      "Step #200, epoch #200, avg. train loss: 1612892.62500\n",
      "Step #100, epoch #100, avg. train loss: 2001797.87500\n",
      "Step #200, epoch #200, avg. train loss: 1546037.50000\n",
      "Step #100, epoch #100, avg. train loss: 2086943.37500\n",
      "Step #200, epoch #200, avg. train loss: 1614921.87500\n",
      "Step #100, epoch #100, avg. train loss: 2398055.25000\n",
      "Step #200, epoch #200, avg. train loss: 1547025.50000\n",
      "Step #100, epoch #100, avg. train loss: 2314352.75000\n",
      "Step #200, epoch #200, avg. train loss: 1621963.37500\n",
      "Step #100, epoch #100, avg. train loss: 2386983.25000\n",
      "Step #200, epoch #200, avg. train loss: 1507057.50000\n",
      "Step #100, epoch #100, avg. train loss: 2658593.25000\n",
      "Step #200, epoch #200, avg. train loss: 1605628.00000\n",
      "Step #100, epoch #100, avg. train loss: 3271380.25000\n",
      "Step #200, epoch #200, avg. train loss: 1711224.37500\n",
      "Step #100, epoch #100, avg. train loss: 2569898.00000\n",
      "Step #200, epoch #200, avg. train loss: 1780079.25000\n",
      "Step #100, epoch #50, avg. train loss: 2988145.00000\n",
      "Step #200, epoch #100, avg. train loss: 1788310.50000\n",
      "Step #100, epoch #50, avg. train loss: 2971436.25000\n",
      "Step #200, epoch #100, avg. train loss: 1700168.00000\n",
      "Step #100, epoch #50, avg. train loss: 2955742.50000\n",
      "Step #200, epoch #100, avg. train loss: 1822765.62500\n",
      "Step #100, epoch #33, avg. train loss: 2123043.25000\n",
      "Step #200, epoch #66, avg. train loss: 1504323.00000\n",
      "Step #100, epoch #33, avg. train loss: 2047609.87500\n",
      "Step #200, epoch #66, avg. train loss: 1552601.00000\n",
      "Step #100, epoch #33, avg. train loss: 2119434.25000\n",
      "Step #200, epoch #66, avg. train loss: 1550490.37500\n",
      "Step #100, epoch #100, avg. train loss: 2276072.25000\n",
      "Step #200, epoch #200, avg. train loss: 1456317.87500\n",
      "Step #100, epoch #100, avg. train loss: 2223458.00000\n",
      "Step #200, epoch #200, avg. train loss: 1339127.00000\n",
      "Step #100, epoch #100, avg. train loss: 2318227.25000\n",
      "Step #200, epoch #200, avg. train loss: 1453288.50000\n",
      "Step #100, epoch #50, avg. train loss: 2241535.75000\n",
      "Step #200, epoch #100, avg. train loss: 1496549.62500\n",
      "Step #100, epoch #50, avg. train loss: 2167343.25000\n",
      "Step #200, epoch #100, avg. train loss: 1501467.50000\n",
      "Step #100, epoch #50, avg. train loss: 2332697.75000\n",
      "Step #200, epoch #100, avg. train loss: 1518552.37500\n",
      "Step #100, epoch #50, avg. train loss: 2161769.75000\n",
      "Step #200, epoch #100, avg. train loss: 1581463.87500\n",
      "Step #100, epoch #50, avg. train loss: 2114563.00000\n",
      "Step #200, epoch #100, avg. train loss: 1516721.50000\n",
      "Step #100, epoch #50, avg. train loss: 2149349.00000\n",
      "Step #200, epoch #100, avg. train loss: 1507932.00000\n",
      "Step #100, epoch #100, avg. train loss: 2189583.75000\n",
      "Step #200, epoch #200, avg. train loss: 1660740.37500\n",
      "Step #100, epoch #100, avg. train loss: 2131494.50000\n",
      "Step #200, epoch #200, avg. train loss: 1601753.12500\n",
      "Step #100, epoch #100, avg. train loss: 2188000.75000\n",
      "Step #200, epoch #200, avg. train loss: 1658843.25000\n",
      "Step #100, epoch #12, avg. train loss: 2168592.25000\n",
      "Step #200, epoch #25, avg. train loss: 1626224.50000\n",
      "Step #100, epoch #12, avg. train loss: 2129046.00000\n",
      "Step #200, epoch #25, avg. train loss: 1580033.12500\n",
      "Step #100, epoch #12, avg. train loss: 2110537.50000\n",
      "Step #200, epoch #25, avg. train loss: 1577447.50000\n",
      "Step #100, epoch #100, avg. train loss: 2061418.25000\n",
      "Step #200, epoch #200, avg. train loss: 1546675.37500\n",
      "Step #100, epoch #100, avg. train loss: 1982165.12500\n",
      "Step #200, epoch #200, avg. train loss: 1447085.25000\n",
      "Step #100, epoch #100, avg. train loss: 2076268.50000\n",
      "Step #200, epoch #200, avg. train loss: 1562748.50000\n",
      "Step #100, epoch #100, avg. train loss: 3204266.25000\n",
      "Step #200, epoch #200, avg. train loss: 1585793.00000\n",
      "Step #100, epoch #100, avg. train loss: 3055509.50000\n",
      "Step #200, epoch #200, avg. train loss: 1530607.50000\n",
      "Step #100, epoch #100, avg. train loss: 3159328.25000\n",
      "Step #200, epoch #200, avg. train loss: 1544171.25000\n",
      "Step #100, epoch #100, avg. train loss: 2058814.25000\n",
      "Step #200, epoch #200, avg. train loss: 1575218.12500\n",
      "Step #100, epoch #100, avg. train loss: 1978743.62500\n",
      "Step #200, epoch #200, avg. train loss: 1504951.37500\n",
      "Step #100, epoch #100, avg. train loss: 2050581.50000\n",
      "Step #200, epoch #200, avg. train loss: 1486659.87500\n",
      "Step #100, epoch #8, avg. train loss: 2270181.00000\n",
      "Step #200, epoch #16, avg. train loss: 1624734.75000\n",
      "Step #100, epoch #8, avg. train loss: 2208310.00000\n",
      "Step #200, epoch #16, avg. train loss: 1575192.62500\n",
      "Step #100, epoch #8, avg. train loss: 2186081.50000\n",
      "Step #200, epoch #16, avg. train loss: 1659984.12500\n",
      "Step #100, epoch #100, avg. train loss: 2239702.50000\n",
      "Step #200, epoch #200, avg. train loss: 1535492.37500\n",
      "Step #100, epoch #100, avg. train loss: 2141971.75000\n",
      "Step #200, epoch #200, avg. train loss: 1545772.12500\n",
      "Step #100, epoch #100, avg. train loss: 2267874.00000\n",
      "Step #200, epoch #200, avg. train loss: 1533957.62500\n",
      "Step #100, epoch #100, avg. train loss: 2796139.50000\n",
      "Step #200, epoch #200, avg. train loss: 1577295.00000\n",
      "Step #100, epoch #100, avg. train loss: 2735498.25000\n",
      "Step #200, epoch #200, avg. train loss: 1533248.12500\n",
      "Step #100, epoch #100, avg. train loss: 2778632.25000\n",
      "Step #200, epoch #200, avg. train loss: 1545524.50000\n",
      "Step #100, epoch #50, avg. train loss: 2144706.50000\n",
      "Step #200, epoch #100, avg. train loss: 1676467.87500\n",
      "Step #100, epoch #50, avg. train loss: 2238720.25000\n",
      "Step #200, epoch #100, avg. train loss: 1596531.62500\n",
      "Step #100, epoch #50, avg. train loss: 2281067.75000\n",
      "Step #200, epoch #100, avg. train loss: 1762105.25000\n",
      "Step #100, epoch #100, avg. train loss: 3649989.75000\n",
      "Step #200, epoch #200, avg. train loss: 1540875.62500\n",
      "Step #100, epoch #100, avg. train loss: 3461685.00000\n",
      "Step #200, epoch #200, avg. train loss: 1612000.00000\n",
      "Step #100, epoch #100, avg. train loss: 3485622.50000\n",
      "Step #200, epoch #200, avg. train loss: 1509854.12500\n",
      "Step #100, epoch #50, avg. train loss: 3222939.50000\n",
      "Step #200, epoch #100, avg. train loss: 1526510.37500\n",
      "Step #100, epoch #50, avg. train loss: 3154471.25000\n",
      "Step #200, epoch #100, avg. train loss: 1530445.75000\n",
      "Step #100, epoch #50, avg. train loss: 3228306.25000\n",
      "Step #200, epoch #100, avg. train loss: 1536271.87500\n",
      "Step #100, epoch #50, avg. train loss: 2990619.50000\n",
      "Step #200, epoch #100, avg. train loss: 1486545.12500\n",
      "Step #100, epoch #50, avg. train loss: 2717203.25000\n",
      "Step #200, epoch #100, avg. train loss: 1630905.62500\n",
      "Step #100, epoch #50, avg. train loss: 2730402.50000\n",
      "Step #200, epoch #100, avg. train loss: 1555500.00000\n",
      "Step #100, epoch #100, avg. train loss: 2830397.75000\n",
      "Step #200, epoch #200, avg. train loss: 1589075.25000\n",
      "Step #100, epoch #100, avg. train loss: 2842053.50000\n",
      "Step #200, epoch #200, avg. train loss: 1497440.62500\n",
      "Step #100, epoch #100, avg. train loss: 2844963.75000\n",
      "Step #200, epoch #200, avg. train loss: 1517593.00000\n",
      "Step #100, epoch #20, avg. train loss: 2241255.00000\n",
      "Step #200, epoch #40, avg. train loss: 1592113.62500\n",
      "Step #100, epoch #20, avg. train loss: 2174331.00000\n",
      "Step #200, epoch #40, avg. train loss: 1497563.87500\n",
      "Step #100, epoch #20, avg. train loss: 2264607.75000\n",
      "Step #200, epoch #40, avg. train loss: 1588102.87500\n",
      "Step #100, epoch #33, avg. train loss: 3022164.25000\n",
      "Step #200, epoch #66, avg. train loss: 1597221.00000\n",
      "Step #100, epoch #33, avg. train loss: 2928345.50000\n",
      "Step #200, epoch #66, avg. train loss: 1476892.50000\n",
      "Step #100, epoch #33, avg. train loss: 2840843.50000\n",
      "Step #200, epoch #66, avg. train loss: 1487319.00000\n",
      "Step #100, epoch #100, avg. train loss: 2747770.00000\n",
      "Step #200, epoch #200, avg. train loss: 1671527.50000\n",
      "Step #100, epoch #100, avg. train loss: 2709749.75000\n",
      "Step #200, epoch #200, avg. train loss: 1509172.12500\n",
      "Step #100, epoch #100, avg. train loss: 2848660.25000\n",
      "Step #200, epoch #200, avg. train loss: 1598958.87500\n",
      "Step #100, epoch #20, avg. train loss: 3159488.00000\n",
      "Step #200, epoch #40, avg. train loss: 1596228.00000\n",
      "Step #100, epoch #20, avg. train loss: 2999059.25000\n",
      "Step #200, epoch #40, avg. train loss: 1567337.62500\n",
      "Step #100, epoch #20, avg. train loss: 3038170.00000\n",
      "Step #200, epoch #40, avg. train loss: 1510263.37500\n",
      "Step #100, epoch #20, avg. train loss: 3046381.75000\n",
      "Step #200, epoch #40, avg. train loss: 1526658.50000\n",
      "Step #100, epoch #20, avg. train loss: 3028054.50000\n",
      "Step #200, epoch #40, avg. train loss: 1511827.25000\n",
      "Step #100, epoch #20, avg. train loss: 2941847.25000\n",
      "Step #200, epoch #40, avg. train loss: 1506790.87500\n",
      "Step #100, epoch #100, avg. train loss: 2910165.00000\n",
      "Step #200, epoch #200, avg. train loss: 1564477.50000\n",
      "Step #100, epoch #100, avg. train loss: 2864787.25000\n",
      "Step #200, epoch #200, avg. train loss: 1479412.37500\n",
      "Step #100, epoch #100, avg. train loss: 2960135.00000\n",
      "Step #200, epoch #200, avg. train loss: 1645316.50000\n",
      "Step #100, epoch #100, avg. train loss: 2150563.75000\n",
      "Step #200, epoch #200, avg. train loss: 1576528.00000\n",
      "Step #100, epoch #100, avg. train loss: 2093691.62500\n",
      "Step #200, epoch #200, avg. train loss: 1574836.00000\n",
      "Step #100, epoch #100, avg. train loss: 2163898.25000\n",
      "Step #200, epoch #200, avg. train loss: 1572247.37500\n",
      "Step #100, epoch #100, avg. train loss: 2079428.12500\n",
      "Step #200, epoch #200, avg. train loss: 1584380.50000\n",
      "Step #100, epoch #100, avg. train loss: 2032653.50000\n",
      "Step #200, epoch #200, avg. train loss: 1543422.37500\n",
      "Step #100, epoch #100, avg. train loss: 2089115.87500\n",
      "Step #200, epoch #200, avg. train loss: 1588741.00000\n",
      "Step #100, epoch #16, avg. train loss: 2766659.00000\n",
      "Step #200, epoch #33, avg. train loss: 1599727.87500\n",
      "Step #100, epoch #16, avg. train loss: 2906922.50000\n",
      "Step #200, epoch #33, avg. train loss: 1513505.87500\n",
      "Step #100, epoch #16, avg. train loss: 2478884.75000\n",
      "Step #200, epoch #33, avg. train loss: 1665618.87500\n",
      "Step #100, epoch #100, avg. train loss: 2051352.50000\n",
      "Step #200, epoch #200, avg. train loss: 1554638.12500\n",
      "Step #100, epoch #100, avg. train loss: 1969647.00000\n",
      "Step #200, epoch #200, avg. train loss: 1485991.25000\n",
      "Step #100, epoch #100, avg. train loss: 2060536.75000\n",
      "Step #200, epoch #200, avg. train loss: 1537331.62500\n",
      "Step #100, epoch #100, avg. train loss: 2103203.25000\n",
      "Step #200, epoch #200, avg. train loss: 1606891.25000\n",
      "Step #100, epoch #100, avg. train loss: 2014872.00000\n",
      "Step #200, epoch #200, avg. train loss: 1492663.50000\n",
      "Step #100, epoch #100, avg. train loss: 2103560.25000\n",
      "Step #200, epoch #200, avg. train loss: 1739428.75000\n",
      "Step #100, epoch #14, avg. train loss: 2658627.50000\n",
      "Step #200, epoch #28, avg. train loss: 1808916.75000\n",
      "Step #100, epoch #14, avg. train loss: 2602256.25000\n",
      "Step #200, epoch #28, avg. train loss: 1714885.25000\n",
      "Step #100, epoch #14, avg. train loss: 2642665.50000\n",
      "Step #200, epoch #28, avg. train loss: 1823337.25000\n",
      "Step #100, epoch #50, avg. train loss: 2283620.25000\n",
      "Step #200, epoch #100, avg. train loss: 1534173.62500\n",
      "Step #100, epoch #50, avg. train loss: 2134234.50000\n",
      "Step #200, epoch #100, avg. train loss: 1469293.12500\n",
      "Step #100, epoch #50, avg. train loss: 2211701.50000\n",
      "Step #200, epoch #100, avg. train loss: 1542490.87500\n",
      "Step #100, epoch #33, avg. train loss: 2263178.25000\n",
      "Step #200, epoch #66, avg. train loss: 1774699.37500\n",
      "Step #100, epoch #33, avg. train loss: 2197606.00000\n",
      "Step #200, epoch #66, avg. train loss: 1636281.75000\n",
      "Step #100, epoch #33, avg. train loss: 2274857.50000\n",
      "Step #200, epoch #66, avg. train loss: 1747668.00000\n",
      "Step #100, epoch #100, avg. train loss: 2159437.00000\n",
      "Step #200, epoch #200, avg. train loss: 1514461.00000\n",
      "Step #100, epoch #100, avg. train loss: 2110196.25000\n",
      "Step #200, epoch #200, avg. train loss: 1490479.62500\n",
      "Step #100, epoch #100, avg. train loss: 2173074.00000\n",
      "Step #200, epoch #200, avg. train loss: 1509347.37500\n",
      "Step #100, epoch #100, avg. train loss: 2108960.75000\n",
      "Step #200, epoch #200, avg. train loss: 1607260.62500\n",
      "Step #100, epoch #100, avg. train loss: 2039867.62500\n",
      "Step #200, epoch #200, avg. train loss: 1543378.75000\n",
      "Step #100, epoch #100, avg. train loss: 2096607.00000\n",
      "Step #200, epoch #200, avg. train loss: 1536421.12500\n",
      "Step #100, epoch #50, avg. train loss: 2141546.50000\n",
      "Step #200, epoch #100, avg. train loss: 1575464.00000\n",
      "Step #100, epoch #50, avg. train loss: 2009946.25000\n",
      "Step #200, epoch #100, avg. train loss: 1479161.50000\n",
      "Step #100, epoch #50, avg. train loss: 2110761.50000\n",
      "Step #200, epoch #100, avg. train loss: 1499729.62500\n",
      "Step #100, epoch #100, avg. train loss: 2280879.75000\n",
      "Step #200, epoch #200, avg. train loss: 1711040.12500\n",
      "Step #100, epoch #100, avg. train loss: 2212221.50000\n",
      "Step #200, epoch #200, avg. train loss: 1621805.12500\n",
      "Step #100, epoch #100, avg. train loss: 2281109.25000\n",
      "Step #200, epoch #200, avg. train loss: 1716939.50000\n",
      "Step #100, epoch #33, avg. train loss: 2624642.25000\n",
      "Step #200, epoch #66, avg. train loss: 1544184.75000\n",
      "Step #100, epoch #33, avg. train loss: 2550775.00000\n",
      "Step #200, epoch #66, avg. train loss: 1527830.12500\n",
      "Step #100, epoch #33, avg. train loss: 2667000.25000\n",
      "Step #200, epoch #66, avg. train loss: 1637188.50000\n",
      "Step #100, epoch #50, avg. train loss: 3897740.75000\n",
      "Step #200, epoch #100, avg. train loss: 1523449.12500\n",
      "Step #100, epoch #50, avg. train loss: 3826730.25000\n",
      "Step #200, epoch #100, avg. train loss: 1487536.75000\n",
      "Step #100, epoch #50, avg. train loss: 3962834.50000\n",
      "Step #200, epoch #100, avg. train loss: 1469023.62500\n",
      "Step #100, epoch #100, avg. train loss: 3833276.50000\n",
      "Step #200, epoch #200, avg. train loss: 1545332.75000\n",
      "Step #100, epoch #100, avg. train loss: 3968717.75000\n",
      "Step #200, epoch #200, avg. train loss: 1379128.75000\n",
      "Step #100, epoch #100, avg. train loss: 3833728.75000\n",
      "Step #200, epoch #200, avg. train loss: 1472471.62500\n",
      "Step #100, epoch #20, avg. train loss: 10627285.00000\n",
      "Step #200, epoch #40, avg. train loss: 7575159.50000\n",
      "Step #100, epoch #20, avg. train loss: 11085585.00000\n",
      "Step #200, epoch #40, avg. train loss: 7762989.00000\n",
      "Step #100, epoch #20, avg. train loss: 10390313.00000\n",
      "Step #200, epoch #40, avg. train loss: 7431293.50000\n",
      "Step #100, epoch #33, avg. train loss: 2959792.00000\n",
      "Step #200, epoch #66, avg. train loss: 1514133.50000\n",
      "Step #100, epoch #33, avg. train loss: 2832543.75000\n",
      "Step #200, epoch #66, avg. train loss: 1470128.12500\n",
      "Step #100, epoch #33, avg. train loss: 3096310.75000\n",
      "Step #200, epoch #66, avg. train loss: 1487292.75000\n",
      "Step #100, epoch #100, avg. train loss: 2319901.50000\n",
      "Step #200, epoch #200, avg. train loss: 1558192.00000\n",
      "Step #100, epoch #100, avg. train loss: 2256460.25000\n",
      "Step #200, epoch #200, avg. train loss: 1421557.25000\n",
      "Step #100, epoch #100, avg. train loss: 2341501.00000\n",
      "Step #200, epoch #200, avg. train loss: 1485200.00000\n",
      "Step #100, epoch #100, avg. train loss: 3649329.50000\n",
      "Step #200, epoch #200, avg. train loss: 1651973.25000\n",
      "Step #100, epoch #100, avg. train loss: 3672239.75000\n",
      "Step #200, epoch #200, avg. train loss: 1589175.62500\n",
      "Step #100, epoch #100, avg. train loss: 3300677.75000\n",
      "Step #200, epoch #200, avg. train loss: 1605825.87500\n",
      "Step #100, epoch #10, avg. train loss: 3162974.00000\n",
      "Step #200, epoch #20, avg. train loss: 1553026.12500\n",
      "Step #100, epoch #10, avg. train loss: 2857022.00000\n",
      "Step #200, epoch #20, avg. train loss: 1545550.12500\n",
      "Step #100, epoch #10, avg. train loss: 3254291.50000\n",
      "Step #200, epoch #20, avg. train loss: 1521518.12500\n",
      "Step #100, epoch #100, avg. train loss: 2115107.00000\n",
      "Step #200, epoch #200, avg. train loss: 1603439.37500\n",
      "Step #100, epoch #100, avg. train loss: 2049401.62500\n",
      "Step #200, epoch #200, avg. train loss: 1529542.12500\n",
      "Step #100, epoch #100, avg. train loss: 2138685.50000\n",
      "Step #200, epoch #200, avg. train loss: 1670756.50000\n",
      "Step #100, epoch #100, avg. train loss: 2068721.12500\n",
      "Step #200, epoch #200, avg. train loss: 1580359.25000\n",
      "Step #100, epoch #100, avg. train loss: 1989547.00000\n",
      "Step #200, epoch #200, avg. train loss: 1534829.75000\n",
      "Step #100, epoch #100, avg. train loss: 2083323.37500\n",
      "Step #200, epoch #200, avg. train loss: 1572651.50000\n",
      "Step #100, epoch #50, avg. train loss: 2219108.25000\n",
      "Step #200, epoch #100, avg. train loss: 1488073.25000\n",
      "Step #100, epoch #50, avg. train loss: 2181728.00000\n",
      "Step #200, epoch #100, avg. train loss: 1561710.75000\n",
      "Step #100, epoch #50, avg. train loss: 2245389.50000\n",
      "Step #200, epoch #100, avg. train loss: 1607008.75000\n",
      "Step #100, epoch #100, avg. train loss: 2262707.75000\n",
      "Step #200, epoch #200, avg. train loss: 1616376.00000\n",
      "Step #100, epoch #100, avg. train loss: 2145246.00000\n",
      "Step #200, epoch #200, avg. train loss: 1516609.75000\n",
      "Step #100, epoch #100, avg. train loss: 2204595.25000\n",
      "Step #200, epoch #200, avg. train loss: 1490356.75000\n",
      "Step #100, epoch #50, avg. train loss: 2110752.00000\n",
      "Step #200, epoch #100, avg. train loss: 1686204.50000\n",
      "Step #100, epoch #50, avg. train loss: 2016871.87500\n",
      "Step #200, epoch #100, avg. train loss: 1573049.12500\n",
      "Step #100, epoch #50, avg. train loss: 2105222.25000\n",
      "Step #200, epoch #100, avg. train loss: 1644762.87500\n",
      "Step #100, epoch #33, avg. train loss: 2871322.50000\n",
      "Step #200, epoch #66, avg. train loss: 1483723.50000\n",
      "Step #100, epoch #33, avg. train loss: 2900327.25000\n",
      "Step #200, epoch #66, avg. train loss: 1489654.75000\n",
      "Step #100, epoch #33, avg. train loss: 2954519.00000\n",
      "Step #200, epoch #66, avg. train loss: 1446248.00000\n",
      "Step #100, epoch #100, avg. train loss: 2907893.00000\n",
      "Step #200, epoch #200, avg. train loss: 1522885.50000\n",
      "Step #100, epoch #100, avg. train loss: 2826361.50000\n",
      "Step #200, epoch #200, avg. train loss: 1472303.00000\n",
      "Step #100, epoch #100, avg. train loss: 2856364.25000\n",
      "Step #200, epoch #200, avg. train loss: 1512214.12500\n",
      "Step #100, epoch #100, avg. train loss: 2862003.75000\n",
      "Step #200, epoch #200, avg. train loss: 1519873.75000\n",
      "Step #100, epoch #100, avg. train loss: 2798714.25000\n",
      "Step #200, epoch #200, avg. train loss: 1461377.62500\n",
      "Step #100, epoch #100, avg. train loss: 2904557.50000\n",
      "Step #200, epoch #200, avg. train loss: 1634681.50000\n",
      "Step #100, epoch #100, avg. train loss: 2219275.25000\n",
      "Step #200, epoch #200, avg. train loss: 1477683.37500\n",
      "Step #100, epoch #100, avg. train loss: 2198113.00000\n",
      "Step #200, epoch #200, avg. train loss: 1370565.00000\n",
      "Step #100, epoch #100, avg. train loss: 2267940.75000\n",
      "Step #200, epoch #200, avg. train loss: 1513991.87500\n",
      "Step #100, epoch #33, avg. train loss: 4089900.75000\n",
      "Step #200, epoch #66, avg. train loss: 1806718.25000\n",
      "Step #100, epoch #33, avg. train loss: 4232185.00000\n",
      "Step #200, epoch #66, avg. train loss: 1733573.87500\n",
      "Step #100, epoch #33, avg. train loss: 4035400.25000\n",
      "Step #200, epoch #66, avg. train loss: 1839787.62500\n",
      "Step #100, epoch #33, avg. train loss: 2542650.50000\n",
      "Step #200, epoch #66, avg. train loss: 1499522.87500\n",
      "Step #100, epoch #33, avg. train loss: 2425359.75000\n",
      "Step #200, epoch #66, avg. train loss: 1519174.87500\n",
      "Step #100, epoch #33, avg. train loss: 2554027.25000\n",
      "Step #200, epoch #66, avg. train loss: 1532152.62500\n",
      "Step #100, epoch #33, avg. train loss: 2827040.25000\n",
      "Step #200, epoch #66, avg. train loss: 1585366.50000\n",
      "Step #100, epoch #33, avg. train loss: 2758733.00000\n",
      "Step #200, epoch #66, avg. train loss: 1545789.00000\n",
      "Step #100, epoch #33, avg. train loss: 2826313.50000\n",
      "Step #200, epoch #66, avg. train loss: 1522020.62500\n",
      "Step #100, epoch #100, avg. train loss: 9358633.00000\n",
      "Step #200, epoch #200, avg. train loss: 6101292.00000\n",
      "Step #100, epoch #100, avg. train loss: 9615220.00000\n",
      "Step #200, epoch #200, avg. train loss: 6057935.50000\n",
      "Step #100, epoch #100, avg. train loss: 9088765.00000\n",
      "Step #200, epoch #200, avg. train loss: 5723144.50000\n",
      "Step #100, epoch #50, avg. train loss: 2157595.00000\n",
      "Step #200, epoch #100, avg. train loss: 1634653.87500\n",
      "Step #100, epoch #50, avg. train loss: 2166034.50000\n",
      "Step #200, epoch #100, avg. train loss: 1533260.75000\n",
      "Step #100, epoch #50, avg. train loss: 2216052.75000\n",
      "Step #200, epoch #100, avg. train loss: 1673646.87500\n",
      "Step #100, epoch #100, avg. train loss: 2549909.25000\n",
      "Step #200, epoch #200, avg. train loss: 1493661.50000\n",
      "Step #100, epoch #100, avg. train loss: 2457851.00000\n",
      "Step #200, epoch #200, avg. train loss: 1466653.75000\n",
      "Step #100, epoch #100, avg. train loss: 2561545.00000\n",
      "Step #200, epoch #200, avg. train loss: 1555106.87500\n",
      "Step #100, epoch #100, avg. train loss: 2338201.50000\n",
      "Step #200, epoch #200, avg. train loss: 1558169.62500\n",
      "Step #100, epoch #100, avg. train loss: 2242876.25000\n",
      "Step #200, epoch #200, avg. train loss: 1413776.00000\n",
      "Step #100, epoch #100, avg. train loss: 2348682.00000\n",
      "Step #200, epoch #200, avg. train loss: 1545973.00000\n",
      "Step #100, epoch #100, avg. train loss: 2818356.50000\n",
      "Step #200, epoch #200, avg. train loss: 1753775.87500\n",
      "Step #100, epoch #100, avg. train loss: 2792784.75000\n",
      "Step #200, epoch #200, avg. train loss: 1665001.87500\n",
      "Step #100, epoch #100, avg. train loss: 2807355.25000\n",
      "Step #200, epoch #200, avg. train loss: 1799002.37500\n",
      "Step #100, epoch #20, avg. train loss: 3927830.00000\n",
      "Step #200, epoch #40, avg. train loss: 1658621.50000\n",
      "Step #100, epoch #20, avg. train loss: 3498306.25000\n",
      "Step #200, epoch #40, avg. train loss: 1713358.50000\n",
      "Step #100, epoch #20, avg. train loss: 3888995.25000\n",
      "Step #200, epoch #40, avg. train loss: 1584800.37500\n",
      "Step #100, epoch #100, avg. train loss: 2253085.50000\n",
      "Step #200, epoch #200, avg. train loss: 1427687.00000\n",
      "Step #100, epoch #100, avg. train loss: 2167443.25000\n",
      "Step #200, epoch #200, avg. train loss: 1557539.00000\n",
      "Step #100, epoch #100, avg. train loss: 2198022.50000\n",
      "Step #200, epoch #200, avg. train loss: 1575325.87500\n",
      "Step #100, epoch #100, avg. train loss: 2640231.25000\n",
      "Step #200, epoch #200, avg. train loss: 1517716.00000\n",
      "Step #100, epoch #100, avg. train loss: 2546234.00000\n",
      "Step #200, epoch #200, avg. train loss: 1466496.12500\n",
      "Step #100, epoch #100, avg. train loss: 2673133.50000\n",
      "Step #200, epoch #200, avg. train loss: 1574491.37500\n",
      "Step #100, epoch #100, avg. train loss: 2852059.50000\n",
      "Step #200, epoch #200, avg. train loss: 1524912.50000\n",
      "Step #100, epoch #100, avg. train loss: 2774754.00000\n",
      "Step #200, epoch #200, avg. train loss: 1465801.87500\n",
      "Step #100, epoch #100, avg. train loss: 2869682.00000\n",
      "Step #200, epoch #200, avg. train loss: 1516518.37500\n",
      "Step #100, epoch #100, avg. train loss: 2905481.25000\n",
      "Step #200, epoch #200, avg. train loss: 1608711.00000\n",
      "Step #100, epoch #100, avg. train loss: 2807994.25000\n",
      "Step #200, epoch #200, avg. train loss: 1486458.50000\n",
      "Step #100, epoch #100, avg. train loss: 2793786.50000\n",
      "Step #200, epoch #200, avg. train loss: 1507047.37500\n",
      "Step #100, epoch #100, avg. train loss: 3224529.50000\n",
      "Step #200, epoch #200, avg. train loss: 1653194.87500\n",
      "Step #100, epoch #100, avg. train loss: 3148504.25000\n",
      "Step #200, epoch #200, avg. train loss: 1513909.62500\n",
      "Step #100, epoch #100, avg. train loss: 3171986.00000\n",
      "Step #200, epoch #200, avg. train loss: 1570780.00000\n",
      "Step #100, epoch #100, avg. train loss: 2150916.25000\n",
      "Step #200, epoch #200, avg. train loss: 1660806.50000\n",
      "Step #100, epoch #100, avg. train loss: 2052036.12500\n",
      "Step #200, epoch #200, avg. train loss: 1405990.50000\n",
      "Step #100, epoch #100, avg. train loss: 2144510.50000\n",
      "Step #200, epoch #200, avg. train loss: 1545141.62500\n",
      "Step #100, epoch #100, avg. train loss: 2118482.00000\n",
      "Step #200, epoch #200, avg. train loss: 1557500.37500\n",
      "Step #100, epoch #100, avg. train loss: 2048873.12500\n",
      "Step #200, epoch #200, avg. train loss: 1496259.25000\n",
      "Step #100, epoch #100, avg. train loss: 2117036.75000\n",
      "Step #200, epoch #200, avg. train loss: 1512029.50000\n",
      "Step #100, epoch #50, avg. train loss: 2913030.75000\n",
      "Step #200, epoch #100, avg. train loss: 1497841.87500\n",
      "Step #100, epoch #50, avg. train loss: 2807627.75000\n",
      "Step #200, epoch #100, avg. train loss: 1400475.37500\n",
      "Step #100, epoch #50, avg. train loss: 2809711.75000\n",
      "Step #200, epoch #100, avg. train loss: 1484329.00000\n",
      "Step #100, epoch #50, avg. train loss: 2079535.37500\n",
      "Step #200, epoch #100, avg. train loss: 1543737.12500\n",
      "Step #100, epoch #50, avg. train loss: 2032164.12500\n",
      "Step #200, epoch #100, avg. train loss: 1548645.00000\n",
      "Step #100, epoch #50, avg. train loss: 2108624.00000\n",
      "Step #200, epoch #100, avg. train loss: 1527920.50000\n",
      "Step #100, epoch #100, avg. train loss: 2883092.25000\n",
      "Step #200, epoch #200, avg. train loss: 1482854.25000\n",
      "Step #100, epoch #100, avg. train loss: 2810886.50000\n",
      "Step #200, epoch #200, avg. train loss: 1495159.62500\n",
      "Step #100, epoch #100, avg. train loss: 2859888.25000\n",
      "Step #200, epoch #200, avg. train loss: 1504781.12500\n",
      "Step #100, epoch #50, avg. train loss: 2993806.50000\n",
      "Step #200, epoch #100, avg. train loss: 1583576.00000\n",
      "Step #100, epoch #50, avg. train loss: 2973673.00000\n",
      "Step #200, epoch #100, avg. train loss: 1525111.37500\n",
      "Step #100, epoch #50, avg. train loss: 2957303.75000\n",
      "Step #200, epoch #100, avg. train loss: 1523731.00000\n",
      "Step #100, epoch #50, avg. train loss: 2169887.50000\n",
      "Step #200, epoch #100, avg. train loss: 1688232.12500\n",
      "Step #100, epoch #50, avg. train loss: 2110389.75000\n",
      "Step #200, epoch #100, avg. train loss: 1628567.87500\n",
      "Step #100, epoch #50, avg. train loss: 2184404.75000\n",
      "Step #200, epoch #100, avg. train loss: 1717838.87500\n",
      "Step #100, epoch #100, avg. train loss: 2124477.50000\n",
      "Step #200, epoch #200, avg. train loss: 1518209.12500\n",
      "Step #100, epoch #100, avg. train loss: 2047005.75000\n",
      "Step #200, epoch #200, avg. train loss: 1479405.00000\n",
      "Step #100, epoch #100, avg. train loss: 2134133.50000\n",
      "Step #200, epoch #200, avg. train loss: 1559175.25000\n",
      "Step #100, epoch #100, avg. train loss: 2923094.00000\n",
      "Step #200, epoch #200, avg. train loss: 1542928.12500\n",
      "Step #100, epoch #100, avg. train loss: 2820809.25000\n",
      "Step #200, epoch #200, avg. train loss: 1429722.75000\n",
      "Step #100, epoch #100, avg. train loss: 2795162.50000\n",
      "Step #200, epoch #200, avg. train loss: 1463687.25000\n",
      "Step #100, epoch #100, avg. train loss: 2104931.25000\n",
      "Step #200, epoch #200, avg. train loss: 1580258.12500\n",
      "Step #100, epoch #100, avg. train loss: 2039353.00000\n",
      "Step #200, epoch #200, avg. train loss: 1522746.25000\n",
      "Step #100, epoch #100, avg. train loss: 2112505.00000\n",
      "Step #200, epoch #200, avg. train loss: 1576905.25000\n",
      "Step #100, epoch #33, avg. train loss: 6788598.00000\n",
      "Step #200, epoch #66, avg. train loss: 2041576.12500\n",
      "Step #100, epoch #33, avg. train loss: 7348463.50000\n",
      "Step #200, epoch #66, avg. train loss: 2020547.62500\n",
      "Step #100, epoch #33, avg. train loss: 6768306.00000\n",
      "Step #200, epoch #66, avg. train loss: 2365662.75000\n",
      "Step #100, epoch #25, avg. train loss: 3421458.25000\n",
      "Step #200, epoch #50, avg. train loss: 1691556.50000\n",
      "Step #100, epoch #25, avg. train loss: 3619305.50000\n",
      "Step #200, epoch #50, avg. train loss: 1625036.37500\n",
      "Step #100, epoch #25, avg. train loss: 3490915.25000\n",
      "Step #200, epoch #50, avg. train loss: 1555442.25000\n",
      "Step #100, epoch #25, avg. train loss: 2355165.25000\n",
      "Step #200, epoch #50, avg. train loss: 1580499.62500\n",
      "Step #100, epoch #25, avg. train loss: 2103899.00000\n",
      "Step #200, epoch #50, avg. train loss: 1516648.37500\n",
      "Step #100, epoch #25, avg. train loss: 2227847.00000\n",
      "Step #200, epoch #50, avg. train loss: 1569249.25000\n",
      "Step #100, epoch #33, avg. train loss: 2296119.75000\n",
      "Step #200, epoch #66, avg. train loss: 1533259.62500\n",
      "Step #100, epoch #33, avg. train loss: 2197642.00000\n",
      "Step #200, epoch #66, avg. train loss: 1446072.37500\n",
      "Step #100, epoch #33, avg. train loss: 2294121.50000\n",
      "Step #200, epoch #66, avg. train loss: 1451797.00000\n",
      "Step #100, epoch #100, avg. train loss: 2630946.25000\n",
      "Step #200, epoch #200, avg. train loss: 1556384.62500\n",
      "Step #100, epoch #100, avg. train loss: 2529382.00000\n",
      "Step #200, epoch #200, avg. train loss: 1486758.87500\n",
      "Step #100, epoch #100, avg. train loss: 2607414.50000\n",
      "Step #200, epoch #200, avg. train loss: 1525757.00000\n",
      "Step #100, epoch #100, avg. train loss: 2101778.25000\n",
      "Step #200, epoch #200, avg. train loss: 1549734.12500\n",
      "Step #100, epoch #100, avg. train loss: 2022877.12500\n",
      "Step #200, epoch #200, avg. train loss: 1485459.62500\n",
      "Step #100, epoch #100, avg. train loss: 2118240.25000\n",
      "Step #200, epoch #200, avg. train loss: 1527966.75000\n",
      "Step #100, epoch #50, avg. train loss: 2082672.37500\n",
      "Step #200, epoch #100, avg. train loss: 1593213.87500\n",
      "Step #100, epoch #50, avg. train loss: 1999960.37500\n",
      "Step #200, epoch #100, avg. train loss: 1497237.12500\n",
      "Step #100, epoch #50, avg. train loss: 2082865.25000\n",
      "Step #200, epoch #100, avg. train loss: 1622113.50000\n",
      "Step #100, epoch #100, avg. train loss: 2761628.25000\n",
      "Step #200, epoch #200, avg. train loss: 1497506.12500\n",
      "Step #100, epoch #100, avg. train loss: 2820888.25000\n",
      "Step #200, epoch #200, avg. train loss: 1463568.12500\n",
      "Step #100, epoch #100, avg. train loss: 2942381.00000\n",
      "Step #200, epoch #200, avg. train loss: 1669221.25000\n",
      "Step #100, epoch #50, avg. train loss: 2513760.00000\n",
      "Step #200, epoch #100, avg. train loss: 1560822.75000\n",
      "Step #100, epoch #50, avg. train loss: 3106363.25000\n",
      "Step #200, epoch #100, avg. train loss: 1514796.62500\n",
      "Step #100, epoch #50, avg. train loss: 2541773.75000\n",
      "Step #200, epoch #100, avg. train loss: 1587473.50000\n",
      "Step #100, epoch #100, avg. train loss: 2621964.25000\n",
      "Step #200, epoch #200, avg. train loss: 1495473.12500\n",
      "Step #100, epoch #100, avg. train loss: 2528052.25000\n",
      "Step #200, epoch #200, avg. train loss: 1447771.87500\n",
      "Step #100, epoch #100, avg. train loss: 2630124.75000\n",
      "Step #200, epoch #200, avg. train loss: 1566486.50000\n",
      "Step #100, epoch #100, avg. train loss: 2485505.25000\n",
      "Step #200, epoch #200, avg. train loss: 1528262.75000\n",
      "Step #100, epoch #100, avg. train loss: 2409673.00000\n",
      "Step #200, epoch #200, avg. train loss: 1473991.62500\n",
      "Step #100, epoch #100, avg. train loss: 2484360.75000\n",
      "Step #200, epoch #200, avg. train loss: 1472144.50000\n",
      "Step #100, epoch #100, avg. train loss: 2352484.25000\n",
      "Step #200, epoch #200, avg. train loss: 1678924.37500\n",
      "Step #100, epoch #100, avg. train loss: 2293015.75000\n",
      "Step #200, epoch #200, avg. train loss: 1613364.50000\n",
      "Step #100, epoch #100, avg. train loss: 2351218.25000\n",
      "Step #200, epoch #200, avg. train loss: 1714034.50000\n",
      "Step #100, epoch #50, avg. train loss: 2550596.75000\n",
      "Step #200, epoch #100, avg. train loss: 1576643.25000\n",
      "Step #100, epoch #50, avg. train loss: 2995008.75000\n",
      "Step #200, epoch #100, avg. train loss: 1581607.37500\n",
      "Step #100, epoch #50, avg. train loss: 2506943.00000\n",
      "Step #200, epoch #100, avg. train loss: 1609937.75000\n",
      "Step #100, epoch #100, avg. train loss: 2366103.75000\n",
      "Step #200, epoch #200, avg. train loss: 1596205.25000\n",
      "Step #100, epoch #100, avg. train loss: 2284269.00000\n",
      "Step #200, epoch #200, avg. train loss: 1515400.12500\n",
      "Step #100, epoch #100, avg. train loss: 2375538.00000\n",
      "Step #200, epoch #200, avg. train loss: 1612546.37500\n",
      "Step #100, epoch #100, avg. train loss: 2161973.25000\n",
      "Step #200, epoch #200, avg. train loss: 1474860.37500\n",
      "Step #100, epoch #100, avg. train loss: 2100096.75000\n",
      "Step #200, epoch #200, avg. train loss: 1426322.87500\n",
      "Step #100, epoch #100, avg. train loss: 2141066.50000\n",
      "Step #200, epoch #200, avg. train loss: 1403894.50000\n",
      "Step #100, epoch #100, avg. train loss: 2386919.50000\n",
      "Step #200, epoch #200, avg. train loss: 1569149.50000\n",
      "Step #100, epoch #100, avg. train loss: 2303779.50000\n",
      "Step #200, epoch #200, avg. train loss: 1551553.12500\n",
      "Step #100, epoch #100, avg. train loss: 2369426.25000\n",
      "Step #200, epoch #200, avg. train loss: 1514131.62500\n",
      "Step #100, epoch #100, avg. train loss: 2202133.00000\n",
      "Step #200, epoch #200, avg. train loss: 1530914.37500\n",
      "Step #100, epoch #100, avg. train loss: 2145886.50000\n",
      "Step #200, epoch #200, avg. train loss: 1353547.62500\n",
      "Step #100, epoch #100, avg. train loss: 2220579.75000\n",
      "Step #200, epoch #200, avg. train loss: 1573889.25000\n",
      "Step #100, epoch #50, avg. train loss: 2149550.00000\n",
      "Step #200, epoch #100, avg. train loss: 1611316.62500\n",
      "Step #100, epoch #50, avg. train loss: 2076605.62500\n",
      "Step #200, epoch #100, avg. train loss: 1529756.50000\n",
      "Step #100, epoch #50, avg. train loss: 2165683.75000\n",
      "Step #200, epoch #100, avg. train loss: 1544435.00000\n",
      "Step #100, epoch #50, avg. train loss: 2509600.75000\n",
      "Step #200, epoch #100, avg. train loss: 1602027.25000\n",
      "Step #100, epoch #50, avg. train loss: 2458602.50000\n",
      "Step #200, epoch #100, avg. train loss: 1542363.50000\n",
      "Step #100, epoch #50, avg. train loss: 2528330.00000\n",
      "Step #200, epoch #100, avg. train loss: 1500028.62500\n",
      "Step #100, epoch #100, avg. train loss: 2722699.00000\n",
      "Step #200, epoch #200, avg. train loss: 1676935.00000\n",
      "Step #100, epoch #100, avg. train loss: 2680947.75000\n",
      "Step #200, epoch #200, avg. train loss: 1593591.37500\n",
      "Step #100, epoch #100, avg. train loss: 2706567.75000\n",
      "Step #200, epoch #200, avg. train loss: 1687872.50000\n",
      "Step #100, epoch #50, avg. train loss: 2581446.25000\n",
      "Step #200, epoch #100, avg. train loss: 1614574.87500\n",
      "Step #100, epoch #50, avg. train loss: 3108446.50000\n",
      "Step #200, epoch #100, avg. train loss: 1632026.75000\n",
      "Step #100, epoch #50, avg. train loss: 2545285.50000\n",
      "Step #200, epoch #100, avg. train loss: 1595225.50000\n",
      "Step #100, epoch #100, avg. train loss: 2207400.75000\n",
      "Step #200, epoch #200, avg. train loss: 1558217.75000\n",
      "Step #100, epoch #100, avg. train loss: 2131622.00000\n",
      "Step #200, epoch #200, avg. train loss: 1439450.50000\n",
      "Step #100, epoch #100, avg. train loss: 2154016.50000\n",
      "Step #200, epoch #200, avg. train loss: 1401175.00000\n",
      "Step #100, epoch #50, avg. train loss: 2280355.25000\n",
      "Step #200, epoch #100, avg. train loss: 1340565.00000\n",
      "Step #100, epoch #50, avg. train loss: 2444072.00000\n",
      "Step #200, epoch #100, avg. train loss: 1374441.00000\n",
      "Step #100, epoch #50, avg. train loss: 2534793.50000\n",
      "Step #200, epoch #100, avg. train loss: 1761967.00000\n",
      "Step #100, epoch #100, avg. train loss: 2835784.75000\n",
      "Step #200, epoch #200, avg. train loss: 1521234.25000\n",
      "Step #100, epoch #100, avg. train loss: 2925711.25000\n",
      "Step #200, epoch #200, avg. train loss: 1488295.37500\n",
      "Step #100, epoch #100, avg. train loss: 2717407.00000\n",
      "Step #200, epoch #200, avg. train loss: 1507558.75000\n",
      "Step #100, epoch #100, avg. train loss: 2340746.25000\n",
      "Step #200, epoch #200, avg. train loss: 1706681.50000\n",
      "Step #100, epoch #100, avg. train loss: 2288599.75000\n",
      "Step #200, epoch #200, avg. train loss: 1633052.00000\n",
      "Step #100, epoch #100, avg. train loss: 2334081.50000\n",
      "Step #200, epoch #200, avg. train loss: 1716899.87500\n",
      "Step #100, epoch #50, avg. train loss: 3573339.75000\n",
      "Step #200, epoch #100, avg. train loss: 1431951.87500\n",
      "Step #100, epoch #50, avg. train loss: 3600037.00000\n",
      "Step #200, epoch #100, avg. train loss: 1536356.37500\n",
      "Step #100, epoch #50, avg. train loss: 3559141.50000\n",
      "Step #200, epoch #100, avg. train loss: 1455671.37500\n",
      "Step #100, epoch #100, avg. train loss: 2175011.00000\n",
      "Step #200, epoch #200, avg. train loss: 1649058.87500\n",
      "Step #100, epoch #100, avg. train loss: 2072504.12500\n",
      "Step #200, epoch #200, avg. train loss: 1451762.87500\n",
      "Step #100, epoch #100, avg. train loss: 2169819.00000\n",
      "Step #200, epoch #200, avg. train loss: 1540933.75000\n",
      "Step #100, epoch #100, avg. train loss: 3047682.25000\n",
      "Step #200, epoch #200, avg. train loss: 1592433.00000\n",
      "Step #100, epoch #100, avg. train loss: 2828947.25000\n",
      "Step #200, epoch #200, avg. train loss: 1459722.37500\n",
      "Step #100, epoch #100, avg. train loss: 2868458.25000\n",
      "Step #200, epoch #200, avg. train loss: 1515951.87500\n",
      "Step #100, epoch #50, avg. train loss: 2950543.00000\n",
      "Step #200, epoch #100, avg. train loss: 1730384.75000\n",
      "Step #100, epoch #50, avg. train loss: 3000263.25000\n",
      "Step #200, epoch #100, avg. train loss: 1688022.12500\n",
      "Step #100, epoch #50, avg. train loss: 2911224.00000\n",
      "Step #200, epoch #100, avg. train loss: 1781286.25000\n",
      "Step #100, epoch #100, avg. train loss: 2845666.00000\n",
      "Step #200, epoch #200, avg. train loss: 1485516.00000\n",
      "Step #100, epoch #100, avg. train loss: 2793156.50000\n",
      "Step #200, epoch #200, avg. train loss: 1469876.00000\n",
      "Step #100, epoch #100, avg. train loss: 3027862.00000\n",
      "Step #200, epoch #200, avg. train loss: 1559479.50000\n",
      "Step #100, epoch #10, avg. train loss: 2551085.25000\n",
      "Step #200, epoch #20, avg. train loss: 1681794.12500\n",
      "Step #100, epoch #10, avg. train loss: 2411381.00000\n",
      "Step #200, epoch #20, avg. train loss: 1536435.00000\n",
      "Step #100, epoch #10, avg. train loss: 2423844.75000\n",
      "Step #200, epoch #20, avg. train loss: 1640799.00000\n",
      "Step #100, epoch #100, avg. train loss: 2860016.25000\n",
      "Step #200, epoch #200, avg. train loss: 1506759.25000\n",
      "Step #100, epoch #100, avg. train loss: 2803646.50000\n",
      "Step #200, epoch #200, avg. train loss: 1486738.25000\n",
      "Step #100, epoch #100, avg. train loss: 2878510.00000\n",
      "Step #200, epoch #200, avg. train loss: 1537989.00000\n",
      "Step #100, epoch #100, avg. train loss: 2107767.25000\n",
      "Step #200, epoch #200, avg. train loss: 1632095.62500\n",
      "Step #100, epoch #100, avg. train loss: 2032445.25000\n",
      "Step #200, epoch #200, avg. train loss: 1554574.25000\n",
      "Step #100, epoch #100, avg. train loss: 2115350.25000\n",
      "Step #200, epoch #200, avg. train loss: 1614797.50000\n",
      "Step #100, epoch #50, avg. train loss: 2400383.00000\n",
      "Step #200, epoch #100, avg. train loss: 1417597.75000\n",
      "Step #100, epoch #50, avg. train loss: 2475980.75000\n",
      "Step #200, epoch #100, avg. train loss: 1467737.87500\n",
      "Step #100, epoch #50, avg. train loss: 2474918.50000\n",
      "Step #200, epoch #100, avg. train loss: 1870397.75000\n",
      "Step #100, epoch #100, avg. train loss: 2040941.12500\n",
      "Step #200, epoch #200, avg. train loss: 1538625.87500\n",
      "Step #100, epoch #100, avg. train loss: 1961382.25000\n",
      "Step #200, epoch #200, avg. train loss: 1480958.87500\n",
      "Step #100, epoch #100, avg. train loss: 2051922.12500\n",
      "Step #200, epoch #200, avg. train loss: 1536068.75000\n",
      "Step #100, epoch #100, avg. train loss: 2206119.00000\n",
      "Step #200, epoch #200, avg. train loss: 1493288.37500\n",
      "Step #100, epoch #100, avg. train loss: 2152192.25000\n",
      "Step #200, epoch #200, avg. train loss: 1456476.75000\n",
      "Step #100, epoch #100, avg. train loss: 2230410.00000\n",
      "Step #200, epoch #200, avg. train loss: 1562900.37500\n",
      "Step #100, epoch #100, avg. train loss: 2181278.75000\n",
      "Step #200, epoch #200, avg. train loss: 1697870.12500\n",
      "Step #100, epoch #100, avg. train loss: 2099404.00000\n",
      "Step #200, epoch #200, avg. train loss: 1549672.12500\n",
      "Step #100, epoch #100, avg. train loss: 2167813.50000\n",
      "Step #200, epoch #200, avg. train loss: 1632311.37500\n",
      "Step #100, epoch #100, avg. train loss: 2775592.75000\n",
      "Step #200, epoch #200, avg. train loss: 1547360.37500\n",
      "Step #100, epoch #100, avg. train loss: 2669261.50000\n",
      "Step #200, epoch #200, avg. train loss: 1545653.00000\n",
      "Step #100, epoch #100, avg. train loss: 2755197.50000\n",
      "Step #200, epoch #200, avg. train loss: 1656756.62500\n",
      "Step #100, epoch #20, avg. train loss: 2191922.00000\n",
      "Step #200, epoch #40, avg. train loss: 1615710.25000\n",
      "Step #100, epoch #20, avg. train loss: 2114031.25000\n",
      "Step #200, epoch #40, avg. train loss: 1554869.87500\n",
      "Step #100, epoch #16, avg. train loss: 2210354.75000\n",
      "Step #200, epoch #33, avg. train loss: 1687237.12500\n",
      "Step #100, epoch #100, avg. train loss: 2422802.50000\n",
      "Step #200, epoch #200, avg. train loss: 1581004.12500\n",
      "Step #100, epoch #100, avg. train loss: 2320832.50000\n",
      "Step #200, epoch #200, avg. train loss: 1468714.50000\n",
      "Step #100, epoch #100, avg. train loss: 2396734.75000\n",
      "Step #200, epoch #200, avg. train loss: 1660593.75000\n",
      "Step #100, epoch #100, avg. train loss: 2141976.25000\n",
      "Step #200, epoch #200, avg. train loss: 1503051.62500\n",
      "Step #100, epoch #100, avg. train loss: 2075550.25000\n",
      "Step #200, epoch #200, avg. train loss: 1488792.62500\n",
      "Step #100, epoch #100, avg. train loss: 2150498.50000\n",
      "Step #200, epoch #200, avg. train loss: 1471711.62500\n",
      "Step #100, epoch #25, avg. train loss: 2731243.00000\n",
      "Step #200, epoch #50, avg. train loss: 1798456.12500\n",
      "Step #100, epoch #25, avg. train loss: 2692265.25000\n",
      "Step #200, epoch #50, avg. train loss: 1704697.25000\n",
      "Step #100, epoch #25, avg. train loss: 2720818.25000\n",
      "Step #200, epoch #50, avg. train loss: 1815364.00000\n",
      "Step #100, epoch #100, avg. train loss: 2078866.87500\n",
      "Step #200, epoch #200, avg. train loss: 1621648.00000\n",
      "Step #100, epoch #100, avg. train loss: 1999896.62500\n",
      "Step #200, epoch #200, avg. train loss: 1518054.75000\n",
      "Step #100, epoch #100, avg. train loss: 2087973.12500\n",
      "Step #200, epoch #200, avg. train loss: 1572064.37500\n",
      "Step #100, epoch #12, avg. train loss: 2663435.25000\n",
      "Step #200, epoch #25, avg. train loss: 1597934.12500\n",
      "Step #100, epoch #12, avg. train loss: 2616339.00000\n",
      "Step #200, epoch #25, avg. train loss: 1571256.62500\n",
      "Step #100, epoch #12, avg. train loss: 2750501.50000\n",
      "Step #200, epoch #25, avg. train loss: 1572534.12500\n",
      "Step #100, epoch #100, avg. train loss: 3463820.25000\n",
      "Step #200, epoch #200, avg. train loss: 1694540.12500\n",
      "Step #100, epoch #100, avg. train loss: 3413924.25000\n",
      "Step #200, epoch #200, avg. train loss: 1512116.75000\n",
      "Step #100, epoch #100, avg. train loss: 3507724.75000\n",
      "Step #200, epoch #200, avg. train loss: 1572897.12500\n",
      "Step #100, epoch #33, avg. train loss: 2201431.75000\n",
      "Step #200, epoch #66, avg. train loss: 1721814.12500\n",
      "Step #100, epoch #33, avg. train loss: 2119165.00000\n",
      "Step #200, epoch #66, avg. train loss: 1623795.87500\n",
      "Step #100, epoch #33, avg. train loss: 2210022.75000\n",
      "Step #200, epoch #66, avg. train loss: 1711118.87500\n",
      "Step #100, epoch #100, avg. train loss: 3586452.25000\n",
      "Step #200, epoch #200, avg. train loss: 1549314.75000\n",
      "Step #100, epoch #100, avg. train loss: 3460722.00000\n",
      "Step #200, epoch #200, avg. train loss: 1483215.37500\n",
      "Step #100, epoch #100, avg. train loss: 3582957.50000\n",
      "Step #200, epoch #200, avg. train loss: 1485895.87500\n",
      "Step #100, epoch #14, avg. train loss: 2080840.12500\n",
      "Step #200, epoch #28, avg. train loss: 1486310.37500\n",
      "Step #100, epoch #14, avg. train loss: 2145852.25000\n",
      "Step #200, epoch #28, avg. train loss: 1532000.00000\n",
      "Step #100, epoch #14, avg. train loss: 2178229.00000\n",
      "Step #200, epoch #28, avg. train loss: 1669119.62500\n",
      "Step #100, epoch #100, avg. train loss: 2710352.75000\n",
      "Step #200, epoch #200, avg. train loss: 1746401.00000\n",
      "Step #100, epoch #100, avg. train loss: 2678255.25000\n",
      "Step #200, epoch #200, avg. train loss: 1659853.25000\n",
      "Step #100, epoch #100, avg. train loss: 2692120.25000\n",
      "Step #200, epoch #200, avg. train loss: 1770093.00000\n",
      "Step #100, epoch #100, avg. train loss: 2613915.25000\n",
      "Step #200, epoch #200, avg. train loss: 1642419.37500\n",
      "Step #100, epoch #100, avg. train loss: 2574462.50000\n",
      "Step #200, epoch #200, avg. train loss: 1523669.75000\n",
      "Step #100, epoch #100, avg. train loss: 2607976.25000\n",
      "Step #200, epoch #200, avg. train loss: 1540459.25000\n",
      "Step #100, epoch #100, avg. train loss: 2503400.25000\n",
      "Step #200, epoch #200, avg. train loss: 1520993.25000\n",
      "Step #100, epoch #100, avg. train loss: 2408622.00000\n",
      "Step #200, epoch #200, avg. train loss: 1493555.25000\n",
      "Step #100, epoch #100, avg. train loss: 2515129.50000\n",
      "Step #200, epoch #200, avg. train loss: 1543804.62500\n",
      "Step #100, epoch #33, avg. train loss: 3081228.50000\n",
      "Step #200, epoch #66, avg. train loss: 1523763.87500\n",
      "Step #100, epoch #33, avg. train loss: 2906774.00000\n",
      "Step #200, epoch #66, avg. train loss: 1501229.87500\n",
      "Step #100, epoch #33, avg. train loss: 2914944.25000\n",
      "Step #200, epoch #66, avg. train loss: 1464902.37500\n",
      "Step #100, epoch #100, avg. train loss: 2309814.00000\n",
      "Step #200, epoch #200, avg. train loss: 1514953.00000\n",
      "Step #100, epoch #100, avg. train loss: 2261303.75000\n",
      "Step #200, epoch #200, avg. train loss: 1469709.12500\n",
      "Step #100, epoch #100, avg. train loss: 2304043.75000\n",
      "Step #200, epoch #200, avg. train loss: 1504418.12500\n",
      "Step #100, epoch #25, avg. train loss: 11465276.00000\n",
      "Step #200, epoch #50, avg. train loss: 11238084.00000\n",
      "Step #100, epoch #25, avg. train loss: 11786426.00000\n",
      "Step #200, epoch #50, avg. train loss: 11547788.00000\n",
      "Step #100, epoch #25, avg. train loss: 11160333.00000\n",
      "Step #200, epoch #50, avg. train loss: 10932315.00000\n",
      "Step #100, epoch #100, avg. train loss: 2106368.00000\n",
      "Step #200, epoch #200, avg. train loss: 1547006.50000\n",
      "Step #100, epoch #100, avg. train loss: 2028303.25000\n",
      "Step #200, epoch #200, avg. train loss: 1453619.87500\n",
      "Step #100, epoch #100, avg. train loss: 2116150.00000\n",
      "Step #200, epoch #200, avg. train loss: 1545280.00000\n",
      "Step #100, epoch #100, avg. train loss: 3442729.25000\n",
      "Step #200, epoch #200, avg. train loss: 1558504.75000\n",
      "Step #100, epoch #100, avg. train loss: 3366320.25000\n",
      "Step #200, epoch #200, avg. train loss: 1576881.00000\n",
      "Step #100, epoch #100, avg. train loss: 3434081.00000\n",
      "Step #200, epoch #200, avg. train loss: 1580296.62500\n",
      "Step #100, epoch #100, avg. train loss: 3290320.25000\n",
      "Step #200, epoch #200, avg. train loss: 1774153.75000\n",
      "Step #100, epoch #100, avg. train loss: 3290893.50000\n",
      "Step #200, epoch #200, avg. train loss: 1683208.12500\n",
      "Step #100, epoch #100, avg. train loss: 3250283.00000\n",
      "Step #200, epoch #200, avg. train loss: 1791607.62500\n",
      "Step #100, epoch #33, avg. train loss: 2651127.50000\n",
      "Step #200, epoch #66, avg. train loss: 1765286.12500\n",
      "Step #100, epoch #33, avg. train loss: 2588034.50000\n",
      "Step #200, epoch #66, avg. train loss: 1665228.00000\n",
      "Step #100, epoch #33, avg. train loss: 2634849.75000\n",
      "Step #200, epoch #66, avg. train loss: 1754352.37500\n",
      "Step #100, epoch #100, avg. train loss: 2139979.00000\n",
      "Step #200, epoch #200, avg. train loss: 1610519.25000\n",
      "Step #100, epoch #100, avg. train loss: 2076205.62500\n",
      "Step #200, epoch #200, avg. train loss: 1548939.00000\n",
      "Step #100, epoch #100, avg. train loss: 2143169.50000\n",
      "Step #200, epoch #200, avg. train loss: 1610565.12500\n",
      "Step #100, epoch #100, avg. train loss: 2797386.25000\n",
      "Step #200, epoch #200, avg. train loss: 1572125.12500\n",
      "Step #100, epoch #100, avg. train loss: 2680110.50000\n",
      "Step #200, epoch #200, avg. train loss: 1473553.62500\n",
      "Step #100, epoch #100, avg. train loss: 2762599.25000\n",
      "Step #200, epoch #200, avg. train loss: 1516701.75000\n",
      "Step #100, epoch #50, avg. train loss: 2257690.50000\n",
      "Step #200, epoch #100, avg. train loss: 1630051.62500\n",
      "Step #100, epoch #50, avg. train loss: 2189766.50000\n",
      "Step #200, epoch #100, avg. train loss: 1536177.12500\n",
      "Step #100, epoch #50, avg. train loss: 2240628.50000\n",
      "Step #200, epoch #100, avg. train loss: 1672597.00000\n",
      "Step #100, epoch #33, avg. train loss: 2288836.75000\n",
      "Step #200, epoch #66, avg. train loss: 1541940.37500\n",
      "Step #100, epoch #33, avg. train loss: 2210361.75000\n",
      "Step #200, epoch #66, avg. train loss: 1482919.37500\n",
      "Step #100, epoch #33, avg. train loss: 2332357.75000\n",
      "Step #200, epoch #66, avg. train loss: 1509287.87500\n",
      "Step #100, epoch #100, avg. train loss: 2784578.50000\n",
      "Step #200, epoch #200, avg. train loss: 1566911.00000\n",
      "Step #100, epoch #100, avg. train loss: 2685916.25000\n",
      "Step #200, epoch #200, avg. train loss: 1485165.75000\n",
      "Step #100, epoch #100, avg. train loss: 2750981.00000\n",
      "Step #200, epoch #200, avg. train loss: 1556882.50000\n",
      "Step #100, epoch #100, avg. train loss: 2361787.00000\n",
      "Step #200, epoch #200, avg. train loss: 1646575.50000\n",
      "Step #100, epoch #100, avg. train loss: 2308076.50000\n",
      "Step #200, epoch #200, avg. train loss: 1559356.37500\n",
      "Step #100, epoch #100, avg. train loss: 2361854.00000\n",
      "Step #200, epoch #200, avg. train loss: 1524286.12500\n",
      "Step #100, epoch #20, avg. train loss: 2398025.75000\n",
      "Step #200, epoch #40, avg. train loss: 1791785.87500\n",
      "Step #100, epoch #20, avg. train loss: 2337062.75000\n",
      "Step #200, epoch #40, avg. train loss: 1712404.50000\n",
      "Step #100, epoch #20, avg. train loss: 2415885.50000\n",
      "Step #200, epoch #40, avg. train loss: 1799271.87500\n",
      "Step #100, epoch #50, avg. train loss: 2223832.00000\n",
      "Step #200, epoch #100, avg. train loss: 1666964.00000\n",
      "Step #100, epoch #50, avg. train loss: 2207294.50000\n",
      "Step #200, epoch #100, avg. train loss: 1645881.50000\n",
      "Step #100, epoch #50, avg. train loss: 2234502.00000\n",
      "Step #200, epoch #100, avg. train loss: 1738990.37500\n",
      "Step #100, epoch #7, avg. train loss: 2257861.50000\n",
      "Step #200, epoch #14, avg. train loss: 1756317.75000\n",
      "Step #100, epoch #7, avg. train loss: 2137879.00000\n",
      "Step #200, epoch #14, avg. train loss: 1505118.87500\n",
      "Step #100, epoch #7, avg. train loss: 2198479.00000\n",
      "Step #200, epoch #14, avg. train loss: 1632546.25000\n",
      "Step #100, epoch #100, avg. train loss: 2762767.00000\n",
      "Step #200, epoch #200, avg. train loss: 1583899.37500\n",
      "Step #100, epoch #100, avg. train loss: 2699908.75000\n",
      "Step #200, epoch #200, avg. train loss: 1503475.00000\n",
      "Step #100, epoch #100, avg. train loss: 2748442.00000\n",
      "Step #200, epoch #200, avg. train loss: 1636936.75000\n",
      "Step #100, epoch #100, avg. train loss: 2138859.00000\n",
      "Step #200, epoch #200, avg. train loss: 1684721.75000\n",
      "Step #100, epoch #100, avg. train loss: 2063781.62500\n",
      "Step #200, epoch #200, avg. train loss: 1602854.75000\n",
      "Step #100, epoch #100, avg. train loss: 2146739.25000\n",
      "Step #200, epoch #200, avg. train loss: 1673999.50000\n",
      "Step #100, epoch #25, avg. train loss: 2356461.00000\n",
      "Step #200, epoch #50, avg. train loss: 1573889.62500\n",
      "Step #100, epoch #25, avg. train loss: 2255158.50000\n",
      "Step #200, epoch #50, avg. train loss: 1587122.37500\n",
      "Step #100, epoch #25, avg. train loss: 2397946.50000\n",
      "Step #200, epoch #50, avg. train loss: 1623856.12500\n",
      "Step #100, epoch #16, avg. train loss: 2247234.25000\n",
      "Step #200, epoch #33, avg. train loss: 1554417.62500\n",
      "Step #100, epoch #16, avg. train loss: 2272748.75000\n",
      "Step #200, epoch #33, avg. train loss: 1501270.75000\n",
      "Step #100, epoch #16, avg. train loss: 2311773.00000\n",
      "Step #200, epoch #33, avg. train loss: 1548034.12500\n",
      "Step #100, epoch #100, avg. train loss: 2885825.50000\n",
      "Step #200, epoch #200, avg. train loss: 1600096.75000\n",
      "Step #100, epoch #100, avg. train loss: 2843019.25000\n",
      "Step #200, epoch #200, avg. train loss: 1507818.12500\n",
      "Step #100, epoch #100, avg. train loss: 2850708.25000\n",
      "Step #200, epoch #200, avg. train loss: 1628980.12500\n",
      "Step #100, epoch #3, avg. train loss: 7869005.50000\n",
      "Step #200, epoch #7, avg. train loss: 2995908.50000\n",
      "Step #100, epoch #3, avg. train loss: 8056458.00000\n",
      "Step #200, epoch #7, avg. train loss: 2836699.50000\n",
      "Step #100, epoch #3, avg. train loss: 7670735.50000\n",
      "Step #200, epoch #7, avg. train loss: 2648622.00000\n",
      "Step #100, epoch #33, avg. train loss: 2138447.75000\n",
      "Step #200, epoch #66, avg. train loss: 1613188.75000\n",
      "Step #100, epoch #33, avg. train loss: 2062102.12500\n",
      "Step #200, epoch #66, avg. train loss: 1534597.25000\n",
      "Step #100, epoch #33, avg. train loss: 2146007.75000\n",
      "Step #200, epoch #66, avg. train loss: 1563133.50000\n",
      "Step #100, epoch #100, avg. train loss: 4246837.50000\n",
      "Step #200, epoch #200, avg. train loss: 1795441.00000\n",
      "Step #100, epoch #100, avg. train loss: 4263069.00000\n",
      "Step #200, epoch #200, avg. train loss: 1695969.87500\n",
      "Step #100, epoch #100, avg. train loss: 4134208.25000\n",
      "Step #200, epoch #200, avg. train loss: 1806236.62500\n",
      "Step #100, epoch #8, avg. train loss: 2279682.25000\n",
      "Step #200, epoch #16, avg. train loss: 1729466.75000\n",
      "Step #100, epoch #8, avg. train loss: 2256641.75000\n",
      "Step #200, epoch #16, avg. train loss: 1661809.87500\n",
      "Step #100, epoch #8, avg. train loss: 2331407.00000\n",
      "Step #200, epoch #16, avg. train loss: 1752517.25000\n",
      "Step #100, epoch #100, avg. train loss: 2076787.87500\n",
      "Step #200, epoch #200, avg. train loss: 1572983.25000\n",
      "Step #100, epoch #100, avg. train loss: 2016457.00000\n",
      "Step #200, epoch #200, avg. train loss: 1530121.87500\n",
      "Step #100, epoch #100, avg. train loss: 2086285.00000\n",
      "Step #200, epoch #200, avg. train loss: 1543053.62500\n",
      "Step #100, epoch #100, avg. train loss: 3326398.00000\n",
      "Step #200, epoch #200, avg. train loss: 1558173.62500\n",
      "Step #100, epoch #100, avg. train loss: 3199090.25000\n",
      "Step #200, epoch #200, avg. train loss: 1509140.00000\n",
      "Step #100, epoch #100, avg. train loss: 3359207.75000\n",
      "Step #200, epoch #200, avg. train loss: 1533360.75000\n",
      "Step #100, epoch #50, avg. train loss: 3800665.00000\n",
      "Step #200, epoch #100, avg. train loss: 1508004.75000\n",
      "Step #100, epoch #50, avg. train loss: 3678173.75000\n",
      "Step #200, epoch #100, avg. train loss: 1562355.37500\n",
      "Step #100, epoch #50, avg. train loss: 3598448.25000\n",
      "Step #200, epoch #100, avg. train loss: 1891989.00000\n",
      "Step #100, epoch #100, avg. train loss: 2159400.25000\n",
      "Step #200, epoch #200, avg. train loss: 1507257.00000\n",
      "Step #100, epoch #100, avg. train loss: 2104086.75000\n",
      "Step #200, epoch #200, avg. train loss: 1489640.50000\n",
      "Step #100, epoch #100, avg. train loss: 2175702.00000\n",
      "Step #200, epoch #200, avg. train loss: 1711173.25000\n",
      "Step #100, epoch #50, avg. train loss: 2451267.25000\n",
      "Step #200, epoch #100, avg. train loss: 1594587.62500\n",
      "Step #100, epoch #50, avg. train loss: 2461901.50000\n",
      "Step #200, epoch #100, avg. train loss: 1631135.62500\n",
      "Step #100, epoch #50, avg. train loss: 2531992.75000\n",
      "Step #200, epoch #100, avg. train loss: 1528046.87500\n",
      "Step #100, epoch #100, avg. train loss: 3079090.50000\n",
      "Step #200, epoch #200, avg. train loss: 1622411.87500\n",
      "Step #100, epoch #100, avg. train loss: 3075512.25000\n",
      "Step #200, epoch #200, avg. train loss: 1484324.75000\n",
      "Step #100, epoch #100, avg. train loss: 3218665.25000\n",
      "Step #200, epoch #200, avg. train loss: 1529454.12500\n",
      "Step #100, epoch #100, avg. train loss: 2136334.50000\n",
      "Step #200, epoch #200, avg. train loss: 1487020.37500\n",
      "Step #100, epoch #100, avg. train loss: 2064558.50000\n",
      "Step #200, epoch #200, avg. train loss: 1414284.50000\n",
      "Step #100, epoch #100, avg. train loss: 2130599.75000\n",
      "Step #200, epoch #200, avg. train loss: 1457281.62500\n",
      "Step #100, epoch #100, avg. train loss: 2105075.00000\n",
      "Step #200, epoch #200, avg. train loss: 1540496.62500\n",
      "Step #100, epoch #100, avg. train loss: 2025863.37500\n",
      "Step #200, epoch #200, avg. train loss: 1477432.62500\n",
      "Step #100, epoch #100, avg. train loss: 2114690.00000\n",
      "Step #200, epoch #200, avg. train loss: 1469129.87500\n",
      "Step #100, epoch #100, avg. train loss: 2126679.00000\n",
      "Step #200, epoch #200, avg. train loss: 1580357.75000\n",
      "Step #100, epoch #100, avg. train loss: 2049638.50000\n",
      "Step #200, epoch #200, avg. train loss: 1502251.50000\n",
      "Step #100, epoch #100, avg. train loss: 2136690.25000\n",
      "Step #200, epoch #200, avg. train loss: 1567369.50000\n",
      "Step #100, epoch #100, avg. train loss: 2818965.75000\n",
      "Step #200, epoch #200, avg. train loss: 1632887.50000\n",
      "Step #100, epoch #100, avg. train loss: 2868557.75000\n",
      "Step #200, epoch #200, avg. train loss: 1560637.62500\n",
      "Step #100, epoch #100, avg. train loss: 2805909.75000\n",
      "Step #200, epoch #200, avg. train loss: 1656275.00000\n",
      "Step #100, epoch #100, avg. train loss: 2890850.50000\n",
      "Step #200, epoch #200, avg. train loss: 1476722.75000\n",
      "Step #100, epoch #100, avg. train loss: 2824612.75000\n",
      "Step #200, epoch #200, avg. train loss: 1473255.50000\n",
      "Step #100, epoch #100, avg. train loss: 2840958.00000\n",
      "Step #200, epoch #200, avg. train loss: 1518591.50000\n",
      "Step #100, epoch #100, avg. train loss: 2321746.50000\n",
      "Step #200, epoch #200, avg. train loss: 1460623.50000\n",
      "Step #100, epoch #100, avg. train loss: 2251606.00000\n",
      "Step #200, epoch #200, avg. train loss: 1497157.25000\n",
      "Step #100, epoch #100, avg. train loss: 2205103.50000\n",
      "Step #200, epoch #200, avg. train loss: 1451357.75000\n",
      "Step #100, epoch #3, avg. train loss: 2706393.00000\n",
      "Step #200, epoch #7, avg. train loss: 1758890.50000\n",
      "Step #100, epoch #3, avg. train loss: 2883266.50000\n",
      "Step #200, epoch #7, avg. train loss: 1820361.62500\n",
      "Step #100, epoch #3, avg. train loss: 3095241.00000\n",
      "Step #200, epoch #7, avg. train loss: 1805505.12500\n",
      "Step #100, epoch #100, avg. train loss: 3909989.75000\n",
      "Step #200, epoch #200, avg. train loss: 1524699.00000\n",
      "Step #100, epoch #100, avg. train loss: 3878369.25000\n",
      "Step #200, epoch #200, avg. train loss: 1447401.75000\n",
      "Step #100, epoch #100, avg. train loss: 3968123.75000\n",
      "Step #200, epoch #200, avg. train loss: 1544850.37500\n",
      "Step #100, epoch #100, avg. train loss: 2561729.50000\n",
      "Step #200, epoch #200, avg. train loss: 1511046.37500\n",
      "Step #100, epoch #100, avg. train loss: 2496791.50000\n",
      "Step #200, epoch #200, avg. train loss: 1508846.37500\n",
      "Step #100, epoch #100, avg. train loss: 2558486.50000\n",
      "Step #200, epoch #200, avg. train loss: 1514928.12500\n",
      "Step #100, epoch #50, avg. train loss: 2846225.50000\n",
      "Step #200, epoch #100, avg. train loss: 1716664.12500\n",
      "Step #100, epoch #50, avg. train loss: 2879290.25000\n",
      "Step #200, epoch #100, avg. train loss: 1687915.25000\n",
      "Step #100, epoch #50, avg. train loss: 2806771.50000\n",
      "Step #200, epoch #100, avg. train loss: 1781123.37500\n",
      "Step #100, epoch #33, avg. train loss: 2263251.00000\n",
      "Step #200, epoch #66, avg. train loss: 1738077.87500\n",
      "Step #100, epoch #33, avg. train loss: 2186992.75000\n",
      "Step #200, epoch #66, avg. train loss: 1649505.00000\n",
      "Step #100, epoch #33, avg. train loss: 2273550.50000\n",
      "Step #200, epoch #66, avg. train loss: 1731679.50000\n",
      "Step #100, epoch #100, avg. train loss: 2641023.25000\n",
      "Step #200, epoch #200, avg. train loss: 1614928.00000\n",
      "Step #100, epoch #100, avg. train loss: 3192694.50000\n",
      "Step #200, epoch #200, avg. train loss: 1682407.62500\n",
      "Step #100, epoch #100, avg. train loss: 2461176.50000\n",
      "Step #200, epoch #200, avg. train loss: 1582343.87500\n",
      "Step #100, epoch #25, avg. train loss: 2171849.75000\n",
      "Step #200, epoch #50, avg. train loss: 1693685.12500\n",
      "Step #100, epoch #25, avg. train loss: 2090748.62500\n",
      "Step #200, epoch #50, avg. train loss: 1563703.62500\n",
      "Step #100, epoch #25, avg. train loss: 2166883.25000\n",
      "Step #200, epoch #50, avg. train loss: 1669499.62500\n",
      "Step #100, epoch #25, avg. train loss: 2176646.00000\n",
      "Step #200, epoch #50, avg. train loss: 1609934.12500\n",
      "Step #100, epoch #25, avg. train loss: 2147015.75000\n",
      "Step #200, epoch #50, avg. train loss: 1496709.12500\n",
      "Step #100, epoch #25, avg. train loss: 2179380.25000\n",
      "Step #200, epoch #50, avg. train loss: 1560073.87500\n",
      "Step #100, epoch #100, avg. train loss: 2790743.75000\n",
      "Step #200, epoch #200, avg. train loss: 1627262.75000\n",
      "Step #100, epoch #100, avg. train loss: 2761496.25000\n",
      "Step #200, epoch #200, avg. train loss: 1506344.75000\n",
      "Step #100, epoch #100, avg. train loss: 2797726.00000\n",
      "Step #200, epoch #200, avg. train loss: 1525873.25000\n",
      "Step #100, epoch #100, avg. train loss: 2055837.50000\n",
      "Step #200, epoch #200, avg. train loss: 1576720.12500\n",
      "Step #100, epoch #100, avg. train loss: 1979479.25000\n",
      "Step #200, epoch #200, avg. train loss: 1524254.25000\n",
      "Step #100, epoch #100, avg. train loss: 2065971.50000\n",
      "Step #200, epoch #200, avg. train loss: 1602000.00000\n",
      "Step #100, epoch #25, avg. train loss: 2346008.50000\n",
      "Step #200, epoch #50, avg. train loss: 1733861.62500\n",
      "Step #100, epoch #25, avg. train loss: 2278863.00000\n",
      "Step #200, epoch #50, avg. train loss: 1652519.62500\n",
      "Step #100, epoch #25, avg. train loss: 2356595.75000\n",
      "Step #200, epoch #50, avg. train loss: 1725904.00000\n",
      "Step #100, epoch #100, avg. train loss: 2923572.50000\n",
      "Step #200, epoch #200, avg. train loss: 1516222.75000\n",
      "Step #100, epoch #100, avg. train loss: 2812492.75000\n",
      "Step #200, epoch #200, avg. train loss: 1545000.62500\n",
      "Step #100, epoch #100, avg. train loss: 2898549.50000\n",
      "Step #200, epoch #200, avg. train loss: 1512961.00000\n",
      "Step #100, epoch #100, avg. train loss: 4587489.00000\n",
      "Step #200, epoch #200, avg. train loss: 1772228.12500\n",
      "Step #100, epoch #100, avg. train loss: 4656109.00000\n",
      "Step #200, epoch #200, avg. train loss: 1688358.37500\n",
      "Step #100, epoch #100, avg. train loss: 4498749.00000\n",
      "Step #200, epoch #200, avg. train loss: 1790124.00000\n",
      "Step #100, epoch #100, avg. train loss: 2147923.00000\n",
      "Step #200, epoch #200, avg. train loss: 1613692.62500\n",
      "Step #100, epoch #100, avg. train loss: 2065527.50000\n",
      "Step #200, epoch #200, avg. train loss: 1557311.87500\n",
      "Step #100, epoch #100, avg. train loss: 2163459.75000\n",
      "Step #200, epoch #200, avg. train loss: 1593053.50000\n",
      "Step #100, epoch #100, avg. train loss: 3132548.75000\n",
      "Step #200, epoch #200, avg. train loss: 1660577.00000\n",
      "Step #100, epoch #100, avg. train loss: 3072405.00000\n",
      "Step #200, epoch #200, avg. train loss: 1498022.75000\n",
      "Step #100, epoch #100, avg. train loss: 3403695.00000\n",
      "Step #200, epoch #200, avg. train loss: 1447191.25000\n",
      "Step #100, epoch #100, avg. train loss: 2592512.50000\n",
      "Step #200, epoch #200, avg. train loss: 1535917.87500\n",
      "Step #100, epoch #100, avg. train loss: 2517801.50000\n",
      "Step #200, epoch #200, avg. train loss: 1484014.50000\n",
      "Step #100, epoch #100, avg. train loss: 2606685.25000\n",
      "Step #200, epoch #200, avg. train loss: 1528854.25000\n",
      "Step #100, epoch #100, avg. train loss: 10781526.00000\n",
      "Step #200, epoch #200, avg. train loss: 9904214.00000\n",
      "Step #100, epoch #100, avg. train loss: 11098282.00000\n",
      "Step #200, epoch #200, avg. train loss: 10174777.00000\n",
      "Step #100, epoch #100, avg. train loss: 10500440.00000\n",
      "Step #200, epoch #200, avg. train loss: 9620902.00000\n",
      "Step #100, epoch #100, avg. train loss: 2579813.50000\n",
      "Step #200, epoch #200, avg. train loss: 1532057.12500\n",
      "Step #100, epoch #100, avg. train loss: 2460267.75000\n",
      "Step #200, epoch #200, avg. train loss: 1507822.25000\n",
      "Step #100, epoch #100, avg. train loss: 2566140.25000\n",
      "Step #200, epoch #200, avg. train loss: 1574305.75000\n",
      "Step #100, epoch #10, avg. train loss: 2300174.50000\n",
      "Step #200, epoch #20, avg. train loss: 1621759.37500\n",
      "Step #100, epoch #10, avg. train loss: 2324825.00000\n",
      "Step #200, epoch #20, avg. train loss: 1586048.75000\n",
      "Step #100, epoch #10, avg. train loss: 2391300.75000\n",
      "Step #200, epoch #20, avg. train loss: 1626115.25000\n",
      "Step #100, epoch #100, avg. train loss: 2245508.75000\n",
      "Step #200, epoch #200, avg. train loss: 1553067.50000\n",
      "Step #100, epoch #100, avg. train loss: 2158326.75000\n",
      "Step #200, epoch #200, avg. train loss: 1506624.50000\n",
      "Step #100, epoch #100, avg. train loss: 2256754.50000\n",
      "Step #200, epoch #200, avg. train loss: 1555047.25000\n",
      "Step #100, epoch #50, avg. train loss: 2412909.75000\n",
      "Step #200, epoch #100, avg. train loss: 1648195.37500\n",
      "Step #100, epoch #50, avg. train loss: 2538321.50000\n",
      "Step #200, epoch #100, avg. train loss: 1611392.62500\n",
      "Step #100, epoch #50, avg. train loss: 2671680.50000\n",
      "Step #200, epoch #100, avg. train loss: 1850654.87500\n",
      "Step #100, epoch #25, avg. train loss: 2305726.25000\n",
      "Step #200, epoch #50, avg. train loss: 1664018.50000\n",
      "Step #100, epoch #25, avg. train loss: 2198672.50000\n",
      "Step #200, epoch #50, avg. train loss: 1572690.87500\n",
      "Step #100, epoch #25, avg. train loss: 2227362.50000\n",
      "Step #200, epoch #50, avg. train loss: 1651417.62500\n",
      "Step #100, epoch #50, avg. train loss: 2457675.75000\n",
      "Step #200, epoch #100, avg. train loss: 1519970.37500\n",
      "Step #100, epoch #50, avg. train loss: 2384902.75000\n",
      "Step #200, epoch #100, avg. train loss: 1591193.12500\n",
      "Step #100, epoch #50, avg. train loss: 2723916.75000\n",
      "Step #200, epoch #100, avg. train loss: 1542323.37500\n",
      "Step #100, epoch #100, avg. train loss: 2146215.25000\n",
      "Step #200, epoch #200, avg. train loss: 1526597.75000\n",
      "Step #100, epoch #100, avg. train loss: 2089012.50000\n",
      "Step #200, epoch #200, avg. train loss: 1523540.00000\n",
      "Step #100, epoch #100, avg. train loss: 2147553.25000\n",
      "Step #200, epoch #200, avg. train loss: 1501121.50000\n",
      "Step #100, epoch #100, avg. train loss: 2211252.25000\n",
      "Step #200, epoch #200, avg. train loss: 1623023.37500\n",
      "Step #100, epoch #100, avg. train loss: 2148852.75000\n",
      "Step #200, epoch #200, avg. train loss: 1494945.87500\n",
      "Step #100, epoch #100, avg. train loss: 2213153.00000\n",
      "Step #200, epoch #200, avg. train loss: 1597478.12500\n",
      "Step #100, epoch #100, avg. train loss: 2268056.25000\n",
      "Step #200, epoch #200, avg. train loss: 1547767.25000\n",
      "Step #100, epoch #100, avg. train loss: 2187831.50000\n",
      "Step #200, epoch #200, avg. train loss: 1481639.87500\n",
      "Step #100, epoch #100, avg. train loss: 2278990.25000\n",
      "Step #200, epoch #200, avg. train loss: 1546506.75000\n",
      "Step #100, epoch #2, avg. train loss: 2412076.25000\n",
      "Step #200, epoch #4, avg. train loss: 1857726.87500\n",
      "Step #100, epoch #2, avg. train loss: 2287670.25000\n",
      "Step #200, epoch #4, avg. train loss: 1748544.62500\n",
      "Step #100, epoch #2, avg. train loss: 2349648.25000\n",
      "Step #200, epoch #4, avg. train loss: 1882538.75000\n",
      "Step #100, epoch #100, avg. train loss: 2188106.50000\n",
      "Step #200, epoch #200, avg. train loss: 1538294.87500\n",
      "Step #100, epoch #100, avg. train loss: 2133644.75000\n",
      "Step #200, epoch #200, avg. train loss: 1509603.00000\n",
      "Step #100, epoch #100, avg. train loss: 2168601.00000\n",
      "Step #200, epoch #200, avg. train loss: 1554919.00000\n",
      "Step #100, epoch #33, avg. train loss: 2926359.25000\n",
      "Step #200, epoch #66, avg. train loss: 1517424.00000\n",
      "Step #100, epoch #33, avg. train loss: 2781841.50000\n",
      "Step #200, epoch #66, avg. train loss: 1487463.87500\n",
      "Step #100, epoch #33, avg. train loss: 2654371.25000\n",
      "Step #200, epoch #66, avg. train loss: 1499148.75000\n",
      "Step #100, epoch #100, avg. train loss: 2505839.00000\n",
      "Step #200, epoch #200, avg. train loss: 1667855.25000\n",
      "Step #100, epoch #100, avg. train loss: 2621385.50000\n",
      "Step #200, epoch #200, avg. train loss: 1652748.75000\n",
      "Step #100, epoch #100, avg. train loss: 2422215.00000\n",
      "Step #200, epoch #200, avg. train loss: 1589702.50000\n",
      "Step #100, epoch #100, avg. train loss: 2109733.75000\n",
      "Step #200, epoch #200, avg. train loss: 1508499.62500\n",
      "Step #100, epoch #100, avg. train loss: 2048953.62500\n",
      "Step #200, epoch #200, avg. train loss: 1463373.87500\n",
      "Step #100, epoch #100, avg. train loss: 2133603.50000\n",
      "Step #200, epoch #200, avg. train loss: 1627070.12500\n",
      "Step #100, epoch #25, avg. train loss: 2267268.00000\n",
      "Step #200, epoch #50, avg. train loss: 1659727.87500\n",
      "Step #100, epoch #25, avg. train loss: 2261621.75000\n",
      "Step #200, epoch #50, avg. train loss: 1668329.25000\n",
      "Step #100, epoch #25, avg. train loss: 2327938.75000\n",
      "Step #200, epoch #50, avg. train loss: 1595409.75000\n",
      "Step #100, epoch #100, avg. train loss: 2428501.00000\n",
      "Step #200, epoch #200, avg. train loss: 1563148.00000\n",
      "Step #100, epoch #100, avg. train loss: 2330455.75000\n",
      "Step #200, epoch #200, avg. train loss: 1537355.62500\n",
      "Step #100, epoch #100, avg. train loss: 2447812.75000\n",
      "Step #200, epoch #200, avg. train loss: 1548523.00000\n",
      "Step #100, epoch #33, avg. train loss: 2234065.00000\n",
      "Step #200, epoch #66, avg. train loss: 1456418.37500\n",
      "Step #100, epoch #33, avg. train loss: 2184893.75000\n",
      "Step #200, epoch #66, avg. train loss: 1474933.62500\n",
      "Step #100, epoch #33, avg. train loss: 2398841.25000\n",
      "Step #200, epoch #66, avg. train loss: 1454511.37500\n",
      "Step #100, epoch #33, avg. train loss: 2260844.00000\n",
      "Step #200, epoch #66, avg. train loss: 1514564.37500\n",
      "Step #100, epoch #33, avg. train loss: 2209872.25000\n",
      "Step #200, epoch #66, avg. train loss: 1470007.37500\n",
      "Step #100, epoch #33, avg. train loss: 2272116.00000\n",
      "Step #200, epoch #66, avg. train loss: 1449914.37500\n",
      "Step #100, epoch #100, avg. train loss: 4500786.00000\n",
      "Step #200, epoch #200, avg. train loss: 1797050.25000\n",
      "Step #100, epoch #100, avg. train loss: 4575824.50000\n",
      "Step #200, epoch #200, avg. train loss: 1707202.37500\n",
      "Step #100, epoch #100, avg. train loss: 4407186.00000\n",
      "Step #200, epoch #200, avg. train loss: 1813197.75000\n",
      "Step #100, epoch #33, avg. train loss: 2550863.50000\n",
      "Step #200, epoch #66, avg. train loss: 1503610.75000\n",
      "Step #100, epoch #33, avg. train loss: 2420954.75000\n",
      "Step #200, epoch #66, avg. train loss: 1530305.50000\n",
      "Step #100, epoch #33, avg. train loss: 2512262.00000\n",
      "Step #200, epoch #66, avg. train loss: 1504762.37500\n",
      "Step #100, epoch #50, avg. train loss: 3847433.50000\n",
      "Step #200, epoch #100, avg. train loss: 1443065.87500\n",
      "Step #100, epoch #50, avg. train loss: 3889893.00000\n",
      "Step #200, epoch #100, avg. train loss: 1491531.87500\n",
      "Step #100, epoch #50, avg. train loss: 4018218.00000\n",
      "Step #200, epoch #100, avg. train loss: 1888002.25000\n",
      "Step #100, epoch #50, avg. train loss: 2783054.00000\n",
      "Step #200, epoch #100, avg. train loss: 1522236.75000\n",
      "Step #100, epoch #50, avg. train loss: 3023639.75000\n",
      "Step #200, epoch #100, avg. train loss: 1549634.50000\n",
      "Step #100, epoch #50, avg. train loss: 2999065.50000\n",
      "Step #200, epoch #100, avg. train loss: 1541259.25000\n",
      "Step #100, epoch #50, avg. train loss: 2175779.00000\n",
      "Step #200, epoch #100, avg. train loss: 1716504.12500\n",
      "Step #100, epoch #50, avg. train loss: 2101857.00000\n",
      "Step #200, epoch #100, avg. train loss: 1631856.62500\n",
      "Step #100, epoch #50, avg. train loss: 2193998.75000\n",
      "Step #200, epoch #100, avg. train loss: 1717470.75000\n",
      "Step #100, epoch #50, avg. train loss: 2635001.50000\n",
      "Step #200, epoch #100, avg. train loss: 1582320.37500\n",
      "Step #100, epoch #50, avg. train loss: 3360611.25000\n",
      "Step #200, epoch #100, avg. train loss: 1575345.12500\n",
      "Step #100, epoch #50, avg. train loss: 2640383.50000\n",
      "Step #200, epoch #100, avg. train loss: 1545434.12500\n",
      "Step #100, epoch #100, avg. train loss: 2614689.50000\n",
      "Step #200, epoch #200, avg. train loss: 1619429.12500\n",
      "Step #100, epoch #100, avg. train loss: 3103454.50000\n",
      "Step #200, epoch #200, avg. train loss: 1662933.00000\n",
      "Step #100, epoch #100, avg. train loss: 2463135.25000\n",
      "Step #200, epoch #200, avg. train loss: 1612610.50000\n",
      "Step #100, epoch #25, avg. train loss: 2193897.25000\n",
      "Step #200, epoch #50, avg. train loss: 1601215.37500\n",
      "Step #100, epoch #25, avg. train loss: 2173588.75000\n",
      "Step #200, epoch #50, avg. train loss: 1572479.25000\n",
      "Step #100, epoch #25, avg. train loss: 2242704.25000\n",
      "Step #200, epoch #50, avg. train loss: 1623185.12500\n",
      "Step #100, epoch #50, avg. train loss: 3137505.00000\n",
      "Step #200, epoch #100, avg. train loss: 1509066.87500\n",
      "Step #100, epoch #50, avg. train loss: 3117541.50000\n",
      "Step #200, epoch #100, avg. train loss: 1504974.25000\n",
      "Step #100, epoch #50, avg. train loss: 3000252.75000\n",
      "Step #200, epoch #100, avg. train loss: 1546871.00000\n",
      "Step #100, epoch #100, avg. train loss: 2212989.50000\n",
      "Step #200, epoch #200, avg. train loss: 1596649.62500\n",
      "Step #100, epoch #100, avg. train loss: 2126919.50000\n",
      "Step #200, epoch #200, avg. train loss: 1435586.50000\n",
      "Step #100, epoch #100, avg. train loss: 2191125.25000\n",
      "Step #200, epoch #200, avg. train loss: 1500868.50000\n",
      "Step #100, epoch #33, avg. train loss: 2339345.75000\n",
      "Step #200, epoch #66, avg. train loss: 1519205.75000\n",
      "Step #100, epoch #33, avg. train loss: 2206586.25000\n",
      "Step #200, epoch #66, avg. train loss: 1482963.00000\n",
      "Step #100, epoch #33, avg. train loss: 2374246.50000\n",
      "Step #200, epoch #66, avg. train loss: 1486726.12500\n",
      "Step #100, epoch #50, avg. train loss: 3450153.00000\n",
      "Step #200, epoch #100, avg. train loss: 1558607.62500\n",
      "Step #100, epoch #50, avg. train loss: 3279732.50000\n",
      "Step #200, epoch #100, avg. train loss: 1507245.87500\n",
      "Step #100, epoch #50, avg. train loss: 3196529.25000\n",
      "Step #200, epoch #100, avg. train loss: 1547289.25000\n",
      "Step #100, epoch #50, avg. train loss: 3342336.75000\n",
      "Step #200, epoch #100, avg. train loss: 1597289.25000\n",
      "Step #100, epoch #50, avg. train loss: 3373339.25000\n",
      "Step #200, epoch #100, avg. train loss: 1504802.75000\n",
      "Step #100, epoch #50, avg. train loss: 3326736.00000\n",
      "Step #200, epoch #100, avg. train loss: 1603005.00000\n",
      "Step #100, epoch #1, avg. train loss: 2304418.00000\n",
      "Step #200, epoch #2, avg. train loss: 1842437.87500\n",
      "Step #100, epoch #1, avg. train loss: 2407549.75000\n",
      "Step #200, epoch #2, avg. train loss: 1831651.25000\n",
      "Step #100, epoch #1, avg. train loss: 2273154.00000\n",
      "Step #200, epoch #2, avg. train loss: 2150755.25000\n",
      "Step #100, epoch #33, avg. train loss: 2791059.25000\n",
      "Step #200, epoch #66, avg. train loss: 1520026.37500\n",
      "Step #100, epoch #33, avg. train loss: 2658382.50000\n",
      "Step #200, epoch #66, avg. train loss: 1437102.87500\n",
      "Step #100, epoch #33, avg. train loss: 2739585.50000\n",
      "Step #200, epoch #66, avg. train loss: 1501690.12500\n",
      "Step #100, epoch #100, avg. train loss: 2875845.00000\n",
      "Step #200, epoch #200, avg. train loss: 1523919.37500\n",
      "Step #100, epoch #100, avg. train loss: 2786051.50000\n",
      "Step #200, epoch #200, avg. train loss: 1542565.12500\n",
      "Step #100, epoch #100, avg. train loss: 2840204.25000\n",
      "Step #200, epoch #200, avg. train loss: 1511768.75000\n",
      "Step #100, epoch #100, avg. train loss: 2247363.75000\n",
      "Step #200, epoch #200, avg. train loss: 1527899.25000\n",
      "Step #100, epoch #100, avg. train loss: 2167850.75000\n",
      "Step #200, epoch #200, avg. train loss: 1477030.12500\n",
      "Step #100, epoch #100, avg. train loss: 2258282.25000\n",
      "Step #200, epoch #200, avg. train loss: 1528024.62500\n",
      "Step #100, epoch #4, avg. train loss: 2303195.00000\n",
      "Step #200, epoch #8, avg. train loss: 1746016.62500\n",
      "Step #100, epoch #4, avg. train loss: 2317910.00000\n",
      "Step #200, epoch #8, avg. train loss: 1487924.62500\n",
      "Step #100, epoch #4, avg. train loss: 2369456.00000\n",
      "Step #200, epoch #8, avg. train loss: 1767215.25000\n",
      "Step #100, epoch #33, avg. train loss: 3077106.00000\n",
      "Step #200, epoch #66, avg. train loss: 1573554.12500\n",
      "Step #100, epoch #33, avg. train loss: 2385225.50000\n",
      "Step #200, epoch #66, avg. train loss: 1554438.87500\n",
      "Step #100, epoch #33, avg. train loss: 2502319.50000\n",
      "Step #200, epoch #66, avg. train loss: 1652737.50000\n",
      "Step #100, epoch #100, avg. train loss: 2818371.75000\n",
      "Step #200, epoch #200, avg. train loss: 1578840.00000\n",
      "Step #100, epoch #100, avg. train loss: 2724062.75000\n",
      "Step #200, epoch #200, avg. train loss: 1457114.87500\n",
      "Step #100, epoch #100, avg. train loss: 2846955.50000\n",
      "Step #200, epoch #200, avg. train loss: 1515645.12500\n",
      "Step #100, epoch #20, avg. train loss: 2635726.50000\n",
      "Step #200, epoch #40, avg. train loss: 1584050.25000\n",
      "Step #100, epoch #20, avg. train loss: 2490738.00000\n",
      "Step #200, epoch #40, avg. train loss: 1492025.25000\n",
      "Step #100, epoch #20, avg. train loss: 2633599.00000\n",
      "Step #200, epoch #40, avg. train loss: 1581051.87500\n",
      "Step #100, epoch #33, avg. train loss: 2137975.00000\n",
      "Step #200, epoch #66, avg. train loss: 1665814.12500\n",
      "Step #100, epoch #33, avg. train loss: 2173233.50000\n",
      "Step #200, epoch #66, avg. train loss: 1695594.50000\n",
      "Step #100, epoch #33, avg. train loss: 2240342.75000\n",
      "Step #200, epoch #66, avg. train loss: 1669736.37500\n",
      "Step #100, epoch #50, avg. train loss: 2506709.25000\n",
      "Step #200, epoch #100, avg. train loss: 1501043.87500\n",
      "Step #100, epoch #50, avg. train loss: 2699059.50000\n",
      "Step #200, epoch #100, avg. train loss: 1563033.87500\n",
      "Step #100, epoch #50, avg. train loss: 3074776.25000\n",
      "Step #200, epoch #100, avg. train loss: 1553732.75000\n",
      "Step #100, epoch #100, avg. train loss: 2227773.25000\n",
      "Step #200, epoch #200, avg. train loss: 1576376.00000\n",
      "Step #100, epoch #100, avg. train loss: 2143919.25000\n",
      "Step #200, epoch #200, avg. train loss: 1530060.50000\n",
      "Step #100, epoch #100, avg. train loss: 2245884.75000\n",
      "Step #200, epoch #200, avg. train loss: 1533697.62500\n",
      "Step #100, epoch #50, avg. train loss: 2505075.00000\n",
      "Step #200, epoch #100, avg. train loss: 1591824.37500\n",
      "Step #100, epoch #50, avg. train loss: 2889258.50000\n",
      "Step #200, epoch #100, avg. train loss: 1520182.50000\n",
      "Step #100, epoch #50, avg. train loss: 2562814.00000\n",
      "Step #200, epoch #100, avg. train loss: 1526796.12500\n",
      "Step #100, epoch #100, avg. train loss: 2732128.00000\n",
      "Step #200, epoch #200, avg. train loss: 1659837.62500\n",
      "Step #100, epoch #100, avg. train loss: 2691174.50000\n",
      "Step #200, epoch #200, avg. train loss: 1495390.37500\n",
      "Step #100, epoch #100, avg. train loss: 2766326.50000\n",
      "Step #200, epoch #200, avg. train loss: 1521556.00000\n",
      "Step #100, epoch #100, avg. train loss: 3206818.00000\n",
      "Step #200, epoch #200, avg. train loss: 1769544.00000\n",
      "Step #100, epoch #100, avg. train loss: 3199784.25000\n",
      "Step #200, epoch #200, avg. train loss: 1680744.75000\n",
      "Step #100, epoch #100, avg. train loss: 3168258.00000\n",
      "Step #200, epoch #200, avg. train loss: 1787907.25000\n",
      "Step #100, epoch #11, avg. train loss: 2048540.12500\n",
      "Step #200, epoch #22, avg. train loss: 1639849.62500\n",
      "Step #100, epoch #11, avg. train loss: 2060295.87500\n",
      "Step #200, epoch #22, avg. train loss: 1585581.87500\n",
      "Step #100, epoch #11, avg. train loss: 2174884.50000\n",
      "Step #200, epoch #22, avg. train loss: 1715220.75000\n",
      "Step #100, epoch #33, avg. train loss: 2170202.25000\n",
      "Step #200, epoch #66, avg. train loss: 1660029.87500\n",
      "Step #100, epoch #33, avg. train loss: 2128613.50000\n",
      "Step #200, epoch #66, avg. train loss: 1591358.87500\n",
      "Step #100, epoch #33, avg. train loss: 2234350.25000\n",
      "Step #200, epoch #66, avg. train loss: 1597322.75000\n",
      "Step #100, epoch #50, avg. train loss: 2887860.50000\n",
      "Step #200, epoch #100, avg. train loss: 1525266.50000\n",
      "Step #100, epoch #50, avg. train loss: 2886575.75000\n",
      "Step #200, epoch #100, avg. train loss: 1512856.62500\n",
      "Step #100, epoch #50, avg. train loss: 2894057.50000\n",
      "Step #200, epoch #100, avg. train loss: 1507093.62500\n",
      "Step #100, epoch #100, avg. train loss: 2208570.75000\n",
      "Step #200, epoch #200, avg. train loss: 1624646.25000\n",
      "Step #100, epoch #100, avg. train loss: 2143397.75000\n",
      "Step #200, epoch #200, avg. train loss: 1528287.00000\n",
      "Step #100, epoch #100, avg. train loss: 2210929.00000\n",
      "Step #200, epoch #200, avg. train loss: 1570307.62500\n",
      "Step #100, epoch #50, avg. train loss: 2215007.25000\n",
      "Step #200, epoch #100, avg. train loss: 1531609.12500\n",
      "Step #100, epoch #50, avg. train loss: 2141138.00000\n",
      "Step #200, epoch #100, avg. train loss: 1490203.87500\n",
      "Step #100, epoch #50, avg. train loss: 2241683.25000\n",
      "Step #200, epoch #100, avg. train loss: 1543268.37500\n",
      "Step #100, epoch #100, avg. train loss: 2253054.00000\n",
      "Step #200, epoch #200, avg. train loss: 1677123.25000\n",
      "Step #100, epoch #100, avg. train loss: 2197516.75000\n",
      "Step #200, epoch #200, avg. train loss: 1606549.00000\n",
      "Step #100, epoch #100, avg. train loss: 2252667.00000\n",
      "Step #200, epoch #200, avg. train loss: 1688136.37500\n",
      "Step #100, epoch #100, avg. train loss: 2114685.00000\n",
      "Step #200, epoch #200, avg. train loss: 1559421.00000\n",
      "Step #100, epoch #100, avg. train loss: 2039809.75000\n",
      "Step #200, epoch #200, avg. train loss: 1416638.12500\n",
      "Step #100, epoch #100, avg. train loss: 2109229.50000\n",
      "Step #200, epoch #200, avg. train loss: 1469154.37500\n",
      "Step #100, epoch #50, avg. train loss: 3245135.75000\n",
      "Step #200, epoch #100, avg. train loss: 1541914.87500\n",
      "Step #100, epoch #50, avg. train loss: 3268616.75000\n",
      "Step #200, epoch #100, avg. train loss: 1567583.25000\n",
      "Step #100, epoch #50, avg. train loss: 3184443.50000\n",
      "Step #200, epoch #100, avg. train loss: 1488187.50000\n",
      "Step #100, epoch #3, avg. train loss: 3071475.75000\n",
      "Step #200, epoch #7, avg. train loss: 1715553.75000\n",
      "Step #100, epoch #3, avg. train loss: 2791063.25000\n",
      "Step #200, epoch #7, avg. train loss: 1700026.50000\n",
      "Step #100, epoch #3, avg. train loss: 2807605.50000\n",
      "Step #200, epoch #7, avg. train loss: 1790740.12500\n",
      "Step #100, epoch #100, avg. train loss: 2569525.75000\n",
      "Step #200, epoch #200, avg. train loss: 1525906.12500\n",
      "Step #100, epoch #100, avg. train loss: 2461765.00000\n",
      "Step #200, epoch #200, avg. train loss: 1611031.62500\n",
      "Step #100, epoch #100, avg. train loss: 2623871.00000\n",
      "Step #200, epoch #200, avg. train loss: 1630037.12500\n",
      "Step #100, epoch #100, avg. train loss: 2552561.00000\n",
      "Step #200, epoch #200, avg. train loss: 1645005.25000\n",
      "Step #100, epoch #100, avg. train loss: 2830267.75000\n",
      "Step #200, epoch #200, avg. train loss: 1653441.50000\n",
      "Step #100, epoch #100, avg. train loss: 2475243.75000\n",
      "Step #200, epoch #200, avg. train loss: 1600411.37500\n",
      "Step #100, epoch #100, avg. train loss: 2877575.75000\n",
      "Step #200, epoch #200, avg. train loss: 1506662.25000\n",
      "Step #100, epoch #100, avg. train loss: 2955732.50000\n",
      "Step #200, epoch #200, avg. train loss: 1472431.50000\n",
      "Step #100, epoch #100, avg. train loss: 2868786.25000\n",
      "Step #200, epoch #200, avg. train loss: 1525771.50000\n",
      "Step #100, epoch #33, avg. train loss: 2816523.75000\n",
      "Step #200, epoch #66, avg. train loss: 1691034.37500\n",
      "Step #100, epoch #33, avg. train loss: 2634532.75000\n",
      "Step #200, epoch #66, avg. train loss: 1741862.12500\n",
      "Step #100, epoch #33, avg. train loss: 2761717.75000\n",
      "Step #200, epoch #66, avg. train loss: 1597716.12500\n",
      "Step #100, epoch #9, avg. train loss: 3067124.75000\n",
      "Step #200, epoch #18, avg. train loss: 1833944.12500\n",
      "Step #100, epoch #9, avg. train loss: 3039942.00000\n",
      "Step #200, epoch #18, avg. train loss: 1742760.12500\n",
      "Step #100, epoch #9, avg. train loss: 3051867.75000\n",
      "Step #200, epoch #18, avg. train loss: 1838781.62500\n",
      "Step #100, epoch #50, avg. train loss: 2569486.00000\n",
      "Step #200, epoch #100, avg. train loss: 1525318.37500\n",
      "Step #100, epoch #50, avg. train loss: 2517393.75000\n",
      "Step #200, epoch #100, avg. train loss: 1516924.75000\n",
      "Step #100, epoch #50, avg. train loss: 2578487.50000\n",
      "Step #200, epoch #100, avg. train loss: 1497418.37500\n",
      "Step #100, epoch #100, avg. train loss: 2513938.50000\n",
      "Step #200, epoch #200, avg. train loss: 1540324.75000\n",
      "Step #100, epoch #100, avg. train loss: 2426843.25000\n",
      "Step #200, epoch #200, avg. train loss: 1499171.25000\n",
      "Step #100, epoch #100, avg. train loss: 2508289.00000\n",
      "Step #200, epoch #200, avg. train loss: 1494634.25000\n",
      "Step #100, epoch #100, avg. train loss: 2773459.75000\n",
      "Step #200, epoch #200, avg. train loss: 1714883.62500\n",
      "Step #100, epoch #100, avg. train loss: 2805661.75000\n",
      "Step #200, epoch #200, avg. train loss: 1487341.12500\n",
      "Step #100, epoch #100, avg. train loss: 2800300.25000\n",
      "Step #200, epoch #200, avg. train loss: 1507395.62500\n",
      "Step #100, epoch #100, avg. train loss: 2134289.00000\n",
      "Step #200, epoch #200, avg. train loss: 1649083.25000\n",
      "Step #100, epoch #100, avg. train loss: 2057421.00000\n",
      "Step #200, epoch #200, avg. train loss: 1515311.87500\n",
      "Step #100, epoch #100, avg. train loss: 2144684.75000\n",
      "Step #200, epoch #200, avg. train loss: 1646511.00000\n",
      "Step #100, epoch #100, avg. train loss: 2894869.00000\n",
      "Step #200, epoch #200, avg. train loss: 1741586.25000\n",
      "Step #100, epoch #100, avg. train loss: 2867401.25000\n",
      "Step #200, epoch #200, avg. train loss: 1653120.12500\n",
      "Step #100, epoch #100, avg. train loss: 2872098.25000\n",
      "Step #200, epoch #200, avg. train loss: 1758329.25000\n",
      "Step #100, epoch #100, avg. train loss: 2827279.75000\n",
      "Step #200, epoch #200, avg. train loss: 1575028.00000\n",
      "Step #100, epoch #100, avg. train loss: 2757543.75000\n",
      "Step #200, epoch #200, avg. train loss: 1478029.75000\n",
      "Step #100, epoch #100, avg. train loss: 2865945.50000\n",
      "Step #200, epoch #200, avg. train loss: 1482046.37500\n",
      "Step #100, epoch #100, avg. train loss: 2328915.00000\n",
      "Step #200, epoch #200, avg. train loss: 1554204.12500\n",
      "Step #100, epoch #100, avg. train loss: 2251858.25000\n",
      "Step #200, epoch #200, avg. train loss: 1527615.50000\n",
      "Step #100, epoch #100, avg. train loss: 2328037.75000\n",
      "Step #200, epoch #200, avg. train loss: 1505060.75000\n",
      "Step #100, epoch #25, avg. train loss: 3045835.75000\n",
      "Step #200, epoch #50, avg. train loss: 1532410.50000\n",
      "Step #100, epoch #25, avg. train loss: 2941354.00000\n",
      "Step #200, epoch #50, avg. train loss: 1489192.75000\n",
      "Step #100, epoch #25, avg. train loss: 2818443.25000\n",
      "Step #200, epoch #50, avg. train loss: 1581481.75000\n",
      "Step #100, epoch #50, avg. train loss: 2236035.50000\n",
      "Step #200, epoch #100, avg. train loss: 1544673.25000\n",
      "Step #100, epoch #50, avg. train loss: 2188141.50000\n",
      "Step #200, epoch #100, avg. train loss: 1460946.50000\n",
      "Step #100, epoch #50, avg. train loss: 2245487.25000\n",
      "Step #200, epoch #100, avg. train loss: 1544878.25000\n",
      "Step #100, epoch #100, avg. train loss: 2286938.75000\n",
      "Step #200, epoch #200, avg. train loss: 1612349.87500\n",
      "Step #100, epoch #100, avg. train loss: 2170166.25000\n",
      "Step #200, epoch #200, avg. train loss: 1618613.25000\n",
      "Step #100, epoch #100, avg. train loss: 2222034.25000\n",
      "Step #200, epoch #200, avg. train loss: 1524767.37500\n",
      "Step #100, epoch #33, avg. train loss: 2090199.62500\n",
      "Step #200, epoch #66, avg. train loss: 1658194.50000\n",
      "Step #100, epoch #33, avg. train loss: 2021233.62500\n",
      "Step #200, epoch #66, avg. train loss: 1554845.75000\n",
      "Step #100, epoch #33, avg. train loss: 2126251.50000\n",
      "Step #200, epoch #66, avg. train loss: 1684651.37500\n",
      "Step #100, epoch #100, avg. train loss: 2193313.00000\n",
      "Step #200, epoch #200, avg. train loss: 1484952.50000\n",
      "Step #100, epoch #100, avg. train loss: 2202663.00000\n",
      "Step #200, epoch #200, avg. train loss: 1355995.00000\n",
      "Step #100, epoch #100, avg. train loss: 2195592.25000\n",
      "Step #200, epoch #200, avg. train loss: 1515241.00000\n",
      "Step #100, epoch #25, avg. train loss: 2401468.75000\n",
      "Step #200, epoch #50, avg. train loss: 1677393.25000\n",
      "Step #100, epoch #25, avg. train loss: 2355661.25000\n",
      "Step #200, epoch #50, avg. train loss: 1568917.62500\n",
      "Step #100, epoch #25, avg. train loss: 2470751.25000\n",
      "Step #200, epoch #50, avg. train loss: 1649941.87500\n",
      "Step #100, epoch #50, avg. train loss: 2139860.75000\n",
      "Step #200, epoch #100, avg. train loss: 1517074.25000\n",
      "Step #100, epoch #50, avg. train loss: 2051313.12500\n",
      "Step #200, epoch #100, avg. train loss: 1474175.62500\n",
      "Step #100, epoch #50, avg. train loss: 2168197.00000\n",
      "Step #200, epoch #100, avg. train loss: 1509643.25000\n",
      "Step #100, epoch #100, avg. train loss: 3594692.25000\n",
      "Step #200, epoch #200, avg. train loss: 1629136.75000\n",
      "Step #100, epoch #100, avg. train loss: 3489362.25000\n",
      "Step #200, epoch #200, avg. train loss: 1577923.50000\n",
      "Step #100, epoch #100, avg. train loss: 3479051.25000\n",
      "Step #200, epoch #200, avg. train loss: 1642421.00000\n",
      "Step #100, epoch #50, avg. train loss: 2653597.00000\n",
      "Step #200, epoch #100, avg. train loss: 1546479.62500\n",
      "Step #100, epoch #50, avg. train loss: 2540189.25000\n",
      "Step #200, epoch #100, avg. train loss: 1500443.50000\n",
      "Step #100, epoch #50, avg. train loss: 2606934.50000\n",
      "Step #200, epoch #100, avg. train loss: 1548800.75000\n",
      "Step #100, epoch #33, avg. train loss: 2633259.75000\n",
      "Step #200, epoch #66, avg. train loss: 1598571.62500\n",
      "Step #100, epoch #33, avg. train loss: 2741125.50000\n",
      "Step #200, epoch #66, avg. train loss: 1593013.12500\n",
      "Step #100, epoch #33, avg. train loss: 2631339.00000\n",
      "Step #200, epoch #66, avg. train loss: 1612749.12500\n",
      "Step #100, epoch #6, avg. train loss: 7438182.00000\n",
      "Step #200, epoch #12, avg. train loss: 2335932.75000\n",
      "Step #100, epoch #6, avg. train loss: 7708812.00000\n",
      "Step #200, epoch #12, avg. train loss: 2320998.25000\n",
      "Step #100, epoch #6, avg. train loss: 7274673.50000\n",
      "Step #200, epoch #12, avg. train loss: 2357123.75000\n",
      "Step #100, epoch #100, avg. train loss: 8576205.00000\n",
      "Step #200, epoch #200, avg. train loss: 4263597.50000\n",
      "Step #100, epoch #100, avg. train loss: 8786593.00000\n",
      "Step #200, epoch #200, avg. train loss: 4071796.50000\n",
      "Step #100, epoch #100, avg. train loss: 8306327.00000\n",
      "Step #200, epoch #200, avg. train loss: 3881034.25000\n",
      "Step #100, epoch #33, avg. train loss: 2750558.50000\n",
      "Step #200, epoch #66, avg. train loss: 1537585.75000\n",
      "Step #100, epoch #33, avg. train loss: 2614689.00000\n",
      "Step #200, epoch #66, avg. train loss: 1477748.50000\n",
      "Step #100, epoch #33, avg. train loss: 2737491.25000\n",
      "Step #200, epoch #66, avg. train loss: 1470656.75000\n",
      "Step #100, epoch #3, avg. train loss: 2406033.25000\n",
      "Step #200, epoch #6, avg. train loss: 1755562.75000\n",
      "Step #100, epoch #3, avg. train loss: 2343019.75000\n",
      "Step #200, epoch #6, avg. train loss: 1741921.00000\n",
      "Step #100, epoch #3, avg. train loss: 2681926.00000\n",
      "Step #200, epoch #6, avg. train loss: 1761473.75000\n",
      "Step #100, epoch #100, avg. train loss: 2056270.75000\n",
      "Step #200, epoch #200, avg. train loss: 1569992.62500\n",
      "Step #100, epoch #100, avg. train loss: 1979238.25000\n",
      "Step #200, epoch #200, avg. train loss: 1532479.25000\n",
      "Step #100, epoch #100, avg. train loss: 2064281.00000\n",
      "Step #200, epoch #200, avg. train loss: 1602644.62500\n",
      "Step #100, epoch #100, avg. train loss: 2129198.50000\n",
      "Step #200, epoch #200, avg. train loss: 1531943.62500\n",
      "Step #100, epoch #100, avg. train loss: 2063996.37500\n",
      "Step #200, epoch #200, avg. train loss: 1469573.87500\n",
      "Step #100, epoch #100, avg. train loss: 2118467.75000\n",
      "Step #200, epoch #200, avg. train loss: 1597521.12500\n",
      "Step #100, epoch #100, avg. train loss: 2881445.75000\n",
      "Step #200, epoch #200, avg. train loss: 1667458.37500\n",
      "Step #100, epoch #100, avg. train loss: 2435461.50000\n",
      "Step #200, epoch #200, avg. train loss: 1611625.62500\n",
      "Step #100, epoch #100, avg. train loss: 2735867.75000\n",
      "Step #200, epoch #200, avg. train loss: 1521619.25000\n",
      "Step #100, epoch #50, avg. train loss: 2163567.75000\n",
      "Step #200, epoch #100, avg. train loss: 1623229.50000\n",
      "Step #100, epoch #50, avg. train loss: 2162736.25000\n",
      "Step #200, epoch #100, avg. train loss: 1477318.50000\n",
      "Step #100, epoch #50, avg. train loss: 2266844.75000\n",
      "Step #200, epoch #100, avg. train loss: 1536077.00000\n",
      "Step #100, epoch #6, avg. train loss: 2202577.50000\n",
      "Step #200, epoch #12, avg. train loss: 1769693.87500\n",
      "Step #100, epoch #6, avg. train loss: 2213165.00000\n",
      "Step #200, epoch #12, avg. train loss: 1669216.00000\n",
      "Step #100, epoch #6, avg. train loss: 2227062.00000\n",
      "Step #200, epoch #12, avg. train loss: 1803449.75000\n",
      "Step #100, epoch #50, avg. train loss: 2963863.75000\n",
      "Step #200, epoch #100, avg. train loss: 1532512.00000\n",
      "Step #100, epoch #50, avg. train loss: 2891839.75000\n",
      "Step #200, epoch #100, avg. train loss: 1523828.50000\n",
      "Step #100, epoch #50, avg. train loss: 2772578.50000\n",
      "Step #200, epoch #100, avg. train loss: 1594005.12500\n",
      "Step #100, epoch #50, avg. train loss: 2434152.75000\n",
      "Step #200, epoch #100, avg. train loss: 1752997.25000\n",
      "Step #100, epoch #50, avg. train loss: 2395706.75000\n",
      "Step #200, epoch #100, avg. train loss: 1683906.25000\n",
      "Step #100, epoch #50, avg. train loss: 2435072.00000\n",
      "Step #200, epoch #100, avg. train loss: 1782821.00000\n",
      "Step #100, epoch #4, avg. train loss: 2769685.00000\n",
      "Step #200, epoch #9, avg. train loss: 1668384.37500\n",
      "Step #100, epoch #4, avg. train loss: 2551850.00000\n",
      "Step #200, epoch #9, avg. train loss: 1541959.25000\n",
      "Step #100, epoch #4, avg. train loss: 2575832.75000\n",
      "Step #200, epoch #9, avg. train loss: 1692906.50000\n",
      "Step #100, epoch #100, avg. train loss: 3161334.75000\n",
      "Step #200, epoch #200, avg. train loss: 1715630.75000\n",
      "Step #100, epoch #100, avg. train loss: 3147455.00000\n",
      "Step #200, epoch #200, avg. train loss: 1631843.00000\n",
      "Step #100, epoch #100, avg. train loss: 3125825.50000\n",
      "Step #200, epoch #200, avg. train loss: 1729771.62500\n",
      "Step #100, epoch #100, avg. train loss: 3001591.75000\n",
      "Step #200, epoch #200, avg. train loss: 1564173.87500\n",
      "Step #100, epoch #100, avg. train loss: 2897361.25000\n",
      "Step #200, epoch #200, avg. train loss: 1547409.62500\n",
      "Step #100, epoch #100, avg. train loss: 2978516.25000\n",
      "Step #200, epoch #200, avg. train loss: 1544418.12500\n",
      "Step #100, epoch #100, avg. train loss: 2107029.25000\n",
      "Step #200, epoch #200, avg. train loss: 1606722.75000\n",
      "Step #100, epoch #100, avg. train loss: 2029535.50000\n",
      "Step #200, epoch #200, avg. train loss: 1507658.37500\n",
      "Step #100, epoch #100, avg. train loss: 2116542.50000\n",
      "Step #200, epoch #200, avg. train loss: 1597531.00000\n",
      "Step #100, epoch #100, avg. train loss: 2531228.75000\n",
      "Step #200, epoch #200, avg. train loss: 1574073.00000\n",
      "Step #100, epoch #100, avg. train loss: 2446936.75000\n",
      "Step #200, epoch #200, avg. train loss: 1502163.87500\n",
      "Step #100, epoch #100, avg. train loss: 2529176.25000\n",
      "Step #200, epoch #200, avg. train loss: 1520075.50000\n",
      "Step #100, epoch #100, avg. train loss: 2244240.75000\n",
      "Step #200, epoch #200, avg. train loss: 1706461.25000\n",
      "Step #100, epoch #100, avg. train loss: 2172994.50000\n",
      "Step #200, epoch #200, avg. train loss: 1615433.87500\n",
      "Step #100, epoch #100, avg. train loss: 2247223.25000\n",
      "Step #200, epoch #200, avg. train loss: 1711396.75000\n",
      "Step #100, epoch #5, avg. train loss: 2286758.75000\n",
      "Step #200, epoch #10, avg. train loss: 1659943.00000\n",
      "Step #100, epoch #5, avg. train loss: 2170990.50000\n",
      "Step #200, epoch #10, avg. train loss: 1565458.75000\n",
      "Step #100, epoch #5, avg. train loss: 2232825.00000\n",
      "Step #200, epoch #10, avg. train loss: 1727038.75000\n",
      "Step #100, epoch #50, avg. train loss: 2126420.25000\n",
      "Step #200, epoch #100, avg. train loss: 1728093.12500\n",
      "Step #100, epoch #50, avg. train loss: 2070091.50000\n",
      "Step #200, epoch #100, avg. train loss: 1680612.37500\n",
      "Step #100, epoch #50, avg. train loss: 2166629.00000\n",
      "Step #200, epoch #100, avg. train loss: 1704650.75000\n",
      "Step #100, epoch #100, avg. train loss: 2818804.75000\n",
      "Step #200, epoch #200, avg. train loss: 1531209.12500\n",
      "Step #100, epoch #100, avg. train loss: 2912313.50000\n",
      "Step #200, epoch #200, avg. train loss: 1522673.25000\n",
      "Step #100, epoch #100, avg. train loss: 2882179.75000\n",
      "Step #200, epoch #200, avg. train loss: 1521021.75000\n",
      "Step #100, epoch #100, avg. train loss: 5515322.00000\n",
      "Step #200, epoch #200, avg. train loss: 1811636.50000\n",
      "Step #100, epoch #100, avg. train loss: 5654908.00000\n",
      "Step #200, epoch #200, avg. train loss: 1721840.37500\n",
      "Step #100, epoch #100, avg. train loss: 5376272.00000\n",
      "Step #200, epoch #200, avg. train loss: 1833030.37500\n",
      "Step #100, epoch #100, avg. train loss: 2508777.00000\n",
      "Step #200, epoch #200, avg. train loss: 1669343.50000\n",
      "Step #100, epoch #100, avg. train loss: 2586379.75000\n",
      "Step #200, epoch #200, avg. train loss: 1651092.62500\n",
      "Step #100, epoch #100, avg. train loss: 2411358.00000\n",
      "Step #200, epoch #200, avg. train loss: 1605964.62500\n",
      "Step #100, epoch #50, avg. train loss: 2412929.50000\n",
      "Step #200, epoch #100, avg. train loss: 1548071.50000\n",
      "Step #100, epoch #50, avg. train loss: 2323909.25000\n",
      "Step #200, epoch #100, avg. train loss: 1500013.00000\n",
      "Step #100, epoch #50, avg. train loss: 2385638.00000\n",
      "Step #200, epoch #100, avg. train loss: 1581772.00000\n",
      "Step #100, epoch #100, avg. train loss: 2493111.50000\n",
      "Step #200, epoch #200, avg. train loss: 1588372.62500\n",
      "Step #100, epoch #100, avg. train loss: 2444892.25000\n",
      "Step #200, epoch #200, avg. train loss: 1513976.12500\n",
      "Step #100, epoch #100, avg. train loss: 2506182.00000\n",
      "Step #200, epoch #200, avg. train loss: 1660613.25000\n",
      "Step #100, epoch #100, avg. train loss: 2131538.25000\n",
      "Step #200, epoch #200, avg. train loss: 1542120.12500\n",
      "Step #100, epoch #100, avg. train loss: 2064503.37500\n",
      "Step #200, epoch #200, avg. train loss: 1497423.25000\n",
      "Step #100, epoch #100, avg. train loss: 2138598.00000\n",
      "Step #200, epoch #200, avg. train loss: 1538774.50000\n",
      "Step #100, epoch #33, avg. train loss: 2278154.75000\n",
      "Step #200, epoch #66, avg. train loss: 1796449.00000\n",
      "Step #100, epoch #33, avg. train loss: 2326442.25000\n",
      "Step #200, epoch #66, avg. train loss: 1712801.75000\n",
      "Step #100, epoch #33, avg. train loss: 2374387.25000\n",
      "Step #200, epoch #66, avg. train loss: 1780741.25000\n",
      "Step #100, epoch #100, avg. train loss: 2855683.50000\n",
      "Step #200, epoch #200, avg. train loss: 1654587.87500\n",
      "Step #100, epoch #100, avg. train loss: 2737382.75000\n",
      "Step #200, epoch #200, avg. train loss: 1470792.00000\n",
      "Step #100, epoch #100, avg. train loss: 2918710.00000\n",
      "Step #200, epoch #200, avg. train loss: 1691326.75000\n",
      "Step #100, epoch #50, avg. train loss: 2378738.75000\n",
      "Step #200, epoch #100, avg. train loss: 1447015.62500\n",
      "Step #100, epoch #50, avg. train loss: 2330913.75000\n",
      "Step #200, epoch #100, avg. train loss: 1488698.25000\n",
      "Step #100, epoch #50, avg. train loss: 2423364.75000\n",
      "Step #200, epoch #100, avg. train loss: 1496886.37500\n",
      "Step #100, epoch #100, avg. train loss: 2135746.00000\n",
      "Step #200, epoch #200, avg. train loss: 1546205.50000\n",
      "Step #100, epoch #100, avg. train loss: 2068617.87500\n",
      "Step #200, epoch #200, avg. train loss: 1438712.37500\n",
      "Step #100, epoch #100, avg. train loss: 2129166.25000\n",
      "Step #200, epoch #200, avg. train loss: 1449589.00000\n",
      "Step #100, epoch #100, avg. train loss: 2124676.25000\n",
      "Step #200, epoch #200, avg. train loss: 1441682.12500\n",
      "Step #100, epoch #100, avg. train loss: 2064437.00000\n",
      "Step #200, epoch #200, avg. train loss: 1425240.50000\n",
      "Step #100, epoch #100, avg. train loss: 2140767.50000\n",
      "Step #200, epoch #200, avg. train loss: 1489206.75000\n",
      "Step #100, epoch #50, avg. train loss: 2464558.00000\n",
      "Step #200, epoch #100, avg. train loss: 1658194.12500\n",
      "Step #100, epoch #50, avg. train loss: 2319624.25000\n",
      "Step #200, epoch #100, avg. train loss: 1550894.75000\n",
      "Step #100, epoch #50, avg. train loss: 2477009.50000\n",
      "Step #200, epoch #100, avg. train loss: 1623345.75000\n",
      "Step #100, epoch #50, avg. train loss: 2264417.25000\n",
      "Step #200, epoch #100, avg. train loss: 1493847.50000\n",
      "Step #100, epoch #50, avg. train loss: 2169087.75000\n",
      "Step #200, epoch #100, avg. train loss: 1469878.87500\n",
      "Step #100, epoch #50, avg. train loss: 2272008.25000\n",
      "Step #200, epoch #100, avg. train loss: 1506204.50000\n",
      "Step #100, epoch #50, avg. train loss: 2131597.50000\n",
      "Step #200, epoch #100, avg. train loss: 1509512.00000\n",
      "Step #100, epoch #50, avg. train loss: 2135927.00000\n",
      "Step #200, epoch #100, avg. train loss: 1511116.62500\n",
      "Step #100, epoch #50, avg. train loss: 2214426.00000\n",
      "Step #200, epoch #100, avg. train loss: 1643806.75000\n",
      "Step #100, epoch #9, avg. train loss: 2956250.50000\n",
      "Step #200, epoch #18, avg. train loss: 1680795.37500\n",
      "Step #100, epoch #9, avg. train loss: 2925732.25000\n",
      "Step #200, epoch #18, avg. train loss: 1510162.50000\n",
      "Step #100, epoch #9, avg. train loss: 3032447.00000\n",
      "Step #200, epoch #18, avg. train loss: 1631137.62500\n",
      "Step #100, epoch #100, avg. train loss: 3037537.25000\n",
      "Step #200, epoch #200, avg. train loss: 1531905.50000\n",
      "Step #100, epoch #100, avg. train loss: 2799099.50000\n",
      "Step #200, epoch #200, avg. train loss: 1525206.25000\n",
      "Step #100, epoch #100, avg. train loss: 2821719.75000\n",
      "Step #200, epoch #200, avg. train loss: 1586333.50000\n",
      "Step #100, epoch #100, avg. train loss: 2142429.25000\n",
      "Step #200, epoch #200, avg. train loss: 1500419.87500\n",
      "Step #100, epoch #100, avg. train loss: 2071045.62500\n",
      "Step #200, epoch #200, avg. train loss: 1482223.37500\n",
      "Step #100, epoch #100, avg. train loss: 2151104.25000\n",
      "Step #200, epoch #200, avg. train loss: 1487359.25000\n",
      "Step #100, epoch #100, avg. train loss: 2097557.50000\n",
      "Step #200, epoch #200, avg. train loss: 1482016.12500\n",
      "Step #100, epoch #100, avg. train loss: 2024401.87500\n",
      "Step #200, epoch #200, avg. train loss: 1433632.75000\n",
      "Step #100, epoch #100, avg. train loss: 2104999.00000\n",
      "Step #200, epoch #200, avg. train loss: 1492546.75000\n",
      "Step #100, epoch #100, avg. train loss: 2139976.50000\n",
      "Step #200, epoch #200, avg. train loss: 1618429.62500\n",
      "Step #100, epoch #100, avg. train loss: 2066677.25000\n",
      "Step #200, epoch #200, avg. train loss: 1529648.37500\n",
      "Step #100, epoch #100, avg. train loss: 2148211.25000\n",
      "Step #200, epoch #200, avg. train loss: 1616710.25000\n",
      "Step #100, epoch #100, avg. train loss: 2268471.25000\n",
      "Step #200, epoch #200, avg. train loss: 1582493.00000\n",
      "Step #100, epoch #100, avg. train loss: 2201222.75000\n",
      "Step #200, epoch #200, avg. train loss: 1506652.62500\n",
      "Step #100, epoch #100, avg. train loss: 2273864.75000\n",
      "Step #200, epoch #200, avg. train loss: 1590421.50000\n",
      "Step #100, epoch #33, avg. train loss: 3014963.50000\n",
      "Step #200, epoch #66, avg. train loss: 1639702.12500\n",
      "Step #100, epoch #33, avg. train loss: 2970601.25000\n",
      "Step #200, epoch #66, avg. train loss: 1658336.62500\n",
      "Step #100, epoch #33, avg. train loss: 3057607.25000\n",
      "Step #200, epoch #66, avg. train loss: 1688963.87500\n",
      "Step #100, epoch #50, avg. train loss: 3075973.75000\n",
      "Step #200, epoch #100, avg. train loss: 1490004.00000\n",
      "Step #100, epoch #50, avg. train loss: 2909169.25000\n",
      "Step #200, epoch #100, avg. train loss: 1497299.37500\n",
      "Step #100, epoch #50, avg. train loss: 2962692.25000\n",
      "Step #200, epoch #100, avg. train loss: 1526011.25000\n",
      "Step #100, epoch #100, avg. train loss: 2521830.00000\n",
      "Step #200, epoch #200, avg. train loss: 1670328.00000\n",
      "Step #100, epoch #100, avg. train loss: 2532143.50000\n",
      "Step #200, epoch #200, avg. train loss: 1643521.50000\n",
      "Step #100, epoch #100, avg. train loss: 2401385.50000\n",
      "Step #200, epoch #200, avg. train loss: 1548387.62500\n",
      "Step #100, epoch #100, avg. train loss: 2152176.75000\n",
      "Step #200, epoch #200, avg. train loss: 1613283.00000\n",
      "Step #100, epoch #100, avg. train loss: 2083443.50000\n",
      "Step #200, epoch #200, avg. train loss: 1511514.87500\n",
      "Step #100, epoch #100, avg. train loss: 2167201.00000\n",
      "Step #200, epoch #200, avg. train loss: 1640371.87500\n",
      "Step #100, epoch #16, avg. train loss: 2269354.50000\n",
      "Step #200, epoch #33, avg. train loss: 1475592.12500\n",
      "Step #100, epoch #16, avg. train loss: 2118214.50000\n",
      "Step #200, epoch #33, avg. train loss: 1577829.00000\n",
      "Step #100, epoch #16, avg. train loss: 2239907.00000\n",
      "Step #200, epoch #33, avg. train loss: 1583779.62500\n",
      "Step #100, epoch #50, avg. train loss: 2487326.25000\n",
      "Step #200, epoch #100, avg. train loss: 1563737.62500\n",
      "Step #100, epoch #50, avg. train loss: 2836566.75000\n",
      "Step #200, epoch #100, avg. train loss: 1584730.75000\n",
      "Step #100, epoch #50, avg. train loss: 2482969.25000\n",
      "Step #200, epoch #100, avg. train loss: 1602080.75000\n",
      "Step #100, epoch #50, avg. train loss: 11635334.00000\n",
      "Step #200, epoch #100, avg. train loss: 10865425.00000\n",
      "Step #100, epoch #50, avg. train loss: 11972189.00000\n",
      "Step #200, epoch #100, avg. train loss: 11184920.00000\n",
      "Step #100, epoch #50, avg. train loss: 11337103.00000\n",
      "Step #200, epoch #100, avg. train loss: 10582663.00000\n",
      "Step #100, epoch #20, avg. train loss: 2687211.00000\n",
      "Step #200, epoch #40, avg. train loss: 1683210.12500\n",
      "Step #100, epoch #20, avg. train loss: 2609671.75000\n",
      "Step #200, epoch #40, avg. train loss: 1627822.50000\n",
      "Step #100, epoch #20, avg. train loss: 2694664.25000\n",
      "Step #200, epoch #40, avg. train loss: 1625067.25000\n",
      "Step #100, epoch #100, avg. train loss: 2507684.25000\n",
      "Step #200, epoch #200, avg. train loss: 1658937.75000\n",
      "Step #100, epoch #100, avg. train loss: 2514644.25000\n",
      "Step #200, epoch #200, avg. train loss: 1641271.25000\n",
      "Step #100, epoch #100, avg. train loss: 2386572.00000\n",
      "Step #200, epoch #200, avg. train loss: 1547531.62500\n",
      "Step #100, epoch #100, avg. train loss: 2160842.50000\n",
      "Step #200, epoch #200, avg. train loss: 1629227.62500\n",
      "Step #100, epoch #100, avg. train loss: 2086207.37500\n",
      "Step #200, epoch #200, avg. train loss: 1520076.37500\n",
      "Step #100, epoch #100, avg. train loss: 2106299.00000\n",
      "Step #200, epoch #200, avg. train loss: 1391360.50000\n",
      "Step #100, epoch #50, avg. train loss: 2175303.00000\n",
      "Step #200, epoch #100, avg. train loss: 1591627.87500\n",
      "Step #100, epoch #50, avg. train loss: 2198180.00000\n",
      "Step #200, epoch #100, avg. train loss: 1537735.00000\n",
      "Step #100, epoch #50, avg. train loss: 2223352.50000\n",
      "Step #200, epoch #100, avg. train loss: 1521553.12500\n",
      "Step #100, epoch #100, avg. train loss: 2157809.75000\n",
      "Step #200, epoch #200, avg. train loss: 1497928.62500\n",
      "Step #100, epoch #100, avg. train loss: 2110388.00000\n",
      "Step #200, epoch #200, avg. train loss: 1452776.50000\n",
      "Step #100, epoch #100, avg. train loss: 2199471.75000\n",
      "Step #200, epoch #200, avg. train loss: 1523851.25000\n",
      "Step #100, epoch #100, avg. train loss: 2356877.00000\n",
      "Step #200, epoch #200, avg. train loss: 1608648.75000\n",
      "Step #100, epoch #100, avg. train loss: 2272931.00000\n",
      "Step #200, epoch #200, avg. train loss: 1551818.25000\n",
      "Step #100, epoch #100, avg. train loss: 2371364.75000\n",
      "Step #200, epoch #200, avg. train loss: 1583445.25000\n",
      "Step #100, epoch #100, avg. train loss: 2149936.25000\n",
      "Step #200, epoch #200, avg. train loss: 1653137.75000\n",
      "Step #100, epoch #100, avg. train loss: 2060023.62500\n",
      "Step #200, epoch #200, avg. train loss: 1490750.50000\n",
      "Step #100, epoch #100, avg. train loss: 2162412.75000\n",
      "Step #200, epoch #200, avg. train loss: 1617905.12500\n",
      "Step #100, epoch #20, avg. train loss: 3200162.00000\n",
      "Step #200, epoch #40, avg. train loss: 1582357.12500\n",
      "Step #100, epoch #20, avg. train loss: 3072148.75000\n",
      "Step #200, epoch #40, avg. train loss: 1493331.50000\n",
      "Step #100, epoch #20, avg. train loss: 3239459.00000\n",
      "Step #200, epoch #40, avg. train loss: 1516326.12500\n",
      "Step #100, epoch #100, avg. train loss: 2582734.50000\n",
      "Step #200, epoch #200, avg. train loss: 1633020.50000\n",
      "Step #100, epoch #100, avg. train loss: 2925382.50000\n",
      "Step #200, epoch #200, avg. train loss: 1655212.00000\n",
      "Step #100, epoch #100, avg. train loss: 2498169.25000\n",
      "Step #200, epoch #200, avg. train loss: 1598270.37500\n",
      "Step #100, epoch #100, avg. train loss: 2321505.50000\n",
      "Step #200, epoch #200, avg. train loss: 1599593.62500\n",
      "Step #100, epoch #100, avg. train loss: 2242590.50000\n",
      "Step #200, epoch #200, avg. train loss: 1536121.75000\n",
      "Step #100, epoch #100, avg. train loss: 2331062.25000\n",
      "Step #200, epoch #200, avg. train loss: 1595680.00000\n",
      "Step #100, epoch #100, avg. train loss: 2617361.00000\n",
      "Step #200, epoch #200, avg. train loss: 1751057.62500\n",
      "Step #100, epoch #100, avg. train loss: 2628665.50000\n",
      "Step #200, epoch #200, avg. train loss: 1635475.00000\n",
      "Step #100, epoch #100, avg. train loss: 2637177.50000\n",
      "Step #200, epoch #200, avg. train loss: 1490843.50000\n",
      "Step #100, epoch #25, avg. train loss: 2812687.25000\n",
      "Step #200, epoch #50, avg. train loss: 1554732.62500\n",
      "Step #100, epoch #25, avg. train loss: 2730792.75000\n",
      "Step #200, epoch #50, avg. train loss: 1536544.12500\n",
      "Step #100, epoch #25, avg. train loss: 2798740.50000\n",
      "Step #200, epoch #50, avg. train loss: 1529834.87500\n",
      "Step #100, epoch #25, avg. train loss: 2207797.75000\n",
      "Step #200, epoch #50, avg. train loss: 1652281.87500\n",
      "Step #100, epoch #25, avg. train loss: 2112080.25000\n",
      "Step #200, epoch #50, avg. train loss: 1526558.12500\n",
      "Step #100, epoch #25, avg. train loss: 2186389.25000\n",
      "Step #200, epoch #50, avg. train loss: 1521602.75000\n",
      "Step #100, epoch #100, avg. train loss: 2112314.25000\n",
      "Step #200, epoch #200, avg. train loss: 1557027.25000\n",
      "Step #100, epoch #100, avg. train loss: 2037449.62500\n",
      "Step #200, epoch #200, avg. train loss: 1458722.25000\n",
      "Step #100, epoch #100, avg. train loss: 2111537.50000\n",
      "Step #200, epoch #200, avg. train loss: 1494890.50000\n",
      "Step #100, epoch #50, avg. train loss: 3071218.25000\n",
      "Step #200, epoch #100, avg. train loss: 1540561.12500\n",
      "Step #100, epoch #50, avg. train loss: 3087440.00000\n",
      "Step #200, epoch #100, avg. train loss: 1470534.37500\n",
      "Step #100, epoch #50, avg. train loss: 2881305.25000\n",
      "Step #200, epoch #100, avg. train loss: 1544799.62500\n",
      "Step #100, epoch #25, avg. train loss: 3030948.50000\n",
      "Step #200, epoch #50, avg. train loss: 1561053.12500\n",
      "Step #100, epoch #25, avg. train loss: 2896765.00000\n",
      "Step #200, epoch #50, avg. train loss: 1475427.25000\n",
      "Step #100, epoch #25, avg. train loss: 2920397.50000\n",
      "Step #200, epoch #50, avg. train loss: 1516399.25000\n",
      "Step #100, epoch #25, avg. train loss: 2332507.00000\n",
      "Step #200, epoch #50, avg. train loss: 1661576.62500\n",
      "Step #100, epoch #25, avg. train loss: 2262351.00000\n",
      "Step #200, epoch #50, avg. train loss: 1584785.50000\n",
      "Step #100, epoch #25, avg. train loss: 2413093.00000\n",
      "Step #200, epoch #50, avg. train loss: 1591137.25000\n",
      "Step #100, epoch #100, avg. train loss: 2521385.00000\n",
      "Step #200, epoch #200, avg. train loss: 1646216.12500\n",
      "Step #100, epoch #100, avg. train loss: 2726627.75000\n",
      "Step #200, epoch #200, avg. train loss: 1654437.50000\n",
      "Step #100, epoch #100, avg. train loss: 2450083.00000\n",
      "Step #200, epoch #200, avg. train loss: 1599146.87500\n",
      "Step #100, epoch #100, avg. train loss: 2071403.00000\n",
      "Step #200, epoch #200, avg. train loss: 1586261.87500\n",
      "Step #100, epoch #100, avg. train loss: 1994137.00000\n",
      "Step #200, epoch #200, avg. train loss: 1458017.00000\n",
      "Step #100, epoch #100, avg. train loss: 2078387.87500\n",
      "Step #200, epoch #200, avg. train loss: 1571768.62500\n",
      "Step #100, epoch #50, avg. train loss: 3149303.00000\n",
      "Step #200, epoch #100, avg. train loss: 1507056.12500\n",
      "Step #100, epoch #50, avg. train loss: 3247004.25000\n",
      "Step #200, epoch #100, avg. train loss: 1566258.50000\n",
      "Step #100, epoch #50, avg. train loss: 3172579.25000\n",
      "Step #200, epoch #100, avg. train loss: 1532982.37500\n",
      "Step #100, epoch #100, avg. train loss: 3196571.50000\n",
      "Step #200, epoch #200, avg. train loss: 1512473.50000\n",
      "Step #100, epoch #100, avg. train loss: 3117647.75000\n",
      "Step #200, epoch #200, avg. train loss: 1495710.75000\n",
      "Step #100, epoch #100, avg. train loss: 3301209.25000\n",
      "Step #200, epoch #200, avg. train loss: 1643403.25000\n",
      "Step #100, epoch #12, avg. train loss: 3490073.25000\n",
      "Step #200, epoch #25, avg. train loss: 1817645.87500\n",
      "Step #100, epoch #12, avg. train loss: 3482230.75000\n",
      "Step #200, epoch #25, avg. train loss: 1729943.37500\n",
      "Step #100, epoch #12, avg. train loss: 3445963.00000\n",
      "Step #200, epoch #25, avg. train loss: 1833130.12500\n",
      "Step #100, epoch #50, avg. train loss: 2447900.25000\n",
      "Step #200, epoch #100, avg. train loss: 1562761.87500\n",
      "Step #100, epoch #50, avg. train loss: 2341764.75000\n",
      "Step #200, epoch #100, avg. train loss: 1515327.00000\n",
      "Step #100, epoch #50, avg. train loss: 2476108.00000\n",
      "Step #200, epoch #100, avg. train loss: 1560056.00000\n",
      "Step #100, epoch #4, avg. train loss: 2979531.00000\n",
      "Step #200, epoch #8, avg. train loss: 1737754.37500\n",
      "Step #100, epoch #4, avg. train loss: 2805120.25000\n",
      "Step #200, epoch #8, avg. train loss: 1596224.37500\n",
      "Step #100, epoch #4, avg. train loss: 2939081.00000\n",
      "Step #200, epoch #8, avg. train loss: 1633684.62500\n",
      "Step #100, epoch #100, avg. train loss: 2634448.00000\n",
      "Step #200, epoch #200, avg. train loss: 1714798.50000\n",
      "Step #100, epoch #100, avg. train loss: 2617268.50000\n",
      "Step #200, epoch #200, avg. train loss: 1641596.50000\n",
      "Step #100, epoch #100, avg. train loss: 2638519.00000\n",
      "Step #200, epoch #200, avg. train loss: 1492994.12500\n",
      "Step #100, epoch #50, avg. train loss: 2621157.25000\n",
      "Step #200, epoch #100, avg. train loss: 1552654.87500\n",
      "Step #100, epoch #50, avg. train loss: 2617235.25000\n",
      "Step #200, epoch #100, avg. train loss: 1595854.50000\n",
      "Step #100, epoch #50, avg. train loss: 2607018.00000\n",
      "Step #200, epoch #100, avg. train loss: 1536974.87500\n",
      "Step #100, epoch #100, avg. train loss: 2104884.75000\n",
      "Step #200, epoch #200, avg. train loss: 1625520.62500\n",
      "Step #100, epoch #100, avg. train loss: 2031783.00000\n",
      "Step #200, epoch #200, avg. train loss: 1527301.62500\n",
      "Step #100, epoch #100, avg. train loss: 2112642.00000\n",
      "Step #200, epoch #200, avg. train loss: 1625405.25000\n",
      "Step #100, epoch #50, avg. train loss: 2317970.50000\n",
      "Step #200, epoch #100, avg. train loss: 1535928.50000\n",
      "Step #100, epoch #50, avg. train loss: 2180677.00000\n",
      "Step #200, epoch #100, avg. train loss: 1418243.87500\n",
      "Step #100, epoch #50, avg. train loss: 2328708.25000\n",
      "Step #200, epoch #100, avg. train loss: 1541420.37500\n",
      "Step #100, epoch #33, avg. train loss: 2898758.75000\n",
      "Step #200, epoch #66, avg. train loss: 1469749.50000\n",
      "Step #100, epoch #33, avg. train loss: 2922410.00000\n",
      "Step #200, epoch #66, avg. train loss: 1478118.50000\n",
      "Step #100, epoch #33, avg. train loss: 2975104.25000\n",
      "Step #200, epoch #66, avg. train loss: 1458573.75000\n",
      "Step #100, epoch #100, avg. train loss: 2070573.50000\n",
      "Step #200, epoch #200, avg. train loss: 1617004.12500\n",
      "Step #100, epoch #100, avg. train loss: 1978905.75000\n",
      "Step #200, epoch #200, avg. train loss: 1461570.75000\n",
      "Step #100, epoch #100, avg. train loss: 2077890.37500\n",
      "Step #200, epoch #200, avg. train loss: 1574763.00000\n",
      "Step #100, epoch #100, avg. train loss: 2210611.75000\n",
      "Step #200, epoch #200, avg. train loss: 1619771.00000\n",
      "Step #100, epoch #100, avg. train loss: 2159402.50000\n",
      "Step #200, epoch #200, avg. train loss: 1608274.12500\n",
      "Step #100, epoch #100, avg. train loss: 2210296.25000\n",
      "Step #200, epoch #200, avg. train loss: 1606638.87500\n",
      "Step #100, epoch #100, avg. train loss: 2203962.00000\n",
      "Step #200, epoch #200, avg. train loss: 1578960.62500\n",
      "Step #100, epoch #100, avg. train loss: 2184316.25000\n",
      "Step #200, epoch #200, avg. train loss: 1376532.50000\n",
      "Step #100, epoch #100, avg. train loss: 2191405.50000\n",
      "Step #200, epoch #200, avg. train loss: 1570836.37500\n",
      "Step #100, epoch #14, avg. train loss: 2983930.25000\n",
      "Step #200, epoch #28, avg. train loss: 1638190.12500\n",
      "Step #100, epoch #14, avg. train loss: 2378997.75000\n",
      "Step #200, epoch #28, avg. train loss: 1598012.50000\n",
      "Step #100, epoch #14, avg. train loss: 2823135.75000\n",
      "Step #200, epoch #28, avg. train loss: 1552167.37500\n",
      "Step #100, epoch #100, avg. train loss: 2213810.00000\n",
      "Step #200, epoch #200, avg. train loss: 1689396.12500\n",
      "Step #100, epoch #100, avg. train loss: 2158107.25000\n",
      "Step #200, epoch #200, avg. train loss: 1673344.00000\n",
      "Step #100, epoch #100, avg. train loss: 2211082.25000\n",
      "Step #200, epoch #200, avg. train loss: 1696139.50000\n",
      "Step #100, epoch #100, avg. train loss: 3725250.50000\n",
      "Step #200, epoch #200, avg. train loss: 1600618.37500\n",
      "Step #100, epoch #100, avg. train loss: 3583334.50000\n",
      "Step #200, epoch #200, avg. train loss: 1475224.62500\n",
      "Step #100, epoch #100, avg. train loss: 3703402.50000\n",
      "Step #200, epoch #200, avg. train loss: 1530773.50000\n",
      "Step #100, epoch #100, avg. train loss: 2329993.00000\n",
      "Step #200, epoch #200, avg. train loss: 1549848.62500\n",
      "Step #100, epoch #100, avg. train loss: 2242136.00000\n",
      "Step #200, epoch #200, avg. train loss: 1503921.12500\n",
      "Step #100, epoch #100, avg. train loss: 2329380.00000\n",
      "Step #200, epoch #200, avg. train loss: 1488977.75000\n",
      "Step #100, epoch #50, avg. train loss: 2217747.75000\n",
      "Step #200, epoch #100, avg. train loss: 1596866.12500\n",
      "Step #100, epoch #50, avg. train loss: 2116471.00000\n",
      "Step #200, epoch #100, avg. train loss: 1526462.25000\n",
      "Step #100, epoch #50, avg. train loss: 2229745.75000\n",
      "Step #200, epoch #100, avg. train loss: 1653648.75000\n",
      "Step #100, epoch #100, avg. train loss: 2211460.25000\n",
      "Step #200, epoch #200, avg. train loss: 1480641.00000\n",
      "Step #100, epoch #100, avg. train loss: 2153992.25000\n",
      "Step #200, epoch #200, avg. train loss: 1426333.25000\n",
      "Step #100, epoch #100, avg. train loss: 2211858.75000\n",
      "Step #200, epoch #200, avg. train loss: 1479914.37500\n",
      "Step #100, epoch #100, avg. train loss: 2069826.50000\n",
      "Step #200, epoch #200, avg. train loss: 1622297.62500\n",
      "Step #100, epoch #100, avg. train loss: 1983529.75000\n",
      "Step #200, epoch #200, avg. train loss: 1487943.00000\n",
      "Step #100, epoch #100, avg. train loss: 2080829.87500\n",
      "Step #200, epoch #200, avg. train loss: 1585357.75000\n",
      "Step #100, epoch #100, avg. train loss: 5447822.50000\n",
      "Step #200, epoch #200, avg. train loss: 1806683.87500\n",
      "Step #100, epoch #100, avg. train loss: 5481417.50000\n",
      "Step #200, epoch #200, avg. train loss: 1716988.00000\n",
      "Step #100, epoch #100, avg. train loss: 5238188.50000\n",
      "Step #200, epoch #200, avg. train loss: 1828331.87500\n",
      "Step #100, epoch #100, avg. train loss: 2122404.50000\n",
      "Step #200, epoch #200, avg. train loss: 1617620.00000\n",
      "Step #100, epoch #100, avg. train loss: 2060894.87500\n",
      "Step #200, epoch #200, avg. train loss: 1572071.50000\n",
      "Step #100, epoch #100, avg. train loss: 2121974.00000\n",
      "Step #200, epoch #200, avg. train loss: 1602721.25000\n",
      "Step #100, epoch #50, avg. train loss: 3050388.50000\n",
      "Step #200, epoch #100, avg. train loss: 1567709.75000\n",
      "Step #100, epoch #50, avg. train loss: 3093075.75000\n",
      "Step #200, epoch #100, avg. train loss: 1524994.25000\n",
      "Step #100, epoch #50, avg. train loss: 2971070.75000\n",
      "Step #200, epoch #100, avg. train loss: 1519730.75000\n",
      "Step #100, epoch #20, avg. train loss: 2265284.75000\n",
      "Step #200, epoch #40, avg. train loss: 1753209.75000\n",
      "Step #100, epoch #20, avg. train loss: 2183244.75000\n",
      "Step #200, epoch #40, avg. train loss: 1653845.62500\n",
      "Step #100, epoch #16, avg. train loss: 2249163.00000\n",
      "Step #200, epoch #33, avg. train loss: 1743386.12500\n",
      "Step #100, epoch #100, avg. train loss: 2914545.50000\n",
      "Step #200, epoch #200, avg. train loss: 1509116.75000\n",
      "Step #100, epoch #100, avg. train loss: 2903823.75000\n",
      "Step #200, epoch #200, avg. train loss: 1490968.12500\n",
      "Step #100, epoch #100, avg. train loss: 2896326.50000\n",
      "Step #200, epoch #200, avg. train loss: 1633318.25000\n",
      "Step #100, epoch #100, avg. train loss: 2055640.50000\n",
      "Step #200, epoch #200, avg. train loss: 1575251.87500\n",
      "Step #100, epoch #100, avg. train loss: 1972447.50000\n",
      "Step #200, epoch #200, avg. train loss: 1482916.62500\n",
      "Step #100, epoch #100, avg. train loss: 2055788.37500\n",
      "Step #200, epoch #200, avg. train loss: 1535176.62500\n",
      "Step #100, epoch #100, avg. train loss: 2526880.00000\n",
      "Step #200, epoch #200, avg. train loss: 1672713.12500\n",
      "Step #100, epoch #100, avg. train loss: 2544343.25000\n",
      "Step #200, epoch #200, avg. train loss: 1645425.62500\n",
      "Step #100, epoch #100, avg. train loss: 2400512.75000\n",
      "Step #200, epoch #200, avg. train loss: 1551144.50000\n",
      "Step #100, epoch #100, avg. train loss: 2070498.75000\n",
      "Step #200, epoch #200, avg. train loss: 1592356.50000\n",
      "Step #100, epoch #100, avg. train loss: 2016534.50000\n",
      "Step #200, epoch #200, avg. train loss: 1607043.37500\n",
      "Step #100, epoch #100, avg. train loss: 2079919.00000\n",
      "Step #200, epoch #200, avg. train loss: 1587735.87500\n",
      "Step #100, epoch #100, avg. train loss: 2198315.25000\n",
      "Step #200, epoch #200, avg. train loss: 1628372.12500\n",
      "Step #100, epoch #100, avg. train loss: 2138853.00000\n",
      "Step #200, epoch #200, avg. train loss: 1474299.25000\n",
      "Step #100, epoch #100, avg. train loss: 2216773.00000\n",
      "Step #200, epoch #200, avg. train loss: 1515970.75000\n",
      "Step #100, epoch #100, avg. train loss: 2220989.50000\n",
      "Step #200, epoch #200, avg. train loss: 1560227.37500\n",
      "Step #100, epoch #100, avg. train loss: 2156660.00000\n",
      "Step #200, epoch #200, avg. train loss: 1525156.12500\n",
      "Step #100, epoch #100, avg. train loss: 2216491.50000\n",
      "Step #200, epoch #200, avg. train loss: 1516937.00000\n",
      "Step #100, epoch #25, avg. train loss: 3054020.75000\n",
      "Step #200, epoch #50, avg. train loss: 1722811.00000\n",
      "Step #100, epoch #25, avg. train loss: 3482816.00000\n",
      "Step #200, epoch #50, avg. train loss: 1667798.12500\n",
      "Step #100, epoch #25, avg. train loss: 3263659.50000\n",
      "Step #200, epoch #50, avg. train loss: 1537836.12500\n",
      "Step #100, epoch #2, avg. train loss: 2969190.75000\n",
      "Step #200, epoch #4, avg. train loss: 1841023.37500\n",
      "Step #100, epoch #2, avg. train loss: 3029617.00000\n",
      "Step #200, epoch #4, avg. train loss: 1732190.37500\n",
      "Step #100, epoch #2, avg. train loss: 2939432.25000\n",
      "Step #200, epoch #4, avg. train loss: 1870226.87500\n",
      "Step #100, epoch #100, avg. train loss: 2205979.25000\n",
      "Step #200, epoch #200, avg. train loss: 1404846.12500\n",
      "Step #100, epoch #100, avg. train loss: 2262304.50000\n",
      "Step #200, epoch #200, avg. train loss: 1413711.25000\n",
      "Step #100, epoch #100, avg. train loss: 2209130.00000\n",
      "Step #200, epoch #200, avg. train loss: 1563902.50000\n",
      "Step #100, epoch #50, avg. train loss: 2294249.25000\n",
      "Step #200, epoch #100, avg. train loss: 1543351.50000\n",
      "Step #100, epoch #50, avg. train loss: 2240996.75000\n",
      "Step #200, epoch #100, avg. train loss: 1550503.50000\n",
      "Step #100, epoch #50, avg. train loss: 2350747.50000\n",
      "Step #200, epoch #100, avg. train loss: 1608971.37500\n",
      "Step #100, epoch #33, avg. train loss: 3013178.00000\n",
      "Step #200, epoch #66, avg. train loss: 1509218.50000\n",
      "Step #100, epoch #33, avg. train loss: 2965761.00000\n",
      "Step #200, epoch #66, avg. train loss: 1531327.62500\n",
      "Step #100, epoch #33, avg. train loss: 2854723.25000\n",
      "Step #200, epoch #66, avg. train loss: 1546532.12500\n",
      "Step #100, epoch #11, avg. train loss: 3389915.50000\n",
      "Step #200, epoch #22, avg. train loss: 1601816.75000\n",
      "Step #100, epoch #11, avg. train loss: 2889379.25000\n",
      "Step #200, epoch #22, avg. train loss: 1524399.37500\n",
      "Step #100, epoch #11, avg. train loss: 3293923.00000\n",
      "Step #200, epoch #22, avg. train loss: 1569404.50000\n",
      "Step #100, epoch #100, avg. train loss: 2543786.00000\n",
      "Step #200, epoch #200, avg. train loss: 1522209.12500\n",
      "Step #100, epoch #100, avg. train loss: 2456067.25000\n",
      "Step #200, epoch #200, avg. train loss: 1552721.25000\n",
      "Step #100, epoch #100, avg. train loss: 2551677.25000\n",
      "Step #200, epoch #200, avg. train loss: 1497841.00000\n",
      "Step #100, epoch #4, avg. train loss: 2752052.75000\n",
      "Step #200, epoch #9, avg. train loss: 1660510.37500\n",
      "Step #100, epoch #4, avg. train loss: 2948931.00000\n",
      "Step #200, epoch #9, avg. train loss: 1572148.75000\n",
      "Step #100, epoch #4, avg. train loss: 2945335.75000\n",
      "Step #200, epoch #9, avg. train loss: 1764195.87500\n",
      "Step #100, epoch #3, avg. train loss: 5455876.00000\n",
      "Step #200, epoch #7, avg. train loss: 1886215.25000\n",
      "Step #100, epoch #3, avg. train loss: 5424982.50000\n",
      "Step #200, epoch #7, avg. train loss: 1853178.37500\n",
      "Step #100, epoch #3, avg. train loss: 5250549.00000\n",
      "Step #200, epoch #7, avg. train loss: 1920678.37500\n",
      "Step #100, epoch #50, avg. train loss: 2236289.75000\n",
      "Step #200, epoch #100, avg. train loss: 1531436.00000\n",
      "Step #100, epoch #50, avg. train loss: 2162793.00000\n",
      "Step #200, epoch #100, avg. train loss: 1467134.87500\n",
      "Step #100, epoch #50, avg. train loss: 2268809.50000\n",
      "Step #200, epoch #100, avg. train loss: 1603698.50000\n",
      "Step #100, epoch #50, avg. train loss: 2292734.50000\n",
      "Step #200, epoch #100, avg. train loss: 1649145.62500\n",
      "Step #100, epoch #50, avg. train loss: 2240979.00000\n",
      "Step #200, epoch #100, avg. train loss: 1609505.12500\n",
      "Step #100, epoch #50, avg. train loss: 2330340.75000\n",
      "Step #200, epoch #100, avg. train loss: 1653841.25000\n",
      "Step #100, epoch #100, avg. train loss: 2207835.00000\n",
      "Step #200, epoch #200, avg. train loss: 1700894.37500\n",
      "Step #100, epoch #100, avg. train loss: 2133820.25000\n",
      "Step #200, epoch #200, avg. train loss: 1606601.00000\n",
      "Step #100, epoch #100, avg. train loss: 2213812.25000\n",
      "Step #200, epoch #200, avg. train loss: 1707050.87500\n",
      "Step #100, epoch #100, avg. train loss: 2575405.25000\n",
      "Step #200, epoch #200, avg. train loss: 1644375.87500\n",
      "Step #100, epoch #100, avg. train loss: 2904403.00000\n",
      "Step #200, epoch #200, avg. train loss: 1653091.87500\n",
      "Step #100, epoch #100, avg. train loss: 2492121.00000\n",
      "Step #200, epoch #200, avg. train loss: 1598273.00000\n",
      "Step #100, epoch #50, avg. train loss: 2971309.00000\n",
      "Step #200, epoch #100, avg. train loss: 1788034.87500\n",
      "Step #100, epoch #50, avg. train loss: 2942483.25000\n",
      "Step #200, epoch #100, avg. train loss: 1714343.25000\n",
      "Step #100, epoch #50, avg. train loss: 2938381.50000\n",
      "Step #200, epoch #100, avg. train loss: 1809096.75000\n",
      "Step #100, epoch #2, avg. train loss: 2910763.50000\n",
      "Step #200, epoch #5, avg. train loss: 1774803.25000\n",
      "Step #100, epoch #2, avg. train loss: 2920109.75000\n",
      "Step #200, epoch #5, avg. train loss: 1694745.75000\n",
      "Step #100, epoch #2, avg. train loss: 2811072.25000\n",
      "Step #200, epoch #5, avg. train loss: 1680161.75000\n",
      "Step #100, epoch #50, avg. train loss: 2095150.87500\n",
      "Step #200, epoch #100, avg. train loss: 1671326.12500\n",
      "Step #100, epoch #50, avg. train loss: 2033827.50000\n",
      "Step #200, epoch #100, avg. train loss: 1636972.37500\n",
      "Step #100, epoch #50, avg. train loss: 2109616.75000\n",
      "Step #200, epoch #100, avg. train loss: 1637361.75000\n",
      "Step #100, epoch #25, avg. train loss: 2293193.75000\n",
      "Step #200, epoch #50, avg. train loss: 1692706.12500\n",
      "Step #100, epoch #25, avg. train loss: 2192454.75000\n",
      "Step #200, epoch #50, avg. train loss: 1628454.37500\n",
      "Step #100, epoch #25, avg. train loss: 2299498.50000\n",
      "Step #200, epoch #50, avg. train loss: 1735803.62500\n",
      "Step #100, epoch #50, avg. train loss: 2789417.00000\n",
      "Step #200, epoch #100, avg. train loss: 1582333.25000\n",
      "Step #100, epoch #50, avg. train loss: 2620630.25000\n",
      "Step #200, epoch #100, avg. train loss: 1493276.37500\n",
      "Step #100, epoch #50, avg. train loss: 2684026.50000\n",
      "Step #200, epoch #100, avg. train loss: 1531771.50000\n",
      "Step #100, epoch #100, avg. train loss: 9988995.00000\n",
      "Step #200, epoch #200, avg. train loss: 7403774.00000\n",
      "Step #100, epoch #100, avg. train loss: 10287139.00000\n",
      "Step #200, epoch #200, avg. train loss: 7631670.00000\n",
      "Step #100, epoch #100, avg. train loss: 9725755.00000\n",
      "Step #200, epoch #200, avg. train loss: 7200532.00000\n",
      "Step #100, epoch #100, avg. train loss: 2178290.50000\n",
      "Step #200, epoch #200, avg. train loss: 1532289.00000\n",
      "Step #100, epoch #100, avg. train loss: 2099155.00000\n",
      "Step #200, epoch #200, avg. train loss: 1495031.25000\n",
      "Step #100, epoch #100, avg. train loss: 2187781.50000\n",
      "Step #200, epoch #200, avg. train loss: 1538830.37500\n",
      "Step #100, epoch #100, avg. train loss: 2122182.00000\n",
      "Step #200, epoch #200, avg. train loss: 1435168.00000\n",
      "Step #100, epoch #100, avg. train loss: 2064917.87500\n",
      "Step #200, epoch #200, avg. train loss: 1413131.00000\n",
      "Step #100, epoch #100, avg. train loss: 2137987.00000\n",
      "Step #200, epoch #200, avg. train loss: 1461153.75000\n",
      "Step #100, epoch #33, avg. train loss: 2196018.00000\n",
      "Step #200, epoch #66, avg. train loss: 1686857.87500\n",
      "Step #100, epoch #33, avg. train loss: 2131249.50000\n",
      "Step #200, epoch #66, avg. train loss: 1572782.37500\n",
      "Step #100, epoch #33, avg. train loss: 2215203.50000\n",
      "Step #200, epoch #66, avg. train loss: 1643714.12500\n",
      "Step #100, epoch #100, avg. train loss: 2106260.75000\n",
      "Step #200, epoch #200, avg. train loss: 1639480.37500\n",
      "Step #100, epoch #100, avg. train loss: 2022286.25000\n",
      "Step #200, epoch #200, avg. train loss: 1577398.12500\n",
      "Step #100, epoch #100, avg. train loss: 2120984.25000\n",
      "Step #200, epoch #200, avg. train loss: 1628307.50000\n",
      "Step #100, epoch #100, avg. train loss: 2301912.00000\n",
      "Step #200, epoch #200, avg. train loss: 1479696.37500\n",
      "Step #100, epoch #100, avg. train loss: 2234885.25000\n",
      "Step #200, epoch #200, avg. train loss: 1418408.50000\n",
      "Step #100, epoch #100, avg. train loss: 2309758.50000\n",
      "Step #200, epoch #200, avg. train loss: 1469267.00000\n",
      "Step #100, epoch #100, avg. train loss: 2275890.75000\n",
      "Step #200, epoch #200, avg. train loss: 1402701.75000\n",
      "Step #100, epoch #100, avg. train loss: 2167250.50000\n",
      "Step #200, epoch #200, avg. train loss: 1417172.00000\n",
      "Step #100, epoch #100, avg. train loss: 2221891.25000\n",
      "Step #200, epoch #200, avg. train loss: 1476349.50000\n",
      "Step #100, epoch #50, avg. train loss: 2102082.25000\n",
      "Step #200, epoch #100, avg. train loss: 1608264.00000\n",
      "Step #100, epoch #50, avg. train loss: 2052429.75000\n",
      "Step #200, epoch #100, avg. train loss: 1547392.12500\n",
      "Step #100, epoch #50, avg. train loss: 2191859.75000\n",
      "Step #200, epoch #100, avg. train loss: 1526053.00000\n",
      "Step #100, epoch #100, avg. train loss: 3060727.75000\n",
      "Step #200, epoch #200, avg. train loss: 1704256.75000\n",
      "Step #100, epoch #100, avg. train loss: 3045596.50000\n",
      "Step #200, epoch #200, avg. train loss: 1624438.37500\n",
      "Step #100, epoch #100, avg. train loss: 3029661.00000\n",
      "Step #200, epoch #200, avg. train loss: 1719241.12500\n",
      "Step #100, epoch #50, avg. train loss: 2235128.50000\n",
      "Step #200, epoch #100, avg. train loss: 1493112.00000\n",
      "Step #100, epoch #50, avg. train loss: 2145369.50000\n",
      "Step #200, epoch #100, avg. train loss: 1483105.50000\n",
      "Step #100, epoch #50, avg. train loss: 2269899.75000\n",
      "Step #200, epoch #100, avg. train loss: 1573782.50000\n",
      "Step #100, epoch #20, avg. train loss: 2183592.75000\n",
      "Step #200, epoch #40, avg. train loss: 1638986.87500\n",
      "Step #100, epoch #20, avg. train loss: 2078248.37500\n",
      "Step #200, epoch #40, avg. train loss: 1533041.00000\n",
      "Step #100, epoch #20, avg. train loss: 2166507.25000\n",
      "Step #200, epoch #40, avg. train loss: 1662843.87500\n",
      "Step #100, epoch #33, avg. train loss: 2319005.25000\n",
      "Step #200, epoch #66, avg. train loss: 1507025.25000\n",
      "Step #100, epoch #33, avg. train loss: 2197859.25000\n",
      "Step #200, epoch #66, avg. train loss: 1465613.00000\n",
      "Step #100, epoch #33, avg. train loss: 2241881.50000\n",
      "Step #200, epoch #66, avg. train loss: 1464903.25000\n",
      "Step #100, epoch #100, avg. train loss: 2505464.25000\n",
      "Step #200, epoch #200, avg. train loss: 1667504.75000\n",
      "Step #100, epoch #100, avg. train loss: 2620541.50000\n",
      "Step #200, epoch #200, avg. train loss: 1652200.50000\n",
      "Step #100, epoch #100, avg. train loss: 2421957.00000\n",
      "Step #200, epoch #200, avg. train loss: 1587107.62500\n",
      "Step #100, epoch #100, avg. train loss: 2109762.50000\n",
      "Step #200, epoch #200, avg. train loss: 1637609.50000\n",
      "Step #100, epoch #100, avg. train loss: 2030763.50000\n",
      "Step #200, epoch #200, avg. train loss: 1602360.75000\n",
      "Step #100, epoch #100, avg. train loss: 2104930.25000\n",
      "Step #200, epoch #200, avg. train loss: 1496404.75000\n",
      "Step #100, epoch #3, avg. train loss: 3084746.50000\n",
      "Step #200, epoch #6, avg. train loss: 1825884.75000\n",
      "Step #100, epoch #3, avg. train loss: 3027205.00000\n",
      "Step #200, epoch #6, avg. train loss: 1652704.37500\n",
      "Step #100, epoch #3, avg. train loss: 3134829.00000\n",
      "Step #200, epoch #6, avg. train loss: 1684299.62500\n",
      "Step #100, epoch #50, avg. train loss: 3654788.25000\n",
      "Step #200, epoch #100, avg. train loss: 1801691.62500\n",
      "Step #100, epoch #50, avg. train loss: 3654169.00000\n",
      "Step #200, epoch #100, avg. train loss: 1725418.12500\n",
      "Step #100, epoch #50, avg. train loss: 3554920.25000\n",
      "Step #200, epoch #100, avg. train loss: 1807023.62500\n",
      "Step #100, epoch #100, avg. train loss: 2066348.00000\n",
      "Step #200, epoch #200, avg. train loss: 1601042.50000\n",
      "Step #100, epoch #100, avg. train loss: 1986807.37500\n",
      "Step #200, epoch #200, avg. train loss: 1517963.37500\n",
      "Step #100, epoch #100, avg. train loss: 2081476.50000\n",
      "Step #200, epoch #200, avg. train loss: 1573482.75000\n",
      "Step #100, epoch #100, avg. train loss: 2136346.00000\n",
      "Step #200, epoch #200, avg. train loss: 1657990.12500\n",
      "Step #100, epoch #100, avg. train loss: 2064414.50000\n",
      "Step #200, epoch #200, avg. train loss: 1605367.87500\n",
      "Step #100, epoch #100, avg. train loss: 2136294.50000\n",
      "Step #200, epoch #200, avg. train loss: 1640058.87500\n",
      "Step #100, epoch #50, avg. train loss: 2109359.75000\n",
      "Step #200, epoch #100, avg. train loss: 1487447.62500\n",
      "Step #100, epoch #50, avg. train loss: 2050299.00000\n",
      "Step #200, epoch #100, avg. train loss: 1501809.25000\n",
      "Step #100, epoch #50, avg. train loss: 2156156.50000\n",
      "Step #200, epoch #100, avg. train loss: 1531529.62500\n",
      "Step #100, epoch #50, avg. train loss: 2076224.50000\n",
      "Step #200, epoch #100, avg. train loss: 1596153.62500\n",
      "Step #100, epoch #50, avg. train loss: 1983071.00000\n",
      "Step #200, epoch #100, avg. train loss: 1548342.37500\n",
      "Step #100, epoch #50, avg. train loss: 2087830.75000\n",
      "Step #200, epoch #100, avg. train loss: 1578241.62500\n",
      "Step #100, epoch #100, avg. train loss: 2280638.50000\n",
      "Step #200, epoch #200, avg. train loss: 1637179.00000\n",
      "Step #100, epoch #100, avg. train loss: 2228934.75000\n",
      "Step #200, epoch #200, avg. train loss: 1597604.37500\n",
      "Step #100, epoch #100, avg. train loss: 2287531.00000\n",
      "Step #200, epoch #200, avg. train loss: 1691411.00000\n",
      "Step #100, epoch #33, avg. train loss: 2255842.25000\n",
      "Step #200, epoch #66, avg. train loss: 1671455.25000\n",
      "Step #100, epoch #33, avg. train loss: 2155160.75000\n",
      "Step #200, epoch #66, avg. train loss: 1595527.87500\n",
      "Step #100, epoch #33, avg. train loss: 2263156.50000\n",
      "Step #200, epoch #66, avg. train loss: 1632707.62500\n",
      "Step #100, epoch #50, avg. train loss: 2591019.75000\n",
      "Step #200, epoch #100, avg. train loss: 1648226.37500\n",
      "Step #100, epoch #50, avg. train loss: 2482354.00000\n",
      "Step #200, epoch #100, avg. train loss: 1607910.87500\n",
      "Step #100, epoch #50, avg. train loss: 2543981.00000\n",
      "Step #200, epoch #100, avg. train loss: 1665068.12500\n",
      "Step #100, epoch #100, avg. train loss: 2712901.75000\n",
      "Step #200, epoch #200, avg. train loss: 1553685.12500\n",
      "Step #100, epoch #100, avg. train loss: 2746509.00000\n",
      "Step #200, epoch #200, avg. train loss: 1518869.12500\n",
      "Step #100, epoch #100, avg. train loss: 2704384.75000\n",
      "Step #200, epoch #200, avg. train loss: 1520829.62500\n",
      "Step #100, epoch #100, avg. train loss: 2122043.75000\n",
      "Step #200, epoch #200, avg. train loss: 1546147.00000\n",
      "Step #100, epoch #100, avg. train loss: 2044010.87500\n",
      "Step #200, epoch #200, avg. train loss: 1442151.37500\n",
      "Step #100, epoch #100, avg. train loss: 2130615.25000\n",
      "Step #200, epoch #200, avg. train loss: 1523391.87500\n",
      "Step #100, epoch #50, avg. train loss: 2209926.00000\n",
      "Step #200, epoch #100, avg. train loss: 1517198.50000\n",
      "Step #100, epoch #50, avg. train loss: 2159160.25000\n",
      "Step #200, epoch #100, avg. train loss: 1521530.37500\n",
      "Step #100, epoch #50, avg. train loss: 2199579.25000\n",
      "Step #200, epoch #100, avg. train loss: 1565307.62500\n",
      "Step #100, epoch #100, avg. train loss: 2403674.00000\n",
      "Step #200, epoch #200, avg. train loss: 1546132.12500\n",
      "Step #100, epoch #100, avg. train loss: 2330370.50000\n",
      "Step #200, epoch #200, avg. train loss: 1491784.00000\n",
      "Step #100, epoch #100, avg. train loss: 2438639.75000\n",
      "Step #200, epoch #200, avg. train loss: 1634278.75000\n",
      "Step #100, epoch #100, avg. train loss: 2219728.75000\n",
      "Step #200, epoch #200, avg. train loss: 1573395.37500\n",
      "Step #100, epoch #100, avg. train loss: 2155060.50000\n",
      "Step #200, epoch #200, avg. train loss: 1543263.87500\n",
      "Step #100, epoch #100, avg. train loss: 2206908.75000\n",
      "Step #200, epoch #200, avg. train loss: 1551175.50000\n",
      "Step #100, epoch #6, avg. train loss: 2192628.75000\n",
      "Step #200, epoch #13, avg. train loss: 1741730.25000\n",
      "Step #100, epoch #6, avg. train loss: 2183426.50000\n",
      "Step #200, epoch #13, avg. train loss: 1675085.50000\n",
      "Step #100, epoch #6, avg. train loss: 2194589.50000\n",
      "Step #200, epoch #13, avg. train loss: 1731956.12500\n",
      "Step #100, epoch #7, avg. train loss: 3527484.50000\n",
      "Step #200, epoch #15, avg. train loss: 1572111.62500\n",
      "Step #100, epoch #7, avg. train loss: 3032376.25000\n",
      "Step #200, epoch #15, avg. train loss: 1573197.00000\n",
      "Step #100, epoch #7, avg. train loss: 2992240.75000\n",
      "Step #200, epoch #15, avg. train loss: 1555391.62500\n",
      "Step #100, epoch #100, avg. train loss: 2414741.50000\n",
      "Step #200, epoch #200, avg. train loss: 1535854.37500\n",
      "Step #100, epoch #100, avg. train loss: 2363742.00000\n",
      "Step #200, epoch #200, avg. train loss: 1478726.87500\n",
      "Step #100, epoch #100, avg. train loss: 2445557.00000\n",
      "Step #200, epoch #200, avg. train loss: 1512672.62500\n",
      "Step #100, epoch #100, avg. train loss: 2120324.25000\n",
      "Step #200, epoch #200, avg. train loss: 1593020.62500\n",
      "Step #100, epoch #100, avg. train loss: 2049664.62500\n",
      "Step #200, epoch #200, avg. train loss: 1514889.00000\n",
      "Step #100, epoch #100, avg. train loss: 2127738.00000\n",
      "Step #200, epoch #200, avg. train loss: 1595770.75000\n",
      "Step #100, epoch #100, avg. train loss: 2204350.00000\n",
      "Step #200, epoch #200, avg. train loss: 1597355.00000\n",
      "Step #100, epoch #100, avg. train loss: 2146189.00000\n",
      "Step #200, epoch #200, avg. train loss: 1476409.12500\n",
      "Step #100, epoch #100, avg. train loss: 2234746.50000\n",
      "Step #200, epoch #200, avg. train loss: 1642269.62500\n",
      "Step #100, epoch #100, avg. train loss: 2082348.37500\n",
      "Step #200, epoch #200, avg. train loss: 1561077.75000\n",
      "Step #100, epoch #100, avg. train loss: 2013394.75000\n",
      "Step #200, epoch #200, avg. train loss: 1521557.62500\n",
      "Step #100, epoch #100, avg. train loss: 2105840.00000\n",
      "Step #200, epoch #200, avg. train loss: 1540704.37500\n",
      "Step #100, epoch #33, avg. train loss: 2913326.50000\n",
      "Step #200, epoch #66, avg. train loss: 1739237.12500\n",
      "Step #100, epoch #33, avg. train loss: 2391479.00000\n",
      "Step #200, epoch #66, avg. train loss: 1562613.62500\n",
      "Step #100, epoch #33, avg. train loss: 2501190.50000\n",
      "Step #200, epoch #66, avg. train loss: 1547476.37500\n",
      "Step #100, epoch #50, avg. train loss: 2795373.75000\n",
      "Step #200, epoch #100, avg. train loss: 1558957.75000\n",
      "Step #100, epoch #50, avg. train loss: 2702784.00000\n",
      "Step #200, epoch #100, avg. train loss: 1564017.75000\n",
      "Step #100, epoch #50, avg. train loss: 2772931.00000\n",
      "Step #200, epoch #100, avg. train loss: 1445001.25000\n",
      "Step #100, epoch #100, avg. train loss: 2339026.00000\n",
      "Step #200, epoch #200, avg. train loss: 1622358.87500\n",
      "Step #100, epoch #100, avg. train loss: 2247012.75000\n",
      "Step #200, epoch #200, avg. train loss: 1441377.00000\n",
      "Step #100, epoch #100, avg. train loss: 2316825.50000\n",
      "Step #200, epoch #200, avg. train loss: 1559923.50000\n",
      "Step #100, epoch #100, avg. train loss: 2507924.75000\n",
      "Step #200, epoch #200, avg. train loss: 1699955.50000\n",
      "Step #100, epoch #100, avg. train loss: 2465367.00000\n",
      "Step #200, epoch #200, avg. train loss: 1625915.25000\n",
      "Step #100, epoch #100, avg. train loss: 2497782.25000\n",
      "Step #200, epoch #200, avg. train loss: 1716150.12500\n",
      "Step #100, epoch #20, avg. train loss: 2985470.75000\n",
      "Step #200, epoch #40, avg. train loss: 1501654.12500\n",
      "Step #100, epoch #20, avg. train loss: 2905635.50000\n",
      "Step #200, epoch #40, avg. train loss: 1584603.50000\n",
      "Step #100, epoch #20, avg. train loss: 2984614.00000\n",
      "Step #200, epoch #40, avg. train loss: 1524342.37500\n",
      "Step #100, epoch #100, avg. train loss: 2682125.00000\n",
      "Step #200, epoch #200, avg. train loss: 1603247.87500\n",
      "Step #100, epoch #100, avg. train loss: 3344999.25000\n",
      "Step #200, epoch #200, avg. train loss: 1742212.62500\n",
      "Step #100, epoch #100, avg. train loss: 2628024.50000\n",
      "Step #200, epoch #200, avg. train loss: 1655211.25000\n",
      "Step #100, epoch #100, avg. train loss: 2084123.50000\n",
      "Step #200, epoch #200, avg. train loss: 1573726.50000\n",
      "Step #100, epoch #100, avg. train loss: 2020471.50000\n",
      "Step #200, epoch #200, avg. train loss: 1566290.37500\n",
      "Step #100, epoch #100, avg. train loss: 2091734.87500\n",
      "Step #200, epoch #200, avg. train loss: 1554478.87500\n",
      "Step #100, epoch #100, avg. train loss: 10200651.00000\n",
      "Step #200, epoch #200, avg. train loss: 8343051.50000\n",
      "Step #100, epoch #100, avg. train loss: 10496970.00000\n",
      "Step #200, epoch #200, avg. train loss: 8499804.00000\n",
      "Step #100, epoch #100, avg. train loss: 9927202.00000\n",
      "Step #200, epoch #200, avg. train loss: 8028622.00000\n",
      "Step #100, epoch #100, avg. train loss: 2161740.50000\n",
      "Step #200, epoch #200, avg. train loss: 1547703.50000\n",
      "Step #100, epoch #100, avg. train loss: 2077248.00000\n",
      "Step #200, epoch #200, avg. train loss: 1455821.25000\n",
      "Step #100, epoch #100, avg. train loss: 2174205.25000\n",
      "Step #200, epoch #200, avg. train loss: 1571288.12500\n",
      "Step #100, epoch #100, avg. train loss: 2785956.50000\n",
      "Step #200, epoch #200, avg. train loss: 1525133.25000\n",
      "Step #100, epoch #100, avg. train loss: 2656826.25000\n",
      "Step #200, epoch #200, avg. train loss: 1621626.12500\n",
      "Step #100, epoch #100, avg. train loss: 2753759.00000\n",
      "Step #200, epoch #200, avg. train loss: 1632625.50000\n",
      "Step #100, epoch #100, avg. train loss: 2354957.50000\n",
      "Step #200, epoch #200, avg. train loss: 1500494.50000\n",
      "Step #100, epoch #100, avg. train loss: 2286382.00000\n",
      "Step #200, epoch #200, avg. train loss: 1478192.50000\n",
      "Step #100, epoch #100, avg. train loss: 2346949.50000\n",
      "Step #200, epoch #200, avg. train loss: 1482618.25000\n",
      "Step #100, epoch #25, avg. train loss: 2745156.50000\n",
      "Step #200, epoch #50, avg. train loss: 1666728.50000\n",
      "Step #100, epoch #25, avg. train loss: 2734957.50000\n",
      "Step #200, epoch #50, avg. train loss: 1615974.87500\n",
      "Step #100, epoch #25, avg. train loss: 2594174.25000\n",
      "Step #200, epoch #50, avg. train loss: 1559469.00000\n",
      "Step #100, epoch #50, avg. train loss: 2773196.50000\n",
      "Step #200, epoch #100, avg. train loss: 1544439.87500\n",
      "Step #100, epoch #50, avg. train loss: 2985578.00000\n",
      "Step #200, epoch #100, avg. train loss: 1457608.00000\n",
      "Step #100, epoch #50, avg. train loss: 2750008.75000\n",
      "Step #200, epoch #100, avg. train loss: 1569230.87500\n",
      "Step #100, epoch #50, avg. train loss: 2824667.00000\n",
      "Step #200, epoch #100, avg. train loss: 1496408.12500\n",
      "Step #100, epoch #50, avg. train loss: 2608456.75000\n",
      "Step #200, epoch #100, avg. train loss: 1624439.87500\n",
      "Step #100, epoch #50, avg. train loss: 2843490.50000\n",
      "Step #200, epoch #100, avg. train loss: 1581868.62500\n",
      "Step #100, epoch #100, avg. train loss: 3064375.25000\n",
      "Step #200, epoch #200, avg. train loss: 1537017.12500\n",
      "Step #100, epoch #100, avg. train loss: 3033939.00000\n",
      "Step #200, epoch #200, avg. train loss: 1503896.62500\n",
      "Step #100, epoch #100, avg. train loss: 3047934.50000\n",
      "Step #200, epoch #200, avg. train loss: 1516538.87500\n",
      "Step #100, epoch #100, avg. train loss: 2207345.25000\n",
      "Step #200, epoch #200, avg. train loss: 1579573.25000\n",
      "Step #100, epoch #100, avg. train loss: 2122348.50000\n",
      "Step #200, epoch #200, avg. train loss: 1512112.75000\n",
      "Step #100, epoch #100, avg. train loss: 2219647.75000\n",
      "Step #200, epoch #200, avg. train loss: 1539845.62500\n",
      "Step #100, epoch #50, avg. train loss: 2444241.75000\n",
      "Step #200, epoch #100, avg. train loss: 1553949.00000\n",
      "Step #100, epoch #50, avg. train loss: 2763568.25000\n",
      "Step #200, epoch #100, avg. train loss: 1489535.25000\n",
      "Step #100, epoch #50, avg. train loss: 3804423.00000\n",
      "Step #200, epoch #100, avg. train loss: 1511699.37500\n",
      "Step #100, epoch #33, avg. train loss: 3996988.50000\n",
      "Step #200, epoch #66, avg. train loss: 1480269.25000\n",
      "Step #100, epoch #33, avg. train loss: 3600239.75000\n",
      "Step #200, epoch #66, avg. train loss: 1682293.00000\n",
      "Step #100, epoch #33, avg. train loss: 3531355.75000\n",
      "Step #200, epoch #66, avg. train loss: 1484804.00000\n",
      "Step #100, epoch #100, avg. train loss: 2803026.25000\n",
      "Step #200, epoch #200, avg. train loss: 1541000.00000\n",
      "Step #100, epoch #100, avg. train loss: 2725922.00000\n",
      "Step #200, epoch #200, avg. train loss: 1477456.12500\n",
      "Step #100, epoch #100, avg. train loss: 2799549.00000\n",
      "Step #200, epoch #200, avg. train loss: 1531298.87500\n",
      "Step #100, epoch #100, avg. train loss: 2290282.50000\n",
      "Step #200, epoch #200, avg. train loss: 1449277.87500\n",
      "Step #100, epoch #100, avg. train loss: 2211819.00000\n",
      "Step #200, epoch #200, avg. train loss: 1411271.25000\n",
      "Step #100, epoch #100, avg. train loss: 2286139.25000\n",
      "Step #200, epoch #200, avg. train loss: 1466988.37500\n",
      "Step #100, epoch #50, avg. train loss: 2103432.50000\n",
      "Step #200, epoch #100, avg. train loss: 1527321.87500\n",
      "Step #100, epoch #50, avg. train loss: 2046012.50000\n",
      "Step #200, epoch #100, avg. train loss: 1567877.12500\n",
      "Step #100, epoch #50, avg. train loss: 2159793.50000\n",
      "Step #200, epoch #100, avg. train loss: 1618405.12500\n",
      "Step #100, epoch #50, avg. train loss: 2326550.00000\n",
      "Step #200, epoch #100, avg. train loss: 1585509.62500\n",
      "Step #100, epoch #50, avg. train loss: 2257796.75000\n",
      "Step #200, epoch #100, avg. train loss: 1452534.50000\n",
      "Step #100, epoch #50, avg. train loss: 2238538.50000\n",
      "Step #200, epoch #100, avg. train loss: 1569093.12500\n",
      "Step #100, epoch #16, avg. train loss: 4885734.50000\n",
      "Step #200, epoch #33, avg. train loss: 1819259.87500\n",
      "Step #100, epoch #16, avg. train loss: 4983564.00000\n",
      "Step #200, epoch #33, avg. train loss: 1746941.75000\n",
      "Step #100, epoch #16, avg. train loss: 4782018.50000\n",
      "Step #200, epoch #33, avg. train loss: 1852999.87500\n",
      "Step #100, epoch #50, avg. train loss: 2209078.25000\n",
      "Step #200, epoch #100, avg. train loss: 1492775.37500\n",
      "Step #100, epoch #50, avg. train loss: 2146626.50000\n",
      "Step #200, epoch #100, avg. train loss: 1566050.87500\n",
      "Step #100, epoch #50, avg. train loss: 2179562.00000\n",
      "Step #200, epoch #100, avg. train loss: 1544731.37500\n",
      "Step #100, epoch #50, avg. train loss: 2267057.50000\n",
      "Step #200, epoch #100, avg. train loss: 1678253.00000\n",
      "Step #100, epoch #50, avg. train loss: 2197819.50000\n",
      "Step #200, epoch #100, avg. train loss: 1565458.75000\n",
      "Step #100, epoch #50, avg. train loss: 2267206.25000\n",
      "Step #200, epoch #100, avg. train loss: 1652896.50000\n",
      "Step #100, epoch #100, avg. train loss: 3821832.75000\n",
      "Step #200, epoch #200, avg. train loss: 1506828.62500\n",
      "Step #100, epoch #100, avg. train loss: 3752028.50000\n",
      "Step #200, epoch #200, avg. train loss: 1485300.50000\n",
      "Step #100, epoch #100, avg. train loss: 3829452.50000\n",
      "Step #200, epoch #200, avg. train loss: 1578333.25000\n",
      "Step #100, epoch #100, avg. train loss: 2126502.00000\n",
      "Step #200, epoch #200, avg. train loss: 1546009.62500\n",
      "Step #100, epoch #100, avg. train loss: 2050698.50000\n",
      "Step #200, epoch #200, avg. train loss: 1417559.62500\n",
      "Step #100, epoch #100, avg. train loss: 2116475.50000\n",
      "Step #200, epoch #200, avg. train loss: 1523549.87500\n",
      "Step #100, epoch #50, avg. train loss: 6282788.00000\n",
      "Step #200, epoch #100, avg. train loss: 1871301.50000\n",
      "Step #100, epoch #50, avg. train loss: 6299074.50000\n",
      "Step #200, epoch #100, avg. train loss: 1780906.75000\n",
      "Step #100, epoch #50, avg. train loss: 6059772.00000\n",
      "Step #200, epoch #100, avg. train loss: 1884911.25000\n",
      "Step #100, epoch #50, avg. train loss: 2407719.00000\n",
      "Step #200, epoch #100, avg. train loss: 1753332.37500\n",
      "Step #100, epoch #50, avg. train loss: 2390377.75000\n",
      "Step #200, epoch #100, avg. train loss: 1674158.50000\n",
      "Step #100, epoch #50, avg. train loss: 2393910.00000\n",
      "Step #200, epoch #100, avg. train loss: 1760010.12500\n",
      "Step #100, epoch #50, avg. train loss: 3120794.00000\n",
      "Step #200, epoch #100, avg. train loss: 1549392.12500\n",
      "Step #100, epoch #50, avg. train loss: 3056451.75000\n",
      "Step #200, epoch #100, avg. train loss: 1453691.25000\n",
      "Step #100, epoch #50, avg. train loss: 3075886.75000\n",
      "Step #200, epoch #100, avg. train loss: 1637560.75000\n",
      "Step #100, epoch #100, avg. train loss: 2072932.37500\n",
      "Step #200, epoch #200, avg. train loss: 1606028.50000\n",
      "Step #100, epoch #100, avg. train loss: 1992707.50000\n",
      "Step #200, epoch #200, avg. train loss: 1534021.00000\n",
      "Step #100, epoch #100, avg. train loss: 2086687.87500\n",
      "Step #200, epoch #200, avg. train loss: 1587550.37500\n",
      "Step #100, epoch #100, avg. train loss: 2118976.75000\n",
      "Step #200, epoch #200, avg. train loss: 1552358.25000\n",
      "Step #100, epoch #100, avg. train loss: 2039021.62500\n",
      "Step #200, epoch #200, avg. train loss: 1453034.75000\n",
      "Step #100, epoch #100, avg. train loss: 2127075.75000\n",
      "Step #200, epoch #200, avg. train loss: 1535918.75000\n",
      "Step #100, epoch #25, avg. train loss: 3755499.00000\n",
      "Step #200, epoch #50, avg. train loss: 1588243.37500\n",
      "Step #100, epoch #25, avg. train loss: 3851028.50000\n",
      "Step #200, epoch #50, avg. train loss: 1575360.62500\n",
      "Step #100, epoch #25, avg. train loss: 2606105.50000\n",
      "Step #200, epoch #50, avg. train loss: 1547285.25000\n",
      "Step #100, epoch #3, avg. train loss: 2562140.75000\n",
      "Step #200, epoch #6, avg. train loss: 1752519.50000\n",
      "Step #100, epoch #3, avg. train loss: 2563535.75000\n",
      "Step #200, epoch #6, avg. train loss: 1696946.37500\n",
      "Step #100, epoch #3, avg. train loss: 2326908.75000\n",
      "Step #200, epoch #6, avg. train loss: 1728169.62500\n",
      "Step #100, epoch #100, avg. train loss: 2218409.00000\n",
      "Step #200, epoch #200, avg. train loss: 1646528.50000\n",
      "Step #100, epoch #100, avg. train loss: 2150055.75000\n",
      "Step #200, epoch #200, avg. train loss: 1514172.37500\n",
      "Step #100, epoch #100, avg. train loss: 2236378.50000\n",
      "Step #200, epoch #200, avg. train loss: 1584038.12500\n",
      "Step #100, epoch #100, avg. train loss: 2105932.75000\n",
      "Step #200, epoch #200, avg. train loss: 1637161.75000\n",
      "Step #100, epoch #100, avg. train loss: 2021770.12500\n",
      "Step #200, epoch #200, avg. train loss: 1577063.37500\n",
      "Step #100, epoch #100, avg. train loss: 2120496.75000\n",
      "Step #200, epoch #200, avg. train loss: 1626531.50000\n",
      "Step #100, epoch #100, avg. train loss: 2222515.75000\n",
      "Step #200, epoch #200, avg. train loss: 1572341.50000\n",
      "Step #100, epoch #100, avg. train loss: 2140287.75000\n",
      "Step #200, epoch #200, avg. train loss: 1534304.12500\n",
      "Step #100, epoch #100, avg. train loss: 2239201.00000\n",
      "Step #200, epoch #200, avg. train loss: 1569640.62500\n",
      "Step #100, epoch #50, avg. train loss: 2080874.50000\n",
      "Step #200, epoch #100, avg. train loss: 1607637.62500\n",
      "Step #100, epoch #50, avg. train loss: 1980255.87500\n",
      "Step #200, epoch #100, avg. train loss: 1521535.25000\n",
      "Step #100, epoch #50, avg. train loss: 2083798.87500\n",
      "Step #200, epoch #100, avg. train loss: 1584104.50000\n",
      "Step #100, epoch #100, avg. train loss: 2934295.25000\n",
      "Step #200, epoch #200, avg. train loss: 1693841.62500\n",
      "Step #100, epoch #100, avg. train loss: 2835812.75000\n",
      "Step #200, epoch #200, avg. train loss: 1452596.37500\n",
      "Step #100, epoch #100, avg. train loss: 2803412.25000\n",
      "Step #200, epoch #200, avg. train loss: 1516074.37500\n",
      "Step #100, epoch #25, avg. train loss: 2148441.00000\n",
      "Step #200, epoch #50, avg. train loss: 1640745.87500\n",
      "Step #100, epoch #25, avg. train loss: 2049804.12500\n",
      "Step #200, epoch #50, avg. train loss: 1556994.87500\n",
      "Step #100, epoch #25, avg. train loss: 2141782.00000\n",
      "Step #200, epoch #50, avg. train loss: 1637771.87500\n",
      "Step #100, epoch #33, avg. train loss: 2296442.50000\n",
      "Step #200, epoch #66, avg. train loss: 1570335.25000\n",
      "Step #100, epoch #33, avg. train loss: 2176603.75000\n",
      "Step #200, epoch #66, avg. train loss: 1565385.00000\n",
      "Step #100, epoch #33, avg. train loss: 2306067.00000\n",
      "Step #200, epoch #66, avg. train loss: 1543027.00000\n",
      "Step #100, epoch #11, avg. train loss: 2101563.75000\n",
      "Step #200, epoch #22, avg. train loss: 1723692.62500\n",
      "Step #100, epoch #11, avg. train loss: 2046568.00000\n",
      "Step #200, epoch #22, avg. train loss: 1647269.50000\n",
      "Step #100, epoch #11, avg. train loss: 2145423.00000\n",
      "Step #200, epoch #22, avg. train loss: 1769347.62500\n",
      "Step #100, epoch #12, avg. train loss: 2140991.00000\n",
      "Step #200, epoch #25, avg. train loss: 1661772.62500\n",
      "Step #100, epoch #12, avg. train loss: 2063944.75000\n",
      "Step #200, epoch #25, avg. train loss: 1559734.50000\n",
      "Step #100, epoch #12, avg. train loss: 2165374.25000\n",
      "Step #200, epoch #25, avg. train loss: 1660223.50000\n",
      "Step #100, epoch #100, avg. train loss: 2302683.00000\n",
      "Step #200, epoch #200, avg. train loss: 1698640.12500\n",
      "Step #100, epoch #100, avg. train loss: 2249087.50000\n",
      "Step #200, epoch #200, avg. train loss: 1627728.62500\n",
      "Step #100, epoch #100, avg. train loss: 2297359.00000\n",
      "Step #200, epoch #200, avg. train loss: 1706745.50000\n",
      "Step #100, epoch #50, avg. train loss: 2167816.75000\n",
      "Step #200, epoch #100, avg. train loss: 1587684.50000\n",
      "Step #100, epoch #50, avg. train loss: 2120049.50000\n",
      "Step #200, epoch #100, avg. train loss: 1476816.37500\n",
      "Step #100, epoch #50, avg. train loss: 2161798.50000\n",
      "Step #200, epoch #100, avg. train loss: 1539119.37500\n",
      "Step #100, epoch #50, avg. train loss: 2668163.00000\n",
      "Step #200, epoch #100, avg. train loss: 1554228.75000\n",
      "Step #100, epoch #50, avg. train loss: 2631040.75000\n",
      "Step #200, epoch #100, avg. train loss: 1556596.50000\n",
      "Step #100, epoch #50, avg. train loss: 2698976.75000\n",
      "Step #200, epoch #100, avg. train loss: 1549017.62500\n",
      "Step #100, epoch #11, avg. train loss: 2148587.25000\n",
      "Step #200, epoch #22, avg. train loss: 1761451.62500\n",
      "Step #100, epoch #11, avg. train loss: 2119914.00000\n",
      "Step #200, epoch #22, avg. train loss: 1692774.37500\n",
      "Step #100, epoch #11, avg. train loss: 2175772.50000\n",
      "Step #200, epoch #22, avg. train loss: 1842650.12500\n",
      "Step #100, epoch #50, avg. train loss: 2129911.75000\n",
      "Step #200, epoch #100, avg. train loss: 1570332.50000\n",
      "Step #100, epoch #50, avg. train loss: 2055670.12500\n",
      "Step #200, epoch #100, avg. train loss: 1462644.12500\n",
      "Step #100, epoch #50, avg. train loss: 2135307.25000\n",
      "Step #200, epoch #100, avg. train loss: 1587091.00000\n",
      "Step #100, epoch #50, avg. train loss: 2467221.00000\n",
      "Step #200, epoch #100, avg. train loss: 1755607.00000\n",
      "Step #100, epoch #50, avg. train loss: 2422330.75000\n",
      "Step #200, epoch #100, avg. train loss: 1696768.62500\n",
      "Step #100, epoch #50, avg. train loss: 2464431.25000\n",
      "Step #200, epoch #100, avg. train loss: 1762910.12500\n",
      "Step #100, epoch #33, avg. train loss: 2550600.25000\n",
      "Step #200, epoch #66, avg. train loss: 1601977.00000\n",
      "Step #100, epoch #33, avg. train loss: 2483252.50000\n",
      "Step #200, epoch #66, avg. train loss: 1594929.50000\n",
      "Step #100, epoch #33, avg. train loss: 2548362.00000\n",
      "Step #200, epoch #66, avg. train loss: 1553589.87500\n",
      "Step #100, epoch #50, avg. train loss: 2104791.75000\n",
      "Step #200, epoch #100, avg. train loss: 1507921.50000\n",
      "Step #100, epoch #50, avg. train loss: 2053313.25000\n",
      "Step #200, epoch #100, avg. train loss: 1472388.50000\n",
      "Step #100, epoch #50, avg. train loss: 2168057.25000\n",
      "Step #200, epoch #100, avg. train loss: 1520226.12500\n",
      "Step #100, epoch #25, avg. train loss: 2623930.50000\n",
      "Step #200, epoch #50, avg. train loss: 1658175.25000\n",
      "Step #100, epoch #25, avg. train loss: 2604186.50000\n",
      "Step #200, epoch #50, avg. train loss: 1643100.62500\n",
      "Step #100, epoch #25, avg. train loss: 2525529.50000\n",
      "Step #200, epoch #50, avg. train loss: 1545313.87500\n",
      "Step #100, epoch #100, avg. train loss: 2930656.00000\n",
      "Step #200, epoch #200, avg. train loss: 1532059.37500\n",
      "Step #100, epoch #100, avg. train loss: 2870179.25000\n",
      "Step #200, epoch #200, avg. train loss: 1441363.50000\n",
      "Step #100, epoch #100, avg. train loss: 2940247.00000\n",
      "Step #200, epoch #200, avg. train loss: 1492093.50000\n",
      "Step #100, epoch #12, avg. train loss: 3199100.50000\n",
      "Step #200, epoch #25, avg. train loss: 1561943.37500\n",
      "Step #100, epoch #12, avg. train loss: 2633213.50000\n",
      "Step #200, epoch #25, avg. train loss: 1625741.25000\n",
      "Step #100, epoch #12, avg. train loss: 2613591.00000\n",
      "Step #200, epoch #25, avg. train loss: 1621226.37500\n",
      "Step #100, epoch #50, avg. train loss: 3259386.50000\n",
      "Step #200, epoch #100, avg. train loss: 1588485.00000\n",
      "Step #100, epoch #50, avg. train loss: 3218183.25000\n",
      "Step #200, epoch #100, avg. train loss: 1528346.25000\n",
      "Step #100, epoch #50, avg. train loss: 3181820.25000\n",
      "Step #200, epoch #100, avg. train loss: 1542480.37500\n",
      "Step #100, epoch #100, avg. train loss: 2989212.25000\n",
      "Step #200, epoch #200, avg. train loss: 1562013.12500\n",
      "Step #100, epoch #100, avg. train loss: 2940396.50000\n",
      "Step #200, epoch #200, avg. train loss: 1602974.37500\n",
      "Step #100, epoch #100, avg. train loss: 3002341.00000\n",
      "Step #200, epoch #200, avg. train loss: 1523228.62500\n",
      "Step #100, epoch #100, avg. train loss: 2088029.00000\n",
      "Step #200, epoch #200, avg. train loss: 1662332.50000\n",
      "Step #100, epoch #100, avg. train loss: 2008352.37500\n",
      "Step #200, epoch #200, avg. train loss: 1565643.62500\n",
      "Step #100, epoch #100, avg. train loss: 2100848.25000\n",
      "Step #200, epoch #200, avg. train loss: 1663890.12500\n",
      "Step #100, epoch #11, avg. train loss: 2443949.25000\n",
      "Step #200, epoch #22, avg. train loss: 1787238.25000\n",
      "Step #100, epoch #11, avg. train loss: 2435376.75000\n",
      "Step #200, epoch #22, avg. train loss: 1700940.37500\n",
      "Step #100, epoch #11, avg. train loss: 2500207.25000\n",
      "Step #200, epoch #22, avg. train loss: 1899958.75000\n",
      "Step #100, epoch #50, avg. train loss: 2757091.75000\n",
      "Step #200, epoch #100, avg. train loss: 1772519.37500\n",
      "Step #100, epoch #50, avg. train loss: 2713639.00000\n",
      "Step #200, epoch #100, avg. train loss: 1702581.25000\n",
      "Step #100, epoch #50, avg. train loss: 2726560.75000\n",
      "Step #200, epoch #100, avg. train loss: 1787523.00000\n",
      "Step #100, epoch #33, avg. train loss: 2304692.50000\n",
      "Step #200, epoch #66, avg. train loss: 1518157.12500\n",
      "Step #100, epoch #33, avg. train loss: 2240322.50000\n",
      "Step #200, epoch #66, avg. train loss: 1506513.87500\n",
      "Step #100, epoch #33, avg. train loss: 2282370.00000\n",
      "Step #200, epoch #66, avg. train loss: 1572117.62500\n",
      "Step #100, epoch #16, avg. train loss: 2881681.50000\n",
      "Step #200, epoch #33, avg. train loss: 1592106.75000\n",
      "Step #100, epoch #16, avg. train loss: 2815487.25000\n",
      "Step #200, epoch #33, avg. train loss: 1549310.25000\n",
      "Step #100, epoch #16, avg. train loss: 2664778.75000\n",
      "Step #200, epoch #33, avg. train loss: 1620534.12500\n",
      "Step #100, epoch #100, avg. train loss: 2830081.25000\n",
      "Step #200, epoch #200, avg. train loss: 1536579.87500\n",
      "Step #100, epoch #100, avg. train loss: 2763011.75000\n",
      "Step #200, epoch #200, avg. train loss: 1499901.25000\n",
      "Step #100, epoch #100, avg. train loss: 2842685.00000\n",
      "Step #200, epoch #200, avg. train loss: 1461482.12500\n",
      "Step #100, epoch #100, avg. train loss: 2143107.25000\n",
      "Step #200, epoch #200, avg. train loss: 1548723.50000\n",
      "Step #100, epoch #100, avg. train loss: 2078673.25000\n",
      "Step #200, epoch #200, avg. train loss: 1444987.87500\n",
      "Step #100, epoch #100, avg. train loss: 2143015.25000\n",
      "Step #200, epoch #200, avg. train loss: 1506122.25000\n",
      "Step #100, epoch #25, avg. train loss: 2147581.50000\n",
      "Step #200, epoch #50, avg. train loss: 1616436.12500\n",
      "Step #100, epoch #25, avg. train loss: 2131905.25000\n",
      "Step #200, epoch #50, avg. train loss: 1646792.37500\n",
      "Step #100, epoch #25, avg. train loss: 2283366.00000\n",
      "Step #200, epoch #50, avg. train loss: 1686926.75000\n",
      "Step #100, epoch #25, avg. train loss: 2261519.25000\n",
      "Step #200, epoch #50, avg. train loss: 1557533.50000\n",
      "Step #100, epoch #25, avg. train loss: 2169135.25000\n",
      "Step #200, epoch #50, avg. train loss: 1536130.37500\n",
      "Step #100, epoch #25, avg. train loss: 2288257.00000\n",
      "Step #200, epoch #50, avg. train loss: 1572671.62500\n",
      "Step #100, epoch #50, avg. train loss: 2200269.50000\n",
      "Step #200, epoch #100, avg. train loss: 1570266.37500\n",
      "Step #100, epoch #50, avg. train loss: 2114301.00000\n",
      "Step #200, epoch #100, avg. train loss: 1512511.37500\n",
      "Step #100, epoch #50, avg. train loss: 2213405.25000\n",
      "Step #200, epoch #100, avg. train loss: 1554821.75000\n",
      "Step #100, epoch #25, avg. train loss: 2151855.25000\n",
      "Step #200, epoch #50, avg. train loss: 1696841.12500\n",
      "Step #100, epoch #25, avg. train loss: 2090408.50000\n",
      "Step #200, epoch #50, avg. train loss: 1659489.00000\n",
      "Step #100, epoch #25, avg. train loss: 2181106.75000\n",
      "Step #200, epoch #50, avg. train loss: 1744196.50000\n",
      "Step #100, epoch #7, avg. train loss: 2223311.00000\n",
      "Step #200, epoch #15, avg. train loss: 1685464.37500\n",
      "Step #100, epoch #7, avg. train loss: 2231688.75000\n",
      "Step #200, epoch #15, avg. train loss: 1651962.75000\n",
      "Step #100, epoch #7, avg. train loss: 2239447.75000\n",
      "Step #200, epoch #15, avg. train loss: 1704781.25000\n",
      "Step #100, epoch #50, avg. train loss: 2290158.75000\n",
      "Step #200, epoch #100, avg. train loss: 1530579.37500\n",
      "Step #100, epoch #50, avg. train loss: 2211991.75000\n",
      "Step #200, epoch #100, avg. train loss: 1567731.62500\n",
      "Step #100, epoch #50, avg. train loss: 2285468.25000\n",
      "Step #200, epoch #100, avg. train loss: 1636669.12500\n",
      "Step #100, epoch #33, avg. train loss: 2509323.75000\n",
      "Step #200, epoch #66, avg. train loss: 1607944.50000\n",
      "Step #100, epoch #33, avg. train loss: 2356781.75000\n",
      "Step #200, epoch #66, avg. train loss: 1537465.50000\n",
      "Step #100, epoch #33, avg. train loss: 2454606.25000\n",
      "Step #200, epoch #66, avg. train loss: 1551337.00000\n",
      "Step #100, epoch #50, avg. train loss: 2893588.50000\n",
      "Step #200, epoch #100, avg. train loss: 1692923.50000\n",
      "Step #100, epoch #50, avg. train loss: 2950132.50000\n",
      "Step #200, epoch #100, avg. train loss: 1681406.37500\n",
      "Step #100, epoch #50, avg. train loss: 2879450.25000\n",
      "Step #200, epoch #100, avg. train loss: 1735858.12500\n",
      "Step #100, epoch #33, avg. train loss: 2146727.25000\n",
      "Step #200, epoch #66, avg. train loss: 1708511.00000\n",
      "Step #100, epoch #33, avg. train loss: 2071881.00000\n",
      "Step #200, epoch #66, avg. train loss: 1611780.12500\n",
      "Step #100, epoch #33, avg. train loss: 2167928.25000\n",
      "Step #200, epoch #66, avg. train loss: 1706525.00000\n",
      "Step #100, epoch #100, avg. train loss: 2205175.00000\n",
      "Step #200, epoch #200, avg. train loss: 1531068.62500\n",
      "Step #100, epoch #100, avg. train loss: 2130431.25000\n",
      "Step #200, epoch #200, avg. train loss: 1518721.75000\n",
      "Step #100, epoch #100, avg. train loss: 2230399.25000\n",
      "Step #200, epoch #200, avg. train loss: 1524733.62500\n",
      "Step #100, epoch #100, avg. train loss: 2186638.25000\n",
      "Step #200, epoch #200, avg. train loss: 1610453.87500\n",
      "Step #100, epoch #100, avg. train loss: 2113074.50000\n",
      "Step #200, epoch #200, avg. train loss: 1526355.87500\n",
      "Step #100, epoch #100, avg. train loss: 2194538.25000\n",
      "Step #200, epoch #200, avg. train loss: 1591428.75000\n",
      "Step #100, epoch #33, avg. train loss: 2085296.62500\n",
      "Step #200, epoch #66, avg. train loss: 1650150.75000\n",
      "Step #100, epoch #33, avg. train loss: 2007297.25000\n",
      "Step #200, epoch #66, avg. train loss: 1554105.75000\n",
      "Step #100, epoch #33, avg. train loss: 2128198.00000\n",
      "Step #200, epoch #66, avg. train loss: 1676369.75000\n",
      "Step #100, epoch #10, avg. train loss: 2209285.50000\n",
      "Step #200, epoch #20, avg. train loss: 1635057.50000\n",
      "Step #100, epoch #10, avg. train loss: 2109845.50000\n",
      "Step #200, epoch #20, avg. train loss: 1579651.25000\n",
      "Step #100, epoch #10, avg. train loss: 2192800.50000\n",
      "Step #200, epoch #20, avg. train loss: 1650433.50000\n",
      "Step #100, epoch #20, avg. train loss: 3385296.75000\n",
      "Step #200, epoch #40, avg. train loss: 1607469.50000\n",
      "Step #100, epoch #20, avg. train loss: 3227048.00000\n",
      "Step #200, epoch #40, avg. train loss: 1587332.62500\n",
      "Step #100, epoch #20, avg. train loss: 2939745.25000\n",
      "Step #200, epoch #40, avg. train loss: 1652094.37500\n",
      "Step #100, epoch #100, avg. train loss: 2587595.75000\n",
      "Step #200, epoch #200, avg. train loss: 1547314.87500\n",
      "Step #100, epoch #100, avg. train loss: 2510196.50000\n",
      "Step #200, epoch #200, avg. train loss: 1479961.25000\n",
      "Step #100, epoch #100, avg. train loss: 2624199.00000\n",
      "Step #200, epoch #200, avg. train loss: 1642375.50000\n",
      "Step #100, epoch #100, avg. train loss: 2146364.00000\n",
      "Step #200, epoch #200, avg. train loss: 1519023.37500\n",
      "Step #100, epoch #100, avg. train loss: 2086168.00000\n",
      "Step #200, epoch #200, avg. train loss: 1527408.37500\n",
      "Step #100, epoch #100, avg. train loss: 2171243.75000\n",
      "Step #200, epoch #200, avg. train loss: 1625903.25000\n",
      "Step #100, epoch #50, avg. train loss: 2398554.00000\n",
      "Step #200, epoch #100, avg. train loss: 1444764.75000\n",
      "Step #100, epoch #50, avg. train loss: 2214588.75000\n",
      "Step #200, epoch #100, avg. train loss: 1444680.00000\n",
      "Step #100, epoch #50, avg. train loss: 2408125.50000\n",
      "Step #200, epoch #100, avg. train loss: 1962451.37500\n",
      "Step #100, epoch #33, avg. train loss: 2868691.75000\n",
      "Step #200, epoch #66, avg. train loss: 1608963.37500\n",
      "Step #100, epoch #33, avg. train loss: 2906737.50000\n",
      "Step #200, epoch #66, avg. train loss: 1570386.37500\n",
      "Step #100, epoch #33, avg. train loss: 3175419.75000\n",
      "Step #200, epoch #66, avg. train loss: 1811069.50000\n",
      "Step #100, epoch #100, avg. train loss: 2287449.00000\n",
      "Step #200, epoch #200, avg. train loss: 1569333.75000\n",
      "Step #100, epoch #100, avg. train loss: 2207829.25000\n",
      "Step #200, epoch #200, avg. train loss: 1496273.50000\n",
      "Step #100, epoch #100, avg. train loss: 2297893.75000\n",
      "Step #200, epoch #200, avg. train loss: 1573549.75000\n",
      "Step #100, epoch #100, avg. train loss: 3286316.50000\n",
      "Step #200, epoch #200, avg. train loss: 1600056.12500\n",
      "Step #100, epoch #100, avg. train loss: 3176470.75000\n",
      "Step #200, epoch #200, avg. train loss: 1514029.87500\n",
      "Step #100, epoch #100, avg. train loss: 3133671.25000\n",
      "Step #200, epoch #200, avg. train loss: 1584501.75000\n",
      "Step #100, epoch #100, avg. train loss: 4513678.00000\n",
      "Step #200, epoch #200, avg. train loss: 1793425.62500\n",
      "Step #100, epoch #100, avg. train loss: 4536590.00000\n",
      "Step #200, epoch #200, avg. train loss: 1702138.75000\n",
      "Step #100, epoch #100, avg. train loss: 4378251.50000\n",
      "Step #200, epoch #200, avg. train loss: 1811360.50000\n",
      "Step #100, epoch #50, avg. train loss: 2139470.00000\n",
      "Step #200, epoch #100, avg. train loss: 1614200.75000\n",
      "Step #100, epoch #50, avg. train loss: 2102682.50000\n",
      "Step #200, epoch #100, avg. train loss: 1535706.50000\n",
      "Step #100, epoch #50, avg. train loss: 2152371.25000\n",
      "Step #200, epoch #100, avg. train loss: 1541760.75000\n",
      "Step #100, epoch #50, avg. train loss: 2518144.25000\n",
      "Step #200, epoch #100, avg. train loss: 1519137.25000\n",
      "Step #100, epoch #50, avg. train loss: 3530001.00000\n",
      "Step #200, epoch #100, avg. train loss: 1511717.25000\n",
      "Step #100, epoch #50, avg. train loss: 3781510.00000\n",
      "Step #200, epoch #100, avg. train loss: 1524236.12500\n",
      "Step #100, epoch #100, avg. train loss: 2675485.50000\n",
      "Step #200, epoch #200, avg. train loss: 1508467.25000\n",
      "Step #100, epoch #100, avg. train loss: 2545494.75000\n",
      "Step #200, epoch #200, avg. train loss: 1507352.75000\n",
      "Step #100, epoch #100, avg. train loss: 2677582.50000\n",
      "Step #200, epoch #200, avg. train loss: 1591712.62500\n",
      "Step #100, epoch #50, avg. train loss: 2140637.25000\n",
      "Step #200, epoch #100, avg. train loss: 1590348.12500\n",
      "Step #100, epoch #50, avg. train loss: 2078319.87500\n",
      "Step #200, epoch #100, avg. train loss: 1565255.62500\n",
      "Step #100, epoch #50, avg. train loss: 2118845.50000\n",
      "Step #200, epoch #100, avg. train loss: 1565117.75000\n",
      "Step #100, epoch #100, avg. train loss: 2858684.50000\n",
      "Step #200, epoch #200, avg. train loss: 1592847.62500\n",
      "Step #100, epoch #100, avg. train loss: 2755367.00000\n",
      "Step #200, epoch #200, avg. train loss: 1483746.12500\n",
      "Step #100, epoch #100, avg. train loss: 2841757.75000\n",
      "Step #200, epoch #200, avg. train loss: 1494603.87500\n",
      "Step #100, epoch #50, avg. train loss: 2298562.25000\n",
      "Step #200, epoch #100, avg. train loss: 1636295.50000\n",
      "Step #100, epoch #50, avg. train loss: 2334340.75000\n",
      "Step #200, epoch #100, avg. train loss: 1694886.25000\n",
      "Step #100, epoch #50, avg. train loss: 2348060.50000\n",
      "Step #200, epoch #100, avg. train loss: 1702307.62500\n",
      "Step #100, epoch #100, avg. train loss: 2439707.00000\n",
      "Step #200, epoch #200, avg. train loss: 1559602.37500\n",
      "Step #100, epoch #100, avg. train loss: 2339824.75000\n",
      "Step #200, epoch #200, avg. train loss: 1531901.62500\n",
      "Step #100, epoch #100, avg. train loss: 2457252.75000\n",
      "Step #200, epoch #200, avg. train loss: 1521613.25000\n",
      "Step #100, epoch #14, avg. train loss: 2371381.50000\n",
      "Step #200, epoch #28, avg. train loss: 1621642.87500\n",
      "Step #100, epoch #14, avg. train loss: 2249950.00000\n",
      "Step #200, epoch #28, avg. train loss: 1554078.25000\n",
      "Step #100, epoch #14, avg. train loss: 2314721.50000\n",
      "Step #200, epoch #28, avg. train loss: 1671663.87500\n",
      "Step #100, epoch #100, avg. train loss: 3002599.25000\n",
      "Step #200, epoch #200, avg. train loss: 1637422.37500\n",
      "Step #100, epoch #100, avg. train loss: 2894941.00000\n",
      "Step #200, epoch #200, avg. train loss: 1455020.00000\n",
      "Step #100, epoch #100, avg. train loss: 2982361.50000\n",
      "Step #200, epoch #200, avg. train loss: 1602920.12500\n",
      "Step #100, epoch #25, avg. train loss: 3682623.25000\n",
      "Step #200, epoch #50, avg. train loss: 1597769.12500\n",
      "Step #100, epoch #25, avg. train loss: 3541894.50000\n",
      "Step #200, epoch #50, avg. train loss: 1521821.12500\n",
      "Step #100, epoch #25, avg. train loss: 3676637.50000\n",
      "Step #200, epoch #50, avg. train loss: 1495007.62500\n",
      "Step #100, epoch #100, avg. train loss: 2078094.75000\n",
      "Step #200, epoch #200, avg. train loss: 1603018.50000\n",
      "Step #100, epoch #100, avg. train loss: 1998728.37500\n",
      "Step #200, epoch #200, avg. train loss: 1500452.00000\n",
      "Step #100, epoch #100, avg. train loss: 2088812.75000\n",
      "Step #200, epoch #200, avg. train loss: 1579386.25000\n",
      "Step #100, epoch #100, avg. train loss: 3325905.00000\n",
      "Step #200, epoch #200, avg. train loss: 1488939.25000\n",
      "Step #100, epoch #100, avg. train loss: 3094417.50000\n",
      "Step #200, epoch #200, avg. train loss: 1445847.62500\n",
      "Step #100, epoch #100, avg. train loss: 3209621.50000\n",
      "Step #200, epoch #200, avg. train loss: 1540021.75000\n",
      "Step #100, epoch #100, avg. train loss: 3300002.00000\n",
      "Step #200, epoch #200, avg. train loss: 1492288.37500\n",
      "Step #100, epoch #100, avg. train loss: 3124712.00000\n",
      "Step #200, epoch #200, avg. train loss: 1456523.62500\n",
      "Step #100, epoch #100, avg. train loss: 3041781.00000\n",
      "Step #200, epoch #200, avg. train loss: 1627238.25000\n",
      "Step #100, epoch #100, avg. train loss: 2547407.00000\n",
      "Step #200, epoch #200, avg. train loss: 1649459.00000\n",
      "Step #100, epoch #100, avg. train loss: 2806526.00000\n",
      "Step #200, epoch #200, avg. train loss: 1656171.87500\n",
      "Step #100, epoch #100, avg. train loss: 2469636.25000\n",
      "Step #200, epoch #200, avg. train loss: 1596274.25000\n",
      "Step #100, epoch #50, avg. train loss: 2096172.37500\n",
      "Step #200, epoch #100, avg. train loss: 1638869.62500\n",
      "Step #100, epoch #50, avg. train loss: 2003872.37500\n",
      "Step #200, epoch #100, avg. train loss: 1576749.75000\n",
      "Step #100, epoch #50, avg. train loss: 2102474.50000\n",
      "Step #200, epoch #100, avg. train loss: 1644553.75000\n",
      "Step #100, epoch #100, avg. train loss: 2136067.25000\n",
      "Step #200, epoch #200, avg. train loss: 1672710.37500\n",
      "Step #100, epoch #100, avg. train loss: 2056632.50000\n",
      "Step #200, epoch #200, avg. train loss: 1574478.37500\n",
      "Step #100, epoch #100, avg. train loss: 2147703.00000\n",
      "Step #200, epoch #200, avg. train loss: 1693942.50000\n",
      "Step #100, epoch #20, avg. train loss: 2238081.75000\n",
      "Step #200, epoch #40, avg. train loss: 1671225.87500\n",
      "Step #100, epoch #20, avg. train loss: 2113295.75000\n",
      "Step #200, epoch #40, avg. train loss: 1571260.50000\n",
      "Step #100, epoch #20, avg. train loss: 2232847.00000\n",
      "Step #200, epoch #40, avg. train loss: 1694672.75000\n",
      "Step #100, epoch #20, avg. train loss: 3116493.50000\n",
      "Step #200, epoch #40, avg. train loss: 1560057.62500\n",
      "Step #100, epoch #20, avg. train loss: 3047128.00000\n",
      "Step #200, epoch #40, avg. train loss: 1530643.87500\n",
      "Step #100, epoch #20, avg. train loss: 3070664.25000\n",
      "Step #200, epoch #40, avg. train loss: 1528722.87500\n",
      "Step #100, epoch #100, avg. train loss: 3162573.50000\n",
      "Step #200, epoch #200, avg. train loss: 1715880.75000\n",
      "Step #100, epoch #100, avg. train loss: 3148659.75000\n",
      "Step #200, epoch #200, avg. train loss: 1633079.37500\n",
      "Step #100, epoch #100, avg. train loss: 3127014.75000\n",
      "Step #200, epoch #200, avg. train loss: 1730122.75000\n",
      "Step #100, epoch #50, avg. train loss: 3514155.50000\n",
      "Step #200, epoch #100, avg. train loss: 1515762.37500\n",
      "Step #100, epoch #50, avg. train loss: 3372144.25000\n",
      "Step #200, epoch #100, avg. train loss: 1508995.37500\n",
      "Step #100, epoch #50, avg. train loss: 3456475.75000\n",
      "Step #200, epoch #100, avg. train loss: 1545501.00000\n",
      "Step #100, epoch #50, avg. train loss: 2756882.25000\n",
      "Step #200, epoch #100, avg. train loss: 1581736.00000\n",
      "Step #100, epoch #50, avg. train loss: 3274750.00000\n",
      "Step #200, epoch #100, avg. train loss: 1661895.37500\n",
      "Step #100, epoch #50, avg. train loss: 3770923.00000\n",
      "Step #200, epoch #100, avg. train loss: 1687436.12500\n",
      "Step #100, epoch #25, avg. train loss: 2232857.25000\n",
      "Step #200, epoch #50, avg. train loss: 1570820.62500\n",
      "Step #100, epoch #25, avg. train loss: 2117401.50000\n",
      "Step #200, epoch #50, avg. train loss: 1424780.37500\n",
      "Step #100, epoch #25, avg. train loss: 2244615.00000\n",
      "Step #200, epoch #50, avg. train loss: 1500860.37500\n",
      "Step #100, epoch #20, avg. train loss: 2862952.75000\n",
      "Step #200, epoch #40, avg. train loss: 1540157.50000\n",
      "Step #100, epoch #20, avg. train loss: 2791349.75000\n",
      "Step #200, epoch #40, avg. train loss: 1539276.00000\n",
      "Step #100, epoch #20, avg. train loss: 2920621.50000\n",
      "Step #200, epoch #40, avg. train loss: 1527387.50000\n",
      "Step #100, epoch #33, avg. train loss: 2245823.25000\n",
      "Step #200, epoch #66, avg. train loss: 1652019.37500\n",
      "Step #100, epoch #33, avg. train loss: 2228902.25000\n",
      "Step #200, epoch #66, avg. train loss: 1537775.62500\n",
      "Step #100, epoch #33, avg. train loss: 2269993.00000\n",
      "Step #200, epoch #66, avg. train loss: 1546529.75000\n",
      "Step #100, epoch #100, avg. train loss: 2143727.50000\n",
      "Step #200, epoch #200, avg. train loss: 1532019.37500\n",
      "Step #100, epoch #100, avg. train loss: 2068268.12500\n",
      "Step #200, epoch #200, avg. train loss: 1463098.37500\n",
      "Step #100, epoch #100, avg. train loss: 2152889.75000\n",
      "Step #200, epoch #200, avg. train loss: 1502938.25000\n",
      "Step #100, epoch #100, avg. train loss: 2916279.75000\n",
      "Step #200, epoch #200, avg. train loss: 1495875.37500\n",
      "Step #100, epoch #100, avg. train loss: 2867579.25000\n",
      "Step #200, epoch #200, avg. train loss: 1474852.00000\n",
      "Step #100, epoch #100, avg. train loss: 2782761.00000\n",
      "Step #200, epoch #200, avg. train loss: 1627188.75000\n",
      "Step #100, epoch #100, avg. train loss: 2174886.50000\n",
      "Step #200, epoch #200, avg. train loss: 1569316.37500\n",
      "Step #100, epoch #100, avg. train loss: 2090194.50000\n",
      "Step #200, epoch #200, avg. train loss: 1539441.12500\n",
      "Step #100, epoch #100, avg. train loss: 2181467.00000\n",
      "Step #200, epoch #200, avg. train loss: 1547164.75000\n",
      "Step #100, epoch #100, avg. train loss: 2202352.25000\n",
      "Step #200, epoch #200, avg. train loss: 1643175.87500\n",
      "Step #100, epoch #100, avg. train loss: 2137396.25000\n",
      "Step #200, epoch #200, avg. train loss: 1561510.75000\n",
      "Step #100, epoch #100, avg. train loss: 2199353.50000\n",
      "Step #200, epoch #200, avg. train loss: 1631478.87500\n",
      "Step #100, epoch #50, avg. train loss: 3554873.25000\n",
      "Step #200, epoch #100, avg. train loss: 1515564.37500\n",
      "Step #100, epoch #50, avg. train loss: 3277170.00000\n",
      "Step #200, epoch #100, avg. train loss: 1509383.50000\n",
      "Step #100, epoch #50, avg. train loss: 3386331.25000\n",
      "Step #200, epoch #100, avg. train loss: 1523036.75000\n",
      "Step #100, epoch #100, avg. train loss: 2115647.50000\n",
      "Step #200, epoch #200, avg. train loss: 1482129.12500\n",
      "Step #100, epoch #100, avg. train loss: 2059094.12500\n",
      "Step #200, epoch #200, avg. train loss: 1412180.50000\n",
      "Step #100, epoch #100, avg. train loss: 2132836.25000\n",
      "Step #200, epoch #200, avg. train loss: 1494219.00000\n",
      "Step #100, epoch #100, avg. train loss: 2674767.75000\n",
      "Step #200, epoch #200, avg. train loss: 1604075.50000\n",
      "Step #100, epoch #100, avg. train loss: 3321673.00000\n",
      "Step #200, epoch #200, avg. train loss: 1733320.12500\n",
      "Step #100, epoch #100, avg. train loss: 2706960.75000\n",
      "Step #200, epoch #200, avg. train loss: 1726508.75000\n",
      "Step #100, epoch #100, avg. train loss: 2268357.25000\n",
      "Step #200, epoch #200, avg. train loss: 1593996.12500\n",
      "Step #100, epoch #100, avg. train loss: 2204104.25000\n",
      "Step #200, epoch #200, avg. train loss: 1532396.50000\n",
      "Step #100, epoch #100, avg. train loss: 2263895.75000\n",
      "Step #200, epoch #200, avg. train loss: 1559143.25000\n",
      "Step #100, epoch #20, avg. train loss: 2793475.00000\n",
      "Step #200, epoch #40, avg. train loss: 1794033.25000\n",
      "Step #100, epoch #20, avg. train loss: 2753627.00000\n",
      "Step #200, epoch #40, avg. train loss: 1707672.12500\n",
      "Step #100, epoch #20, avg. train loss: 2783755.00000\n",
      "Step #200, epoch #40, avg. train loss: 1839188.75000\n",
      "Step #100, epoch #100, avg. train loss: 2362973.75000\n",
      "Step #200, epoch #200, avg. train loss: 1669679.00000\n",
      "Step #100, epoch #100, avg. train loss: 2314632.00000\n",
      "Step #200, epoch #200, avg. train loss: 1616236.00000\n",
      "Step #100, epoch #100, avg. train loss: 2359415.25000\n",
      "Step #200, epoch #200, avg. train loss: 1706016.62500\n",
      "Step #100, epoch #100, avg. train loss: 3091516.50000\n",
      "Step #200, epoch #200, avg. train loss: 1650169.62500\n",
      "Step #100, epoch #100, avg. train loss: 3083453.75000\n",
      "Step #200, epoch #200, avg. train loss: 1487382.50000\n",
      "Step #100, epoch #100, avg. train loss: 3093480.75000\n",
      "Step #200, epoch #200, avg. train loss: 1545714.75000\n",
      "Step #100, epoch #100, avg. train loss: 2230566.00000\n",
      "Step #200, epoch #200, avg. train loss: 1473023.00000\n",
      "Step #100, epoch #100, avg. train loss: 2165722.50000\n",
      "Step #200, epoch #200, avg. train loss: 1415042.75000\n",
      "Step #100, epoch #100, avg. train loss: 2254152.25000\n",
      "Step #200, epoch #200, avg. train loss: 1511167.87500\n",
      "Step #100, epoch #100, avg. train loss: 2764926.50000\n",
      "Step #200, epoch #200, avg. train loss: 1580092.00000\n",
      "Step #100, epoch #100, avg. train loss: 2697810.25000\n",
      "Step #200, epoch #200, avg. train loss: 1504599.00000\n",
      "Step #100, epoch #100, avg. train loss: 2766332.50000\n",
      "Step #200, epoch #200, avg. train loss: 1611711.00000\n",
      "Step #100, epoch #100, avg. train loss: 2592156.00000\n",
      "Step #200, epoch #200, avg. train loss: 1633671.25000\n",
      "Step #100, epoch #100, avg. train loss: 2964118.00000\n",
      "Step #200, epoch #200, avg. train loss: 1658996.12500\n",
      "Step #100, epoch #100, avg. train loss: 2507515.75000\n",
      "Step #200, epoch #200, avg. train loss: 1596063.62500\n",
      "Step #100, epoch #100, avg. train loss: 2173298.75000\n",
      "Step #200, epoch #200, avg. train loss: 1631519.50000\n",
      "Step #100, epoch #100, avg. train loss: 2102270.25000\n",
      "Step #200, epoch #200, avg. train loss: 1548836.62500\n",
      "Step #100, epoch #100, avg. train loss: 2175530.25000\n",
      "Step #200, epoch #200, avg. train loss: 1629658.37500\n",
      "Step #100, epoch #50, avg. train loss: 2192374.00000\n",
      "Step #200, epoch #100, avg. train loss: 1735837.00000\n",
      "Step #100, epoch #50, avg. train loss: 2118787.75000\n",
      "Step #200, epoch #100, avg. train loss: 1621309.62500\n",
      "Step #100, epoch #50, avg. train loss: 2198893.50000\n",
      "Step #200, epoch #100, avg. train loss: 1719582.75000\n",
      "Step #100, epoch #33, avg. train loss: 2902072.75000\n",
      "Step #200, epoch #66, avg. train loss: 1788902.12500\n",
      "Step #100, epoch #33, avg. train loss: 2872227.00000\n",
      "Step #200, epoch #66, avg. train loss: 1701234.50000\n",
      "Step #100, epoch #33, avg. train loss: 2884225.25000\n",
      "Step #200, epoch #66, avg. train loss: 1812138.25000\n",
      "Step #100, epoch #50, avg. train loss: 2182817.00000\n",
      "Step #200, epoch #100, avg. train loss: 1589070.50000\n",
      "Step #100, epoch #50, avg. train loss: 2161774.00000\n",
      "Step #200, epoch #100, avg. train loss: 1540443.37500\n",
      "Step #100, epoch #50, avg. train loss: 2203003.25000\n",
      "Step #200, epoch #100, avg. train loss: 1598137.50000\n",
      "Step #100, epoch #50, avg. train loss: 2169425.75000\n",
      "Step #200, epoch #100, avg. train loss: 1476806.75000\n",
      "Step #100, epoch #50, avg. train loss: 2175736.00000\n",
      "Step #200, epoch #100, avg. train loss: 1513392.12500\n",
      "Step #100, epoch #50, avg. train loss: 2244150.25000\n",
      "Step #200, epoch #100, avg. train loss: 1598876.75000\n",
      "Step #100, epoch #100, avg. train loss: 2864790.50000\n",
      "Step #200, epoch #200, avg. train loss: 1575830.12500\n",
      "Step #100, epoch #100, avg. train loss: 2932522.50000\n",
      "Step #200, epoch #200, avg. train loss: 1499676.00000\n",
      "Step #100, epoch #100, avg. train loss: 2886592.75000\n",
      "Step #200, epoch #200, avg. train loss: 1594733.87500\n",
      "Step #100, epoch #100, avg. train loss: 2444857.75000\n",
      "Step #200, epoch #200, avg. train loss: 1561209.25000\n",
      "Step #100, epoch #100, avg. train loss: 2321470.75000\n",
      "Step #200, epoch #200, avg. train loss: 1481366.12500\n",
      "Step #100, epoch #100, avg. train loss: 2394538.00000\n",
      "Step #200, epoch #200, avg. train loss: 1653279.25000\n",
      "Step #100, epoch #1, avg. train loss: 3128188.75000\n",
      "Step #200, epoch #3, avg. train loss: 1890323.25000\n",
      "Step #100, epoch #1, avg. train loss: 3272467.00000\n",
      "Step #200, epoch #3, avg. train loss: 1734664.75000\n",
      "Step #100, epoch #1, avg. train loss: 3232391.75000\n",
      "Step #200, epoch #3, avg. train loss: 1902929.50000\n",
      "Step #100, epoch #100, avg. train loss: 2226970.50000\n",
      "Step #200, epoch #200, avg. train loss: 1600699.00000\n",
      "Step #100, epoch #100, avg. train loss: 2156481.00000\n",
      "Step #200, epoch #200, avg. train loss: 1535879.37500\n",
      "Step #100, epoch #100, avg. train loss: 2229631.75000\n",
      "Step #200, epoch #200, avg. train loss: 1572455.50000\n",
      "Step #100, epoch #100, avg. train loss: 2508626.50000\n",
      "Step #200, epoch #200, avg. train loss: 1668964.50000\n",
      "Step #100, epoch #100, avg. train loss: 2630114.50000\n",
      "Step #200, epoch #200, avg. train loss: 1653740.12500\n",
      "Step #100, epoch #100, avg. train loss: 2424849.50000\n",
      "Step #200, epoch #200, avg. train loss: 1604187.50000\n",
      "Step #100, epoch #14, avg. train loss: 3115560.75000\n",
      "Step #200, epoch #28, avg. train loss: 1559644.00000\n",
      "Step #100, epoch #14, avg. train loss: 3324860.50000\n",
      "Step #200, epoch #28, avg. train loss: 1516872.50000\n",
      "Step #100, epoch #14, avg. train loss: 3589357.00000\n",
      "Step #200, epoch #28, avg. train loss: 1580265.50000\n",
      "Step #100, epoch #100, avg. train loss: 2270999.25000\n",
      "Step #200, epoch #200, avg. train loss: 1581586.37500\n",
      "Step #100, epoch #100, avg. train loss: 2230832.25000\n",
      "Step #200, epoch #200, avg. train loss: 1558462.50000\n",
      "Step #100, epoch #100, avg. train loss: 2248437.50000\n",
      "Step #200, epoch #200, avg. train loss: 1560978.37500\n",
      "Step #100, epoch #100, avg. train loss: 6344765.50000\n",
      "Step #200, epoch #200, avg. train loss: 1894869.62500\n",
      "Step #100, epoch #100, avg. train loss: 6413979.50000\n",
      "Step #200, epoch #200, avg. train loss: 1772798.37500\n",
      "Step #100, epoch #100, avg. train loss: 6079757.00000\n",
      "Step #200, epoch #200, avg. train loss: 1869930.50000\n",
      "Step #100, epoch #50, avg. train loss: 2672101.50000\n",
      "Step #200, epoch #100, avg. train loss: 1583228.62500\n",
      "Step #100, epoch #50, avg. train loss: 2643918.50000\n",
      "Step #200, epoch #100, avg. train loss: 1506841.12500\n",
      "Step #100, epoch #50, avg. train loss: 2691511.25000\n",
      "Step #200, epoch #100, avg. train loss: 1559258.25000\n",
      "Step #100, epoch #10, avg. train loss: 3043732.50000\n",
      "Step #200, epoch #20, avg. train loss: 1571068.75000\n",
      "Step #100, epoch #10, avg. train loss: 2974508.50000\n",
      "Step #200, epoch #20, avg. train loss: 1495180.75000\n",
      "Step #100, epoch #10, avg. train loss: 3021424.00000\n",
      "Step #200, epoch #20, avg. train loss: 1534197.62500\n",
      "Step #100, epoch #20, avg. train loss: 2844651.25000\n",
      "Step #200, epoch #40, avg. train loss: 1557645.50000\n",
      "Step #100, epoch #20, avg. train loss: 2741506.50000\n",
      "Step #200, epoch #40, avg. train loss: 1485612.00000\n",
      "Step #100, epoch #20, avg. train loss: 2792041.50000\n",
      "Step #200, epoch #40, avg. train loss: 1544841.75000\n",
      "Step #100, epoch #100, avg. train loss: 2229187.50000\n",
      "Step #200, epoch #200, avg. train loss: 1623318.37500\n",
      "Step #100, epoch #100, avg. train loss: 2141138.00000\n",
      "Step #200, epoch #200, avg. train loss: 1522381.50000\n",
      "Step #100, epoch #100, avg. train loss: 2204000.25000\n",
      "Step #200, epoch #200, avg. train loss: 1478227.87500\n",
      "Step #100, epoch #100, avg. train loss: 2653977.75000\n",
      "Step #200, epoch #200, avg. train loss: 1718737.87500\n",
      "Step #100, epoch #100, avg. train loss: 2617126.00000\n",
      "Step #200, epoch #200, avg. train loss: 1633759.62500\n",
      "Step #100, epoch #100, avg. train loss: 2638287.00000\n",
      "Step #200, epoch #200, avg. train loss: 1747887.00000\n",
      "Step #100, epoch #7, avg. train loss: 2333823.00000\n",
      "Step #200, epoch #15, avg. train loss: 1627619.62500\n",
      "Step #100, epoch #7, avg. train loss: 2297089.25000\n",
      "Step #200, epoch #15, avg. train loss: 1527573.00000\n",
      "Step #100, epoch #7, avg. train loss: 2310174.50000\n",
      "Step #200, epoch #15, avg. train loss: 1619783.87500\n",
      "Step #100, epoch #50, avg. train loss: 2759449.00000\n",
      "Step #200, epoch #100, avg. train loss: 1577403.37500\n",
      "Step #100, epoch #50, avg. train loss: 2671432.50000\n",
      "Step #200, epoch #100, avg. train loss: 1465590.25000\n",
      "Step #100, epoch #50, avg. train loss: 2681075.75000\n",
      "Step #200, epoch #100, avg. train loss: 1586853.00000\n",
      "Step #100, epoch #50, avg. train loss: 3591556.50000\n",
      "Step #200, epoch #100, avg. train loss: 1588713.25000\n",
      "Step #100, epoch #50, avg. train loss: 3604505.00000\n",
      "Step #200, epoch #100, avg. train loss: 1457544.37500\n",
      "Step #100, epoch #50, avg. train loss: 3592046.00000\n",
      "Step #200, epoch #100, avg. train loss: 1473893.50000\n",
      "Step #100, epoch #100, avg. train loss: 2137163.75000\n",
      "Step #200, epoch #200, avg. train loss: 1616699.00000\n",
      "Step #100, epoch #100, avg. train loss: 2057694.75000\n",
      "Step #200, epoch #200, avg. train loss: 1546009.50000\n",
      "Step #100, epoch #100, avg. train loss: 2149408.50000\n",
      "Step #200, epoch #200, avg. train loss: 1609550.75000\n",
      "Step #100, epoch #100, avg. train loss: 2131530.00000\n",
      "Step #200, epoch #200, avg. train loss: 1641749.87500\n",
      "Step #100, epoch #100, avg. train loss: 2064251.50000\n",
      "Step #200, epoch #200, avg. train loss: 1595197.25000\n",
      "Step #100, epoch #100, avg. train loss: 2130154.50000\n",
      "Step #200, epoch #200, avg. train loss: 1624201.62500\n",
      "Step #100, epoch #100, avg. train loss: 2072591.00000\n",
      "Step #200, epoch #200, avg. train loss: 1572639.25000\n",
      "Step #100, epoch #100, avg. train loss: 2015216.50000\n",
      "Step #200, epoch #200, avg. train loss: 1642608.00000\n",
      "Step #100, epoch #100, avg. train loss: 2089959.37500\n",
      "Step #200, epoch #200, avg. train loss: 1585244.62500\n",
      "Step #100, epoch #25, avg. train loss: 3466208.00000\n",
      "Step #200, epoch #50, avg. train loss: 1654562.25000\n",
      "Step #100, epoch #25, avg. train loss: 2618839.50000\n",
      "Step #200, epoch #50, avg. train loss: 1664906.37500\n",
      "Step #100, epoch #25, avg. train loss: 2576650.00000\n",
      "Step #200, epoch #50, avg. train loss: 1611952.62500\n",
      "Step #100, epoch #50, avg. train loss: 2254790.00000\n",
      "Step #200, epoch #100, avg. train loss: 1533655.50000\n",
      "Step #100, epoch #50, avg. train loss: 2174193.50000\n",
      "Step #200, epoch #100, avg. train loss: 1503003.25000\n",
      "Step #100, epoch #50, avg. train loss: 2297337.25000\n",
      "Step #200, epoch #100, avg. train loss: 1509318.37500\n",
      "Step #100, epoch #50, avg. train loss: 2427364.75000\n",
      "Step #200, epoch #100, avg. train loss: 1752922.50000\n",
      "Step #100, epoch #50, avg. train loss: 2297304.50000\n",
      "Step #200, epoch #100, avg. train loss: 1527485.87500\n",
      "Step #100, epoch #50, avg. train loss: 4044812.25000\n",
      "Step #200, epoch #100, avg. train loss: 1604305.25000\n",
      "Step #100, epoch #25, avg. train loss: 2233651.75000\n",
      "Step #200, epoch #50, avg. train loss: 1514367.00000\n",
      "Step #100, epoch #25, avg. train loss: 2189580.75000\n",
      "Step #200, epoch #50, avg. train loss: 1465231.62500\n",
      "Step #100, epoch #25, avg. train loss: 2313746.25000\n",
      "Step #200, epoch #50, avg. train loss: 1543976.50000\n",
      "Step #100, epoch #33, avg. train loss: 2884006.75000\n",
      "Step #200, epoch #66, avg. train loss: 1494541.00000\n",
      "Step #100, epoch #33, avg. train loss: 2770237.75000\n",
      "Step #200, epoch #66, avg. train loss: 1508740.50000\n",
      "Step #100, epoch #33, avg. train loss: 2862345.00000\n",
      "Step #200, epoch #66, avg. train loss: 1517185.62500\n",
      "Step #100, epoch #50, avg. train loss: 2181681.75000\n",
      "Step #200, epoch #100, avg. train loss: 1625534.12500\n",
      "Step #100, epoch #50, avg. train loss: 2114855.25000\n",
      "Step #200, epoch #100, avg. train loss: 1523598.12500\n",
      "Step #100, epoch #50, avg. train loss: 2192608.00000\n",
      "Step #200, epoch #100, avg. train loss: 1615861.50000\n",
      "Step #100, epoch #8, avg. train loss: 3257529.25000\n",
      "Step #200, epoch #16, avg. train loss: 1577563.25000\n",
      "Step #100, epoch #8, avg. train loss: 3018341.00000\n",
      "Step #200, epoch #16, avg. train loss: 1516799.25000\n",
      "Step #100, epoch #8, avg. train loss: 3400781.50000\n",
      "Step #200, epoch #16, avg. train loss: 1572133.25000\n",
      "Step #100, epoch #100, avg. train loss: 2490452.25000\n",
      "Step #200, epoch #200, avg. train loss: 1621598.12500\n",
      "Step #100, epoch #100, avg. train loss: 2462878.50000\n",
      "Step #200, epoch #200, avg. train loss: 1593527.50000\n",
      "Step #100, epoch #100, avg. train loss: 2416546.00000\n",
      "Step #200, epoch #200, avg. train loss: 1632161.12500\n",
      "Step #100, epoch #33, avg. train loss: 2277719.75000\n",
      "Step #200, epoch #66, avg. train loss: 1755866.12500\n",
      "Step #100, epoch #33, avg. train loss: 2210396.25000\n",
      "Step #200, epoch #66, avg. train loss: 1646458.12500\n",
      "Step #100, epoch #33, avg. train loss: 2293223.75000\n",
      "Step #200, epoch #66, avg. train loss: 1760736.00000\n",
      "Step #100, epoch #100, avg. train loss: 8795896.00000\n",
      "Step #200, epoch #200, avg. train loss: 4743419.00000\n",
      "Step #100, epoch #100, avg. train loss: 9019640.00000\n",
      "Step #200, epoch #200, avg. train loss: 4584447.50000\n",
      "Step #100, epoch #100, avg. train loss: 8524886.00000\n",
      "Step #200, epoch #200, avg. train loss: 4350410.00000\n",
      "Step #100, epoch #50, avg. train loss: 2953637.00000\n",
      "Step #200, epoch #100, avg. train loss: 1495782.25000\n",
      "Step #100, epoch #50, avg. train loss: 2879929.25000\n",
      "Step #200, epoch #100, avg. train loss: 1658595.25000\n",
      "Step #100, epoch #50, avg. train loss: 2881128.25000\n",
      "Step #200, epoch #100, avg. train loss: 1526446.75000\n",
      "Step #100, epoch #50, avg. train loss: 2143119.75000\n",
      "Step #200, epoch #100, avg. train loss: 1592797.87500\n",
      "Step #100, epoch #50, avg. train loss: 2068437.25000\n",
      "Step #200, epoch #100, avg. train loss: 1567968.37500\n",
      "Step #100, epoch #50, avg. train loss: 2153691.00000\n",
      "Step #200, epoch #100, avg. train loss: 1607651.87500\n",
      "Step #100, epoch #16, avg. train loss: 2197001.50000\n",
      "Step #200, epoch #33, avg. train loss: 1579486.87500\n",
      "Step #100, epoch #16, avg. train loss: 2098495.50000\n",
      "Step #200, epoch #33, avg. train loss: 1510822.12500\n",
      "Step #100, epoch #16, avg. train loss: 2247825.00000\n",
      "Step #200, epoch #33, avg. train loss: 1567615.25000\n",
      "Step #100, epoch #33, avg. train loss: 3535140.50000\n",
      "Step #200, epoch #66, avg. train loss: 1560875.62500\n",
      "Step #100, epoch #33, avg. train loss: 3409170.50000\n",
      "Step #200, epoch #66, avg. train loss: 1482112.00000\n",
      "Step #100, epoch #33, avg. train loss: 3366157.75000\n",
      "Step #200, epoch #66, avg. train loss: 1510603.25000\n",
      "Step #100, epoch #50, avg. train loss: 2105841.50000\n",
      "Step #200, epoch #100, avg. train loss: 1629043.37500\n",
      "Step #100, epoch #50, avg. train loss: 2044733.25000\n",
      "Step #200, epoch #100, avg. train loss: 1587471.00000\n",
      "Step #100, epoch #50, avg. train loss: 2157889.75000\n",
      "Step #200, epoch #100, avg. train loss: 1609912.62500\n",
      "Step #100, epoch #100, avg. train loss: 2584310.50000\n",
      "Step #200, epoch #200, avg. train loss: 1534216.00000\n",
      "Step #100, epoch #100, avg. train loss: 2531611.75000\n",
      "Step #200, epoch #200, avg. train loss: 1505191.25000\n",
      "Step #100, epoch #100, avg. train loss: 2599479.00000\n",
      "Step #200, epoch #200, avg. train loss: 1532378.25000\n",
      "Step #100, epoch #100, avg. train loss: 2307819.75000\n",
      "Step #200, epoch #200, avg. train loss: 1591181.75000\n",
      "Step #100, epoch #100, avg. train loss: 2229189.75000\n",
      "Step #200, epoch #200, avg. train loss: 1519301.75000\n",
      "Step #100, epoch #100, avg. train loss: 2318641.50000\n",
      "Step #200, epoch #200, avg. train loss: 1590386.75000\n",
      "Step #100, epoch #100, avg. train loss: 3041012.75000\n",
      "Step #200, epoch #200, avg. train loss: 1519911.37500\n",
      "Step #100, epoch #100, avg. train loss: 2773134.50000\n",
      "Step #200, epoch #200, avg. train loss: 1504348.37500\n",
      "Step #100, epoch #100, avg. train loss: 2848018.50000\n",
      "Step #200, epoch #200, avg. train loss: 1505739.37500\n",
      "Step #100, epoch #100, avg. train loss: 2575749.75000\n",
      "Step #200, epoch #200, avg. train loss: 1646356.12500\n",
      "Step #100, epoch #100, avg. train loss: 2532869.00000\n",
      "Step #200, epoch #200, avg. train loss: 1577641.12500\n",
      "Step #100, epoch #100, avg. train loss: 2559315.00000\n",
      "Step #200, epoch #200, avg. train loss: 1642320.37500\n",
      "Step #100, epoch #100, avg. train loss: 7878363.00000\n",
      "Step #200, epoch #200, avg. train loss: 2809632.25000\n",
      "Step #100, epoch #100, avg. train loss: 8116533.00000\n",
      "Step #200, epoch #200, avg. train loss: 2834742.50000\n",
      "Step #100, epoch #100, avg. train loss: 7663335.00000\n",
      "Step #200, epoch #200, avg. train loss: 2758538.00000\n",
      "Step #100, epoch #14, avg. train loss: 3606000.25000\n",
      "Step #200, epoch #28, avg. train loss: 1591557.12500\n",
      "Step #100, epoch #14, avg. train loss: 3546190.75000\n",
      "Step #200, epoch #28, avg. train loss: 1561951.00000\n",
      "Step #100, epoch #14, avg. train loss: 3927445.00000\n",
      "Step #200, epoch #28, avg. train loss: 1591292.37500\n",
      "Step #100, epoch #12, avg. train loss: 2199004.00000\n",
      "Step #200, epoch #25, avg. train loss: 1736651.25000\n",
      "Step #100, epoch #12, avg. train loss: 2105293.50000\n",
      "Step #200, epoch #25, avg. train loss: 1613224.37500\n",
      "Step #100, epoch #12, avg. train loss: 2171408.75000\n",
      "Step #200, epoch #25, avg. train loss: 1713178.37500\n",
      "Step #100, epoch #100, avg. train loss: 2390257.50000\n",
      "Step #200, epoch #200, avg. train loss: 1584611.87500\n",
      "Step #100, epoch #100, avg. train loss: 2299168.00000\n",
      "Step #200, epoch #200, avg. train loss: 1515098.87500\n",
      "Step #100, epoch #100, avg. train loss: 2380354.00000\n",
      "Step #200, epoch #200, avg. train loss: 1493610.87500\n",
      "Step #100, epoch #33, avg. train loss: 2920681.00000\n",
      "Step #200, epoch #66, avg. train loss: 1503774.25000\n",
      "Step #100, epoch #33, avg. train loss: 2977476.50000\n",
      "Step #200, epoch #66, avg. train loss: 1498627.25000\n",
      "Step #100, epoch #33, avg. train loss: 2947645.75000\n",
      "Step #200, epoch #66, avg. train loss: 1501615.62500\n",
      "Step #100, epoch #100, avg. train loss: 2193419.00000\n",
      "Step #200, epoch #200, avg. train loss: 1686443.50000\n",
      "Step #100, epoch #100, avg. train loss: 2103775.75000\n",
      "Step #200, epoch #200, avg. train loss: 1514233.62500\n",
      "Step #100, epoch #100, avg. train loss: 2194155.75000\n",
      "Step #200, epoch #200, avg. train loss: 1687711.25000\n",
      "Step #100, epoch #100, avg. train loss: 2204858.50000\n",
      "Step #200, epoch #200, avg. train loss: 1419489.25000\n",
      "Step #100, epoch #100, avg. train loss: 2262712.75000\n",
      "Step #200, epoch #200, avg. train loss: 1408404.50000\n",
      "Step #100, epoch #100, avg. train loss: 2215346.50000\n",
      "Step #200, epoch #200, avg. train loss: 1458635.00000\n",
      "Step #100, epoch #100, avg. train loss: 2746845.50000\n",
      "Step #200, epoch #200, avg. train loss: 1666504.37500\n",
      "Step #100, epoch #100, avg. train loss: 2704704.00000\n",
      "Step #200, epoch #200, avg. train loss: 1523489.25000\n",
      "Step #100, epoch #100, avg. train loss: 2847602.25000\n",
      "Step #200, epoch #200, avg. train loss: 1593980.62500\n",
      "Step #100, epoch #20, avg. train loss: 3105143.25000\n",
      "Step #200, epoch #40, avg. train loss: 1571761.50000\n",
      "Step #100, epoch #20, avg. train loss: 2882217.50000\n",
      "Step #200, epoch #40, avg. train loss: 1501162.12500\n",
      "Step #100, epoch #20, avg. train loss: 3091368.25000\n",
      "Step #200, epoch #40, avg. train loss: 1572265.00000\n",
      "Step #100, epoch #100, avg. train loss: 2268647.25000\n",
      "Step #200, epoch #200, avg. train loss: 1579368.75000\n",
      "Step #100, epoch #100, avg. train loss: 2201189.25000\n",
      "Step #200, epoch #200, avg. train loss: 1505188.12500\n",
      "Step #100, epoch #100, avg. train loss: 2274005.50000\n",
      "Step #200, epoch #200, avg. train loss: 1590130.87500\n",
      "Step #100, epoch #33, avg. train loss: 8777496.00000\n",
      "Step #200, epoch #66, avg. train loss: 2945955.50000\n",
      "Step #100, epoch #33, avg. train loss: 9025043.00000\n",
      "Step #200, epoch #66, avg. train loss: 2957338.25000\n",
      "Step #100, epoch #33, avg. train loss: 8533498.00000\n",
      "Step #200, epoch #66, avg. train loss: 2885027.25000\n",
      "Step #100, epoch #100, avg. train loss: 2273985.50000\n",
      "Step #200, epoch #200, avg. train loss: 1552423.25000\n",
      "Step #100, epoch #100, avg. train loss: 2193830.75000\n",
      "Step #200, epoch #200, avg. train loss: 1482973.00000\n",
      "Step #100, epoch #100, avg. train loss: 2284778.00000\n",
      "Step #200, epoch #200, avg. train loss: 1563531.00000\n",
      "Step #100, epoch #100, avg. train loss: 2844225.50000\n",
      "Step #200, epoch #200, avg. train loss: 1572090.37500\n",
      "Step #100, epoch #100, avg. train loss: 2894811.00000\n",
      "Step #200, epoch #200, avg. train loss: 1610271.25000\n",
      "Step #100, epoch #100, avg. train loss: 2613804.25000\n",
      "Step #200, epoch #200, avg. train loss: 1650682.75000\n",
      "Step #100, epoch #100, avg. train loss: 2746101.50000\n",
      "Step #200, epoch #200, avg. train loss: 1581484.62500\n",
      "Step #100, epoch #100, avg. train loss: 2854338.00000\n",
      "Step #200, epoch #200, avg. train loss: 1476815.37500\n",
      "Step #100, epoch #100, avg. train loss: 2743442.25000\n",
      "Step #200, epoch #200, avg. train loss: 1459537.75000\n",
      "Step #100, epoch #25, avg. train loss: 2178960.25000\n",
      "Step #200, epoch #50, avg. train loss: 1728352.00000\n",
      "Step #100, epoch #25, avg. train loss: 2101473.50000\n",
      "Step #200, epoch #50, avg. train loss: 1646815.00000\n",
      "Step #100, epoch #25, avg. train loss: 2202114.50000\n",
      "Step #200, epoch #50, avg. train loss: 1753985.25000\n",
      "Step #100, epoch #100, avg. train loss: 2259913.50000\n",
      "Step #200, epoch #200, avg. train loss: 1491328.50000\n",
      "Step #100, epoch #100, avg. train loss: 2189799.25000\n",
      "Step #200, epoch #200, avg. train loss: 1443678.37500\n",
      "Step #100, epoch #100, avg. train loss: 2263845.00000\n",
      "Step #200, epoch #200, avg. train loss: 1521613.00000\n",
      "Step #100, epoch #100, avg. train loss: 2160550.00000\n",
      "Step #200, epoch #200, avg. train loss: 1667738.87500\n",
      "Step #100, epoch #100, avg. train loss: 2091655.25000\n",
      "Step #200, epoch #200, avg. train loss: 1511287.50000\n",
      "Step #100, epoch #100, avg. train loss: 2164547.75000\n",
      "Step #200, epoch #200, avg. train loss: 1617494.75000\n",
      "Step #100, epoch #8, avg. train loss: 2205328.75000\n",
      "Step #200, epoch #16, avg. train loss: 1731719.37500\n",
      "Step #100, epoch #8, avg. train loss: 2248600.25000\n",
      "Step #200, epoch #16, avg. train loss: 1712804.37500\n",
      "Step #100, epoch #8, avg. train loss: 2224683.75000\n",
      "Step #200, epoch #16, avg. train loss: 1716073.00000\n",
      "Step #100, epoch #25, avg. train loss: 3217381.75000\n",
      "Step #200, epoch #50, avg. train loss: 1604953.87500\n",
      "Step #100, epoch #25, avg. train loss: 3095802.50000\n",
      "Step #200, epoch #50, avg. train loss: 1591810.37500\n",
      "Step #100, epoch #25, avg. train loss: 3167518.00000\n",
      "Step #200, epoch #50, avg. train loss: 1609644.75000\n",
      "Step #100, epoch #25, avg. train loss: 2246878.50000\n",
      "Step #200, epoch #50, avg. train loss: 1523224.37500\n",
      "Step #100, epoch #25, avg. train loss: 2084122.50000\n",
      "Step #200, epoch #50, avg. train loss: 1518833.12500\n",
      "Step #100, epoch #25, avg. train loss: 2228459.75000\n",
      "Step #200, epoch #50, avg. train loss: 1540608.12500\n",
      "Step #100, epoch #100, avg. train loss: 3324600.75000\n",
      "Step #200, epoch #200, avg. train loss: 1758921.62500\n",
      "Step #100, epoch #100, avg. train loss: 3324321.50000\n",
      "Step #200, epoch #200, avg. train loss: 1521475.37500\n",
      "Step #100, epoch #100, avg. train loss: 3298199.75000\n",
      "Step #200, epoch #200, avg. train loss: 1556259.87500\n",
      "Step #100, epoch #100, avg. train loss: 2212649.25000\n",
      "Step #200, epoch #200, avg. train loss: 1547087.50000\n",
      "Step #100, epoch #100, avg. train loss: 2207867.00000\n",
      "Step #200, epoch #200, avg. train loss: 1373622.75000\n",
      "Step #100, epoch #100, avg. train loss: 2217308.25000\n",
      "Step #200, epoch #200, avg. train loss: 1577063.25000\n",
      "Step #100, epoch #100, avg. train loss: 3628549.50000\n",
      "Step #200, epoch #200, avg. train loss: 1505191.62500\n",
      "Step #100, epoch #100, avg. train loss: 3565142.50000\n",
      "Step #200, epoch #200, avg. train loss: 1510230.75000\n",
      "Step #100, epoch #100, avg. train loss: 3539568.25000\n",
      "Step #200, epoch #200, avg. train loss: 1484904.50000\n",
      "Step #100, epoch #50, avg. train loss: 3134983.25000\n",
      "Step #200, epoch #100, avg. train loss: 1510155.62500\n",
      "Step #100, epoch #50, avg. train loss: 3023471.75000\n",
      "Step #200, epoch #100, avg. train loss: 1473491.00000\n",
      "Step #100, epoch #50, avg. train loss: 3025352.00000\n",
      "Step #200, epoch #100, avg. train loss: 1534566.87500\n",
      "Step #100, epoch #50, avg. train loss: 2108874.50000\n",
      "Step #200, epoch #100, avg. train loss: 1620611.37500\n",
      "Step #100, epoch #50, avg. train loss: 2013420.12500\n",
      "Step #200, epoch #100, avg. train loss: 1536818.75000\n",
      "Step #100, epoch #50, avg. train loss: 2156133.50000\n",
      "Step #200, epoch #100, avg. train loss: 1584053.87500\n",
      "Step #100, epoch #33, avg. train loss: 2221250.75000\n",
      "Step #200, epoch #66, avg. train loss: 1749275.25000\n",
      "Step #100, epoch #33, avg. train loss: 2130502.25000\n",
      "Step #200, epoch #66, avg. train loss: 1626720.37500\n",
      "Step #100, epoch #33, avg. train loss: 2251020.00000\n",
      "Step #200, epoch #66, avg. train loss: 1757283.37500\n",
      "Step #100, epoch #50, avg. train loss: 2324859.00000\n",
      "Step #200, epoch #100, avg. train loss: 1524745.87500\n",
      "Step #100, epoch #50, avg. train loss: 2267091.00000\n",
      "Step #200, epoch #100, avg. train loss: 1499060.12500\n",
      "Step #100, epoch #50, avg. train loss: 2273989.50000\n",
      "Step #200, epoch #100, avg. train loss: 1447756.50000\n",
      "Step #100, epoch #12, avg. train loss: 2891349.75000\n",
      "Step #200, epoch #25, avg. train loss: 1603093.87500\n",
      "Step #100, epoch #12, avg. train loss: 3372884.75000\n",
      "Step #200, epoch #25, avg. train loss: 1474173.50000\n",
      "Step #100, epoch #12, avg. train loss: 3196083.75000\n",
      "Step #200, epoch #25, avg. train loss: 1537839.25000\n",
      "Step #100, epoch #50, avg. train loss: 2154935.25000\n",
      "Step #200, epoch #100, avg. train loss: 1535986.50000\n",
      "Step #100, epoch #50, avg. train loss: 2116338.50000\n",
      "Step #200, epoch #100, avg. train loss: 1520126.50000\n",
      "Step #100, epoch #50, avg. train loss: 2166939.75000\n",
      "Step #200, epoch #100, avg. train loss: 1543512.00000\n",
      "Step #100, epoch #20, avg. train loss: 2835093.00000\n",
      "Step #200, epoch #40, avg. train loss: 1672242.50000\n",
      "Step #100, epoch #20, avg. train loss: 2728994.00000\n",
      "Step #200, epoch #40, avg. train loss: 1524124.37500\n",
      "Step #100, epoch #20, avg. train loss: 2672098.25000\n",
      "Step #200, epoch #40, avg. train loss: 1641679.87500\n",
      "Step #100, epoch #12, avg. train loss: 3564414.50000\n",
      "Step #200, epoch #25, avg. train loss: 1617237.12500\n",
      "Step #100, epoch #12, avg. train loss: 3026543.75000\n",
      "Step #200, epoch #25, avg. train loss: 1668259.50000\n",
      "Step #100, epoch #12, avg. train loss: 2827331.75000\n",
      "Step #200, epoch #25, avg. train loss: 1772656.00000\n",
      "Step #100, epoch #100, avg. train loss: 2156723.00000\n",
      "Step #200, epoch #200, avg. train loss: 1565914.37500\n",
      "Step #100, epoch #100, avg. train loss: 2092559.00000\n",
      "Step #200, epoch #200, avg. train loss: 1445047.00000\n",
      "Step #100, epoch #100, avg. train loss: 2150497.25000\n",
      "Step #200, epoch #200, avg. train loss: 1456845.50000\n",
      "Step #100, epoch #50, avg. train loss: 2450650.25000\n",
      "Step #200, epoch #100, avg. train loss: 1649511.87500\n",
      "Step #100, epoch #50, avg. train loss: 2428487.50000\n",
      "Step #200, epoch #100, avg. train loss: 1616419.62500\n",
      "Step #100, epoch #50, avg. train loss: 2379248.50000\n",
      "Step #200, epoch #100, avg. train loss: 1572708.12500\n",
      "Step #100, epoch #100, avg. train loss: 3004834.50000\n",
      "Step #200, epoch #200, avg. train loss: 1552460.50000\n",
      "Step #100, epoch #100, avg. train loss: 2956844.75000\n",
      "Step #200, epoch #200, avg. train loss: 1510486.87500\n",
      "Step #100, epoch #100, avg. train loss: 2984733.50000\n",
      "Step #200, epoch #200, avg. train loss: 1588640.62500\n",
      "Step #100, epoch #4, avg. train loss: 3041547.75000\n",
      "Step #200, epoch #8, avg. train loss: 1811694.25000\n",
      "Step #100, epoch #4, avg. train loss: 3009525.50000\n",
      "Step #200, epoch #8, avg. train loss: 1749800.62500\n",
      "Step #100, epoch #4, avg. train loss: 3017081.25000\n",
      "Step #200, epoch #8, avg. train loss: 1838823.87500\n",
      "Step #100, epoch #100, avg. train loss: 2286691.00000\n",
      "Step #200, epoch #200, avg. train loss: 1525186.50000\n",
      "Step #100, epoch #100, avg. train loss: 2202710.00000\n",
      "Step #200, epoch #200, avg. train loss: 1499933.87500\n",
      "Step #100, epoch #100, avg. train loss: 2281692.25000\n",
      "Step #200, epoch #200, avg. train loss: 1523864.50000\n",
      "Step #100, epoch #100, avg. train loss: 2536765.75000\n",
      "Step #200, epoch #200, avg. train loss: 1650978.87500\n",
      "Step #100, epoch #100, avg. train loss: 2772897.25000\n",
      "Step #200, epoch #200, avg. train loss: 1652634.75000\n",
      "Step #100, epoch #100, avg. train loss: 2461603.00000\n",
      "Step #200, epoch #200, avg. train loss: 1598872.62500\n",
      "Step #100, epoch #25, avg. train loss: 2890860.75000\n",
      "Step #200, epoch #50, avg. train loss: 1789259.25000\n",
      "Step #100, epoch #25, avg. train loss: 2869688.00000\n",
      "Step #200, epoch #50, avg. train loss: 1698608.00000\n",
      "Step #100, epoch #25, avg. train loss: 2879390.75000\n",
      "Step #200, epoch #50, avg. train loss: 1816830.25000\n",
      "Step #100, epoch #100, avg. train loss: 2755640.00000\n",
      "Step #200, epoch #200, avg. train loss: 1577328.75000\n",
      "Step #100, epoch #100, avg. train loss: 2694113.25000\n",
      "Step #200, epoch #200, avg. train loss: 1518913.75000\n",
      "Step #100, epoch #100, avg. train loss: 2763406.00000\n",
      "Step #200, epoch #200, avg. train loss: 1590801.62500\n",
      "Step #100, epoch #100, avg. train loss: 2130423.00000\n",
      "Step #200, epoch #200, avg. train loss: 1594265.62500\n",
      "Step #100, epoch #100, avg. train loss: 2042466.25000\n",
      "Step #200, epoch #200, avg. train loss: 1566716.75000\n",
      "Step #100, epoch #100, avg. train loss: 2140406.50000\n",
      "Step #200, epoch #200, avg. train loss: 1631716.75000\n",
      "Step #100, epoch #50, avg. train loss: 2835931.00000\n",
      "Step #200, epoch #100, avg. train loss: 1572790.50000\n",
      "Step #100, epoch #50, avg. train loss: 2836868.75000\n",
      "Step #200, epoch #100, avg. train loss: 1435433.25000\n",
      "Step #100, epoch #50, avg. train loss: 2815424.00000\n",
      "Step #200, epoch #100, avg. train loss: 1581113.00000\n",
      "Step #100, epoch #100, avg. train loss: 2991000.25000\n",
      "Step #200, epoch #200, avg. train loss: 1714656.75000\n",
      "Step #100, epoch #100, avg. train loss: 2778468.25000\n",
      "Step #200, epoch #200, avg. train loss: 1615299.00000\n",
      "Step #100, epoch #100, avg. train loss: 2854888.75000\n",
      "Step #200, epoch #200, avg. train loss: 1504605.25000\n",
      "Step #100, epoch #100, avg. train loss: 2847132.75000\n",
      "Step #200, epoch #200, avg. train loss: 1574553.25000\n",
      "Step #100, epoch #100, avg. train loss: 2757568.25000\n",
      "Step #200, epoch #200, avg. train loss: 1485626.12500\n",
      "Step #100, epoch #100, avg. train loss: 2792324.75000\n",
      "Step #200, epoch #200, avg. train loss: 1466606.12500\n",
      "Step #100, epoch #16, avg. train loss: 2789745.50000\n",
      "Step #200, epoch #33, avg. train loss: 1562445.62500\n",
      "Step #100, epoch #16, avg. train loss: 2962943.25000\n",
      "Step #200, epoch #33, avg. train loss: 1411736.12500\n",
      "Step #100, epoch #16, avg. train loss: 2924210.50000\n",
      "Step #200, epoch #33, avg. train loss: 1556240.50000\n",
      "Step #100, epoch #100, avg. train loss: 2064204.00000\n",
      "Step #200, epoch #200, avg. train loss: 1571107.62500\n",
      "Step #100, epoch #100, avg. train loss: 1998370.12500\n",
      "Step #200, epoch #200, avg. train loss: 1529219.00000\n",
      "Step #100, epoch #100, avg. train loss: 2065181.25000\n",
      "Step #200, epoch #200, avg. train loss: 1518473.25000\n",
      "Step #100, epoch #50, avg. train loss: 2143757.25000\n",
      "Step #200, epoch #100, avg. train loss: 1566100.50000\n",
      "Step #100, epoch #50, avg. train loss: 2068776.75000\n",
      "Step #200, epoch #100, avg. train loss: 1621583.62500\n",
      "Step #100, epoch #50, avg. train loss: 2207136.00000\n",
      "Step #200, epoch #100, avg. train loss: 1578549.12500\n",
      "Step #100, epoch #5, avg. train loss: 3893271.25000\n",
      "Step #200, epoch #10, avg. train loss: 1584105.87500\n",
      "Step #100, epoch #5, avg. train loss: 3285671.00000\n",
      "Step #200, epoch #10, avg. train loss: 1617721.75000\n",
      "Step #100, epoch #5, avg. train loss: 3397462.00000\n",
      "Step #200, epoch #10, avg. train loss: 1604358.37500\n",
      "Step #100, epoch #50, avg. train loss: 2222210.00000\n",
      "Step #200, epoch #100, avg. train loss: 1616499.62500\n",
      "Step #100, epoch #50, avg. train loss: 2140035.50000\n",
      "Step #200, epoch #100, avg. train loss: 1587795.25000\n",
      "Step #100, epoch #50, avg. train loss: 2211857.00000\n",
      "Step #200, epoch #100, avg. train loss: 1670608.37500\n",
      "Step #100, epoch #12, avg. train loss: 2281111.25000\n",
      "Step #200, epoch #25, avg. train loss: 1623885.12500\n",
      "Step #100, epoch #12, avg. train loss: 2229962.00000\n",
      "Step #200, epoch #25, avg. train loss: 1614467.25000\n",
      "Step #100, epoch #12, avg. train loss: 2334053.50000\n",
      "Step #200, epoch #25, avg. train loss: 1614781.87500\n",
      "Step #100, epoch #50, avg. train loss: 2091207.25000\n",
      "Step #200, epoch #100, avg. train loss: 1626459.62500\n",
      "Step #100, epoch #50, avg. train loss: 2036054.75000\n",
      "Step #200, epoch #100, avg. train loss: 1610195.50000\n",
      "Step #100, epoch #50, avg. train loss: 2130935.75000\n",
      "Step #200, epoch #100, avg. train loss: 1618381.00000\n",
      "Step #100, epoch #33, avg. train loss: 2209327.75000\n",
      "Step #200, epoch #66, avg. train loss: 1573304.12500\n",
      "Step #100, epoch #33, avg. train loss: 2152299.25000\n",
      "Step #200, epoch #66, avg. train loss: 1547656.62500\n",
      "Step #100, epoch #33, avg. train loss: 2234934.50000\n",
      "Step #200, epoch #66, avg. train loss: 1609236.00000\n",
      "Step #100, epoch #100, avg. train loss: 2832420.50000\n",
      "Step #200, epoch #200, avg. train loss: 1490952.75000\n",
      "Step #100, epoch #100, avg. train loss: 2781846.75000\n",
      "Step #200, epoch #200, avg. train loss: 1504999.25000\n",
      "Step #100, epoch #100, avg. train loss: 2826589.50000\n",
      "Step #200, epoch #200, avg. train loss: 1490505.12500\n",
      "Step #100, epoch #100, avg. train loss: 2917483.50000\n",
      "Step #200, epoch #200, avg. train loss: 1558088.00000\n",
      "Step #100, epoch #100, avg. train loss: 2966724.25000\n",
      "Step #200, epoch #200, avg. train loss: 1598715.50000\n",
      "Step #100, epoch #100, avg. train loss: 2914520.00000\n",
      "Step #200, epoch #200, avg. train loss: 1605388.37500\n",
      "Step #100, epoch #100, avg. train loss: 2108527.25000\n",
      "Step #200, epoch #200, avg. train loss: 1580362.75000\n",
      "Step #100, epoch #100, avg. train loss: 2045161.50000\n",
      "Step #200, epoch #200, avg. train loss: 1529077.12500\n",
      "Step #100, epoch #100, avg. train loss: 2113159.75000\n",
      "Step #200, epoch #200, avg. train loss: 1576206.50000\n",
      "Step #100, epoch #3, avg. train loss: 2456474.75000\n",
      "Step #200, epoch #6, avg. train loss: 1738495.50000\n",
      "Step #100, epoch #3, avg. train loss: 2430132.50000\n",
      "Step #200, epoch #6, avg. train loss: 1655067.50000\n",
      "Step #100, epoch #3, avg. train loss: 2514252.75000\n",
      "Step #200, epoch #6, avg. train loss: 1726474.50000\n",
      "Step #100, epoch #100, avg. train loss: 6102875.00000\n",
      "Step #200, epoch #200, avg. train loss: 1840129.12500\n",
      "Step #100, epoch #100, avg. train loss: 6273549.00000\n",
      "Step #200, epoch #200, avg. train loss: 1758376.00000\n",
      "Step #100, epoch #100, avg. train loss: 5940566.50000\n",
      "Step #200, epoch #200, avg. train loss: 1859126.75000\n",
      "Step #100, epoch #33, avg. train loss: 2207112.25000\n",
      "Step #200, epoch #66, avg. train loss: 1737961.62500\n",
      "Step #100, epoch #33, avg. train loss: 2113518.50000\n",
      "Step #200, epoch #66, avg. train loss: 1653784.62500\n",
      "Step #100, epoch #33, avg. train loss: 2198951.25000\n",
      "Step #200, epoch #66, avg. train loss: 1747187.37500\n",
      "Step #100, epoch #100, avg. train loss: 2898927.00000\n",
      "Step #200, epoch #200, avg. train loss: 1502284.62500\n",
      "Step #100, epoch #100, avg. train loss: 2892362.00000\n",
      "Step #200, epoch #200, avg. train loss: 1545052.00000\n",
      "Step #100, epoch #100, avg. train loss: 2908327.00000\n",
      "Step #200, epoch #200, avg. train loss: 1512134.50000\n",
      "Step #100, epoch #12, avg. train loss: 2946248.75000\n",
      "Step #200, epoch #25, avg. train loss: 1599408.50000\n",
      "Step #100, epoch #12, avg. train loss: 2866547.50000\n",
      "Step #200, epoch #25, avg. train loss: 1585416.00000\n",
      "Step #100, epoch #12, avg. train loss: 2860362.25000\n",
      "Step #200, epoch #25, avg. train loss: 1642986.12500\n",
      "Step #100, epoch #50, avg. train loss: 2345086.00000\n",
      "Step #200, epoch #100, avg. train loss: 1711003.50000\n",
      "Step #100, epoch #50, avg. train loss: 2389943.00000\n",
      "Step #200, epoch #100, avg. train loss: 1711350.12500\n",
      "Step #100, epoch #50, avg. train loss: 2455276.50000\n",
      "Step #200, epoch #100, avg. train loss: 1753961.62500\n",
      "Step #100, epoch #50, avg. train loss: 2117488.00000\n",
      "Step #200, epoch #100, avg. train loss: 1496753.75000\n",
      "Step #100, epoch #50, avg. train loss: 2044152.00000\n",
      "Step #200, epoch #100, avg. train loss: 1484615.37500\n",
      "Step #100, epoch #50, avg. train loss: 2137572.00000\n",
      "Step #200, epoch #100, avg. train loss: 1597860.00000\n",
      "Step #100, epoch #100, avg. train loss: 2272827.25000\n",
      "Step #200, epoch #200, avg. train loss: 1472446.37500\n",
      "Step #100, epoch #100, avg. train loss: 2228689.00000\n",
      "Step #200, epoch #200, avg. train loss: 1490736.37500\n",
      "Step #100, epoch #100, avg. train loss: 2280002.00000\n",
      "Step #200, epoch #200, avg. train loss: 1473699.37500\n",
      "Step #100, epoch #100, avg. train loss: 2262035.25000\n",
      "Step #200, epoch #200, avg. train loss: 1456370.75000\n",
      "Step #100, epoch #100, avg. train loss: 2193823.00000\n",
      "Step #200, epoch #200, avg. train loss: 1411903.25000\n",
      "Step #100, epoch #100, avg. train loss: 2279241.00000\n",
      "Step #200, epoch #200, avg. train loss: 1461370.75000\n",
      "Step #100, epoch #100, avg. train loss: 2654761.25000\n",
      "Step #200, epoch #200, avg. train loss: 1608198.12500\n",
      "Step #100, epoch #100, avg. train loss: 3251743.00000\n",
      "Step #200, epoch #200, avg. train loss: 1701874.25000\n",
      "Step #100, epoch #100, avg. train loss: 2731773.50000\n",
      "Step #200, epoch #200, avg. train loss: 1757307.25000\n",
      "Step #100, epoch #100, avg. train loss: 2301021.50000\n",
      "Step #200, epoch #200, avg. train loss: 1578543.00000\n",
      "Step #100, epoch #100, avg. train loss: 2216197.50000\n",
      "Step #200, epoch #200, avg. train loss: 1555380.50000\n",
      "Step #100, epoch #100, avg. train loss: 2318457.50000\n",
      "Step #200, epoch #200, avg. train loss: 1553690.25000\n",
      "Step #100, epoch #100, avg. train loss: 5959938.00000\n",
      "Step #200, epoch #200, avg. train loss: 1832232.62500\n",
      "Step #100, epoch #100, avg. train loss: 6014707.00000\n",
      "Step #200, epoch #200, avg. train loss: 1730419.62500\n",
      "Step #100, epoch #100, avg. train loss: 5710728.50000\n",
      "Step #200, epoch #200, avg. train loss: 1838093.12500\n",
      "Step #100, epoch #50, avg. train loss: 2493201.00000\n",
      "Step #200, epoch #100, avg. train loss: 1579525.25000\n",
      "Step #100, epoch #50, avg. train loss: 2951334.75000\n",
      "Step #200, epoch #100, avg. train loss: 1615316.12500\n",
      "Step #100, epoch #50, avg. train loss: 2504531.75000\n",
      "Step #200, epoch #100, avg. train loss: 1593809.75000\n",
      "Step #100, epoch #100, avg. train loss: 2142977.00000\n",
      "Step #200, epoch #200, avg. train loss: 1569322.12500\n",
      "Step #100, epoch #100, avg. train loss: 2069489.25000\n",
      "Step #200, epoch #200, avg. train loss: 1451908.12500\n",
      "Step #100, epoch #100, avg. train loss: 2165613.00000\n",
      "Step #200, epoch #200, avg. train loss: 1631293.00000\n",
      "Step #99, avg. train loss: 4135808.75000\n",
      "Step #200, epoch #1, avg. train loss: 2453292.25000\n",
      "Step #99, avg. train loss: 3335531.25000\n",
      "Step #200, epoch #1, avg. train loss: 2172237.50000\n",
      "Step #99, avg. train loss: 3814802.25000\n",
      "Step #200, epoch #1, avg. train loss: 2301650.50000\n",
      "Step #100, epoch #25, avg. train loss: 2245819.75000\n",
      "Step #200, epoch #50, avg. train loss: 1700354.50000\n",
      "Step #100, epoch #25, avg. train loss: 2159033.50000\n",
      "Step #200, epoch #50, avg. train loss: 1579246.12500\n",
      "Step #100, epoch #25, avg. train loss: 2253131.00000\n",
      "Step #200, epoch #50, avg. train loss: 1681279.50000\n",
      "Step #100, epoch #100, avg. train loss: 2129699.00000\n",
      "Step #200, epoch #200, avg. train loss: 1649642.75000\n",
      "Step #100, epoch #100, avg. train loss: 2074811.50000\n",
      "Step #200, epoch #200, avg. train loss: 1641775.37500\n",
      "Step #100, epoch #100, avg. train loss: 2141124.25000\n",
      "Step #200, epoch #200, avg. train loss: 1666014.37500\n",
      "Step #100, epoch #14, avg. train loss: 2275906.50000\n",
      "Step #200, epoch #28, avg. train loss: 1507592.75000\n",
      "Step #100, epoch #14, avg. train loss: 2212594.00000\n",
      "Step #200, epoch #28, avg. train loss: 1463909.12500\n",
      "Step #100, epoch #14, avg. train loss: 2348544.75000\n",
      "Step #200, epoch #28, avg. train loss: 1567629.12500\n",
      "Step #100, epoch #50, avg. train loss: 2775557.75000\n",
      "Step #200, epoch #100, avg. train loss: 1536862.75000\n",
      "Step #100, epoch #50, avg. train loss: 2739514.25000\n",
      "Step #200, epoch #100, avg. train loss: 1525433.50000\n",
      "Step #100, epoch #50, avg. train loss: 2751474.25000\n",
      "Step #200, epoch #100, avg. train loss: 1535276.75000\n",
      "Step #100, epoch #100, avg. train loss: 2106082.75000\n",
      "Step #200, epoch #200, avg. train loss: 1639114.75000\n",
      "Step #100, epoch #100, avg. train loss: 2022043.62500\n",
      "Step #200, epoch #200, avg. train loss: 1577566.75000\n",
      "Step #100, epoch #100, avg. train loss: 2120997.00000\n",
      "Step #200, epoch #200, avg. train loss: 1624926.25000\n",
      "Step #100, epoch #100, avg. train loss: 2213941.25000\n",
      "Step #200, epoch #200, avg. train loss: 1485737.87500\n",
      "Step #100, epoch #100, avg. train loss: 2163873.75000\n",
      "Step #200, epoch #200, avg. train loss: 1426595.87500\n",
      "Step #100, epoch #100, avg. train loss: 2229816.75000\n",
      "Step #200, epoch #200, avg. train loss: 1504841.87500\n",
      "Step #100, epoch #20, avg. train loss: 2224811.00000\n",
      "Step #200, epoch #40, avg. train loss: 1555757.62500\n",
      "Step #100, epoch #20, avg. train loss: 2113236.25000\n",
      "Step #200, epoch #40, avg. train loss: 1538763.25000\n",
      "Step #100, epoch #20, avg. train loss: 2186014.50000\n",
      "Step #200, epoch #40, avg. train loss: 1580023.25000\n",
      "Step #100, epoch #50, avg. train loss: 2912111.00000\n",
      "Step #200, epoch #100, avg. train loss: 1508813.12500\n",
      "Step #100, epoch #50, avg. train loss: 2931553.25000\n",
      "Step #200, epoch #100, avg. train loss: 1525006.75000\n",
      "Step #100, epoch #50, avg. train loss: 2998786.25000\n",
      "Step #200, epoch #100, avg. train loss: 1515008.37500\n",
      "Step #100, epoch #50, avg. train loss: 3687530.25000\n",
      "Step #200, epoch #100, avg. train loss: 1581684.62500\n",
      "Step #100, epoch #50, avg. train loss: 3470658.00000\n",
      "Step #200, epoch #100, avg. train loss: 1509481.12500\n",
      "Step #100, epoch #50, avg. train loss: 3444840.75000\n",
      "Step #200, epoch #100, avg. train loss: 1531308.62500\n",
      "Step #100, epoch #100, avg. train loss: 2960210.25000\n",
      "Step #200, epoch #200, avg. train loss: 1584733.00000\n",
      "Step #100, epoch #100, avg. train loss: 2827761.00000\n",
      "Step #200, epoch #200, avg. train loss: 1478933.25000\n",
      "Step #100, epoch #100, avg. train loss: 2745559.25000\n",
      "Step #200, epoch #200, avg. train loss: 1438952.00000\n",
      "Step #100, epoch #100, avg. train loss: 2803182.00000\n",
      "Step #200, epoch #200, avg. train loss: 1541603.62500\n",
      "Step #100, epoch #100, avg. train loss: 2750097.00000\n",
      "Step #200, epoch #200, avg. train loss: 1585988.75000\n",
      "Step #100, epoch #100, avg. train loss: 2797623.00000\n",
      "Step #200, epoch #200, avg. train loss: 1528741.87500\n",
      "Step #100, epoch #100, avg. train loss: 2357251.00000\n",
      "Step #200, epoch #200, avg. train loss: 1607603.50000\n",
      "Step #100, epoch #100, avg. train loss: 2273234.50000\n",
      "Step #200, epoch #200, avg. train loss: 1551574.50000\n",
      "Step #100, epoch #100, avg. train loss: 2371794.50000\n",
      "Step #200, epoch #200, avg. train loss: 1593327.25000\n",
      "Step #100, epoch #33, avg. train loss: 2199328.25000\n",
      "Step #200, epoch #66, avg. train loss: 1705448.37500\n",
      "Step #100, epoch #33, avg. train loss: 2119625.75000\n",
      "Step #200, epoch #66, avg. train loss: 1647869.62500\n",
      "Step #100, epoch #33, avg. train loss: 2226393.00000\n",
      "Step #200, epoch #66, avg. train loss: 1765078.12500\n",
      "Step #100, epoch #100, avg. train loss: 2307780.50000\n",
      "Step #200, epoch #200, avg. train loss: 1462999.37500\n",
      "Step #100, epoch #100, avg. train loss: 2271847.75000\n",
      "Step #200, epoch #200, avg. train loss: 1350582.37500\n",
      "Step #100, epoch #100, avg. train loss: 2313867.25000\n",
      "Step #200, epoch #200, avg. train loss: 1467193.75000\n",
      "Step #100, epoch #100, avg. train loss: 2832920.25000\n",
      "Step #200, epoch #200, avg. train loss: 1516719.62500\n",
      "Step #100, epoch #100, avg. train loss: 2769550.00000\n",
      "Step #200, epoch #200, avg. train loss: 1607341.00000\n",
      "Step #100, epoch #100, avg. train loss: 2875838.00000\n",
      "Step #200, epoch #200, avg. train loss: 1519217.75000\n",
      "Step #100, epoch #100, avg. train loss: 2151472.75000\n",
      "Step #200, epoch #200, avg. train loss: 1509937.62500\n",
      "Step #100, epoch #100, avg. train loss: 2078126.25000\n",
      "Step #200, epoch #200, avg. train loss: 1420925.00000\n",
      "Step #100, epoch #100, avg. train loss: 2158204.75000\n",
      "Step #200, epoch #200, avg. train loss: 1493836.75000\n",
      "Step #100, epoch #100, avg. train loss: 2270664.75000\n",
      "Step #200, epoch #200, avg. train loss: 1453481.12500\n",
      "Step #100, epoch #100, avg. train loss: 2183621.50000\n",
      "Step #200, epoch #200, avg. train loss: 1456685.87500\n",
      "Step #100, epoch #100, avg. train loss: 2303822.00000\n",
      "Step #200, epoch #200, avg. train loss: 1532269.50000\n",
      "Step #100, epoch #100, avg. train loss: 2370700.25000\n",
      "Step #200, epoch #200, avg. train loss: 1602165.75000\n",
      "Step #100, epoch #100, avg. train loss: 2284077.25000\n",
      "Step #200, epoch #200, avg. train loss: 1551082.50000\n",
      "Step #100, epoch #100, avg. train loss: 2387218.50000\n",
      "Step #200, epoch #200, avg. train loss: 1576632.12500\n",
      "Step #100, epoch #33, avg. train loss: 2243921.50000\n",
      "Step #200, epoch #66, avg. train loss: 1482555.00000\n",
      "Step #100, epoch #33, avg. train loss: 2239503.00000\n",
      "Step #200, epoch #66, avg. train loss: 1473389.00000\n",
      "Step #100, epoch #33, avg. train loss: 2320911.50000\n",
      "Step #200, epoch #66, avg. train loss: 1507384.00000\n",
      "Step #100, epoch #100, avg. train loss: 2273853.00000\n",
      "Step #200, epoch #200, avg. train loss: 1514940.37500\n",
      "Step #100, epoch #100, avg. train loss: 2187347.75000\n",
      "Step #200, epoch #200, avg. train loss: 1534835.25000\n",
      "Step #100, epoch #100, avg. train loss: 2286476.50000\n",
      "Step #200, epoch #200, avg. train loss: 1485374.37500\n",
      "Step #100, epoch #14, avg. train loss: 2301328.25000\n",
      "Step #200, epoch #28, avg. train loss: 1550848.00000\n",
      "Step #100, epoch #14, avg. train loss: 2206955.75000\n",
      "Step #200, epoch #28, avg. train loss: 1482885.00000\n",
      "Step #100, epoch #14, avg. train loss: 2375651.25000\n",
      "Step #200, epoch #28, avg. train loss: 1544696.00000\n",
      "Step #100, epoch #100, avg. train loss: 2717333.00000\n",
      "Step #200, epoch #200, avg. train loss: 1537043.37500\n",
      "Step #100, epoch #100, avg. train loss: 2634691.50000\n",
      "Step #200, epoch #200, avg. train loss: 1500111.50000\n",
      "Step #100, epoch #100, avg. train loss: 2686805.00000\n",
      "Step #200, epoch #200, avg. train loss: 1537052.50000\n",
      "Step #100, epoch #100, avg. train loss: 2132323.25000\n",
      "Step #200, epoch #200, avg. train loss: 1631903.00000\n",
      "Step #100, epoch #100, avg. train loss: 2061732.12500\n",
      "Step #200, epoch #200, avg. train loss: 1556569.87500\n",
      "Step #100, epoch #100, avg. train loss: 2135904.25000\n",
      "Step #200, epoch #200, avg. train loss: 1618467.00000\n",
      "Step #100, epoch #100, avg. train loss: 2342581.50000\n",
      "Step #200, epoch #200, avg. train loss: 1518000.12500\n",
      "Step #100, epoch #100, avg. train loss: 2263424.50000\n",
      "Step #200, epoch #200, avg. train loss: 1496011.25000\n",
      "Step #100, epoch #100, avg. train loss: 2341915.25000\n",
      "Step #200, epoch #200, avg. train loss: 1536020.12500\n",
      "Step #100, epoch #50, avg. train loss: 2182466.50000\n",
      "Step #200, epoch #100, avg. train loss: 1556018.37500\n",
      "Step #100, epoch #50, avg. train loss: 2099848.75000\n",
      "Step #200, epoch #100, avg. train loss: 1528516.50000\n",
      "Step #100, epoch #50, avg. train loss: 2217520.75000\n",
      "Step #200, epoch #100, avg. train loss: 1572279.50000\n",
      "Step #100, epoch #100, avg. train loss: 2867124.25000\n",
      "Step #200, epoch #200, avg. train loss: 1533311.87500\n",
      "Step #100, epoch #100, avg. train loss: 2659547.00000\n",
      "Step #200, epoch #200, avg. train loss: 1528390.75000\n",
      "Step #100, epoch #100, avg. train loss: 2905632.00000\n",
      "Step #200, epoch #200, avg. train loss: 1590466.87500\n",
      "Step #100, epoch #100, avg. train loss: 2372242.50000\n",
      "Step #200, epoch #200, avg. train loss: 1561992.37500\n",
      "Step #100, epoch #100, avg. train loss: 2328118.00000\n",
      "Step #200, epoch #200, avg. train loss: 1525455.62500\n",
      "Step #100, epoch #100, avg. train loss: 2361853.50000\n",
      "Step #200, epoch #200, avg. train loss: 1550773.87500\n",
      "Step #100, epoch #12, avg. train loss: 3566804.50000\n",
      "Step #200, epoch #25, avg. train loss: 1542167.50000\n",
      "Step #100, epoch #12, avg. train loss: 3358341.50000\n",
      "Step #200, epoch #25, avg. train loss: 1548516.00000\n",
      "Step #100, epoch #12, avg. train loss: 3419359.75000\n",
      "Step #200, epoch #25, avg. train loss: 1618121.12500\n",
      "Step #100, epoch #100, avg. train loss: 2128425.50000\n",
      "Step #200, epoch #200, avg. train loss: 1582664.37500\n",
      "Step #100, epoch #100, avg. train loss: 2050490.50000\n",
      "Step #200, epoch #200, avg. train loss: 1506321.12500\n",
      "Step #100, epoch #100, avg. train loss: 2140059.25000\n",
      "Step #200, epoch #200, avg. train loss: 1566890.50000\n",
      "Step #100, epoch #100, avg. train loss: 2282186.25000\n",
      "Step #200, epoch #200, avg. train loss: 1661044.00000\n",
      "Step #100, epoch #100, avg. train loss: 2225437.50000\n",
      "Step #200, epoch #200, avg. train loss: 1621668.75000\n",
      "Step #100, epoch #100, avg. train loss: 2285267.75000\n",
      "Step #200, epoch #200, avg. train loss: 1700502.37500\n",
      "Step #100, epoch #50, avg. train loss: 2432053.00000\n",
      "Step #200, epoch #100, avg. train loss: 1539266.87500\n",
      "Step #100, epoch #50, avg. train loss: 2818805.75000\n",
      "Step #200, epoch #100, avg. train loss: 1572307.37500\n",
      "Step #100, epoch #50, avg. train loss: 2459423.75000\n",
      "Step #200, epoch #100, avg. train loss: 1602439.37500\n",
      "Step #100, epoch #33, avg. train loss: 2866665.00000\n",
      "Step #200, epoch #66, avg. train loss: 1486287.50000\n",
      "Step #100, epoch #33, avg. train loss: 2746271.75000\n",
      "Step #200, epoch #66, avg. train loss: 1496676.12500\n",
      "Step #100, epoch #33, avg. train loss: 2845623.75000\n",
      "Step #200, epoch #66, avg. train loss: 1480799.87500\n",
      "Step #100, epoch #14, avg. train loss: 2738924.50000\n",
      "Step #200, epoch #28, avg. train loss: 1782646.87500\n",
      "Step #100, epoch #14, avg. train loss: 2679537.50000\n",
      "Step #200, epoch #28, avg. train loss: 1686888.12500\n",
      "Step #100, epoch #14, avg. train loss: 2724544.00000\n",
      "Step #200, epoch #28, avg. train loss: 1827778.25000\n",
      "Step #100, epoch #100, avg. train loss: 2090513.75000\n",
      "Step #200, epoch #200, avg. train loss: 1601976.75000\n",
      "Step #100, epoch #100, avg. train loss: 2005065.00000\n",
      "Step #200, epoch #200, avg. train loss: 1495068.00000\n",
      "Step #100, epoch #100, avg. train loss: 2109509.00000\n",
      "Step #200, epoch #200, avg. train loss: 1641221.62500\n",
      "Step #100, epoch #100, avg. train loss: 2152917.50000\n",
      "Step #200, epoch #200, avg. train loss: 1512372.37500\n",
      "Step #100, epoch #100, avg. train loss: 2064512.50000\n",
      "Step #200, epoch #200, avg. train loss: 1429211.25000\n",
      "Step #100, epoch #100, avg. train loss: 2166530.25000\n",
      "Step #200, epoch #200, avg. train loss: 1552234.87500\n",
      "Step #100, epoch #100, avg. train loss: 2870178.50000\n",
      "Step #200, epoch #200, avg. train loss: 1521296.50000\n",
      "Step #100, epoch #100, avg. train loss: 2823402.50000\n",
      "Step #200, epoch #200, avg. train loss: 1509667.50000\n",
      "Step #100, epoch #100, avg. train loss: 2843164.75000\n",
      "Step #200, epoch #200, avg. train loss: 1513753.87500\n",
      "Step #100, epoch #100, avg. train loss: 2180850.00000\n",
      "Step #200, epoch #200, avg. train loss: 1607549.62500\n",
      "Step #100, epoch #100, avg. train loss: 2108611.00000\n",
      "Step #200, epoch #200, avg. train loss: 1565139.37500\n",
      "Step #100, epoch #100, avg. train loss: 2137383.00000\n",
      "Step #200, epoch #200, avg. train loss: 1417502.50000\n",
      "Step #100, epoch #100, avg. train loss: 2818248.25000\n",
      "Step #200, epoch #200, avg. train loss: 1567149.00000\n",
      "Step #100, epoch #100, avg. train loss: 2816390.00000\n",
      "Step #200, epoch #200, avg. train loss: 1518060.37500\n",
      "Step #100, epoch #100, avg. train loss: 2803769.50000\n",
      "Step #200, epoch #200, avg. train loss: 1536489.87500\n",
      "Step #100, epoch #100, avg. train loss: 2924833.25000\n",
      "Step #200, epoch #200, avg. train loss: 1545541.75000\n",
      "Step #100, epoch #100, avg. train loss: 2827419.50000\n",
      "Step #200, epoch #200, avg. train loss: 1618482.75000\n",
      "Step #100, epoch #100, avg. train loss: 2973272.75000\n",
      "Step #200, epoch #200, avg. train loss: 1536092.37500\n",
      "Step #100, epoch #100, avg. train loss: 2551445.00000\n",
      "Step #200, epoch #200, avg. train loss: 1611773.00000\n",
      "Step #100, epoch #100, avg. train loss: 2514439.00000\n",
      "Step #200, epoch #200, avg. train loss: 1555901.75000\n",
      "Step #100, epoch #100, avg. train loss: 2537665.00000\n",
      "Step #200, epoch #200, avg. train loss: 1612377.62500\n",
      "Step #100, epoch #100, avg. train loss: 2050857.87500\n",
      "Step #200, epoch #200, avg. train loss: 1557478.12500\n",
      "Step #100, epoch #100, avg. train loss: 1978482.25000\n",
      "Step #200, epoch #200, avg. train loss: 1500879.87500\n",
      "Step #100, epoch #100, avg. train loss: 2057946.12500\n",
      "Step #200, epoch #200, avg. train loss: 1501691.87500\n",
      "Step #100, epoch #100, avg. train loss: 2135117.25000\n",
      "Step #200, epoch #200, avg. train loss: 1560543.50000\n",
      "Step #100, epoch #100, avg. train loss: 2064138.50000\n",
      "Step #200, epoch #200, avg. train loss: 1493565.87500\n",
      "Step #100, epoch #100, avg. train loss: 2138381.50000\n",
      "Step #200, epoch #200, avg. train loss: 1529635.87500\n",
      "Step #100, epoch #100, avg. train loss: 2315430.50000\n",
      "Step #200, epoch #200, avg. train loss: 1612561.87500\n",
      "Step #100, epoch #100, avg. train loss: 2249302.25000\n",
      "Step #200, epoch #200, avg. train loss: 1534338.12500\n",
      "Step #100, epoch #100, avg. train loss: 2315526.75000\n",
      "Step #200, epoch #200, avg. train loss: 1609292.62500\n",
      "Step #100, epoch #50, avg. train loss: 2735605.00000\n",
      "Step #200, epoch #100, avg. train loss: 1614753.62500\n",
      "Step #100, epoch #50, avg. train loss: 2856448.25000\n",
      "Step #200, epoch #100, avg. train loss: 1533093.00000\n",
      "Step #100, epoch #50, avg. train loss: 2940305.50000\n",
      "Step #200, epoch #100, avg. train loss: 1507394.12500\n",
      "Step #100, epoch #50, avg. train loss: 11138701.00000\n",
      "Step #200, epoch #100, avg. train loss: 10433646.00000\n",
      "Step #100, epoch #50, avg. train loss: 11375169.00000\n",
      "Step #200, epoch #100, avg. train loss: 10803428.00000\n",
      "Step #100, epoch #50, avg. train loss: 10798840.00000\n",
      "Step #200, epoch #100, avg. train loss: 10309089.00000\n",
      "Step #100, epoch #33, avg. train loss: 2177085.00000\n",
      "Step #200, epoch #66, avg. train loss: 1614979.87500\n",
      "Step #100, epoch #33, avg. train loss: 2110470.25000\n",
      "Step #200, epoch #66, avg. train loss: 1540513.25000\n",
      "Step #100, epoch #33, avg. train loss: 2212349.50000\n",
      "Step #200, epoch #66, avg. train loss: 1651322.25000\n",
      "Step #100, epoch #100, avg. train loss: 2601979.75000\n",
      "Step #200, epoch #200, avg. train loss: 1551445.00000\n",
      "Step #100, epoch #100, avg. train loss: 2622811.25000\n",
      "Step #200, epoch #200, avg. train loss: 1547413.12500\n",
      "Step #100, epoch #100, avg. train loss: 2601522.00000\n",
      "Step #200, epoch #200, avg. train loss: 1570171.50000\n",
      "Step #100, epoch #100, avg. train loss: 2993012.50000\n",
      "Step #200, epoch #200, avg. train loss: 1556005.50000\n",
      "Step #100, epoch #100, avg. train loss: 2900557.00000\n",
      "Step #200, epoch #200, avg. train loss: 1488104.62500\n",
      "Step #100, epoch #100, avg. train loss: 2833905.50000\n",
      "Step #200, epoch #200, avg. train loss: 1722329.75000\n",
      "Step #100, epoch #100, avg. train loss: 2535176.50000\n",
      "Step #200, epoch #200, avg. train loss: 1507177.50000\n",
      "Step #100, epoch #100, avg. train loss: 2443854.50000\n",
      "Step #200, epoch #200, avg. train loss: 1473923.62500\n",
      "Step #100, epoch #100, avg. train loss: 2544855.00000\n",
      "Step #200, epoch #200, avg. train loss: 1499352.75000\n",
      "Step #100, epoch #50, avg. train loss: 2293183.00000\n",
      "Step #200, epoch #100, avg. train loss: 1529354.25000\n",
      "Step #100, epoch #50, avg. train loss: 2184895.75000\n",
      "Step #200, epoch #100, avg. train loss: 1477072.00000\n",
      "Step #100, epoch #50, avg. train loss: 2313519.75000\n",
      "Step #200, epoch #100, avg. train loss: 1578952.37500\n",
      "Step #100, epoch #100, avg. train loss: 2091255.62500\n",
      "Step #200, epoch #200, avg. train loss: 1597354.75000\n",
      "Step #100, epoch #100, avg. train loss: 2030140.50000\n",
      "Step #200, epoch #200, avg. train loss: 1619384.00000\n",
      "Step #100, epoch #100, avg. train loss: 2092229.50000\n",
      "Step #200, epoch #200, avg. train loss: 1579322.25000\n",
      "Step #100, epoch #50, avg. train loss: 2657003.00000\n",
      "Step #200, epoch #100, avg. train loss: 1613617.50000\n",
      "Step #100, epoch #50, avg. train loss: 3481013.00000\n",
      "Step #200, epoch #100, avg. train loss: 1522640.00000\n",
      "Step #100, epoch #50, avg. train loss: 2506540.75000\n",
      "Step #200, epoch #100, avg. train loss: 1645776.37500\n",
      "Step #100, epoch #100, avg. train loss: 9738709.00000\n",
      "Step #200, epoch #200, avg. train loss: 7093742.00000\n",
      "Step #100, epoch #100, avg. train loss: 10013741.00000\n",
      "Step #200, epoch #200, avg. train loss: 7138436.00000\n",
      "Step #100, epoch #100, avg. train loss: 9468313.00000\n",
      "Step #200, epoch #200, avg. train loss: 6742666.00000\n",
      "Step #100, epoch #100, avg. train loss: 2162551.50000\n",
      "Step #200, epoch #200, avg. train loss: 1512011.25000\n",
      "Step #100, epoch #100, avg. train loss: 2083002.25000\n",
      "Step #200, epoch #200, avg. train loss: 1481905.87500\n",
      "Step #100, epoch #100, avg. train loss: 2172471.00000\n",
      "Step #200, epoch #200, avg. train loss: 1512308.62500\n",
      "Step #100, epoch #100, avg. train loss: 2875561.00000\n",
      "Step #200, epoch #200, avg. train loss: 1513084.12500\n",
      "Step #100, epoch #100, avg. train loss: 2802553.50000\n",
      "Step #200, epoch #200, avg. train loss: 1549447.87500\n",
      "Step #100, epoch #100, avg. train loss: 2906308.75000\n",
      "Step #200, epoch #200, avg. train loss: 1515419.25000\n",
      "Step #100, epoch #33, avg. train loss: 2731049.50000\n",
      "Step #200, epoch #66, avg. train loss: 1757297.12500\n",
      "Step #100, epoch #33, avg. train loss: 2686852.25000\n",
      "Step #200, epoch #66, avg. train loss: 1668529.50000\n",
      "Step #100, epoch #33, avg. train loss: 2723265.50000\n",
      "Step #200, epoch #66, avg. train loss: 1776658.87500\n",
      "Step #100, epoch #50, avg. train loss: 2079494.12500\n",
      "Step #200, epoch #100, avg. train loss: 1657320.00000\n",
      "Step #100, epoch #50, avg. train loss: 2005958.25000\n",
      "Step #200, epoch #100, avg. train loss: 1587644.37500\n",
      "Step #100, epoch #50, avg. train loss: 2094537.62500\n",
      "Step #200, epoch #100, avg. train loss: 1636275.00000\n",
      "Step #100, epoch #100, avg. train loss: 3044424.25000\n",
      "Step #200, epoch #200, avg. train loss: 1708301.00000\n",
      "Step #100, epoch #100, avg. train loss: 3016707.25000\n",
      "Step #200, epoch #200, avg. train loss: 1615096.12500\n",
      "Step #100, epoch #100, avg. train loss: 3017187.00000\n",
      "Step #200, epoch #200, avg. train loss: 1722771.62500\n",
      "Step #100, epoch #100, avg. train loss: 2349920.25000\n",
      "Step #200, epoch #200, avg. train loss: 1607910.75000\n",
      "Step #100, epoch #100, avg. train loss: 2267267.00000\n",
      "Step #200, epoch #200, avg. train loss: 1549200.37500\n",
      "Step #100, epoch #100, avg. train loss: 2363370.25000\n",
      "Step #200, epoch #200, avg. train loss: 1586936.00000\n",
      "Step #100, epoch #25, avg. train loss: 3487768.25000\n",
      "Step #200, epoch #50, avg. train loss: 1658643.25000\n",
      "Step #100, epoch #25, avg. train loss: 2590680.75000\n",
      "Step #200, epoch #50, avg. train loss: 1651450.25000\n",
      "Step #100, epoch #25, avg. train loss: 2555080.25000\n",
      "Step #200, epoch #50, avg. train loss: 1535829.50000\n",
      "Step #100, epoch #100, avg. train loss: 2220581.50000\n",
      "Step #200, epoch #200, avg. train loss: 1516836.00000\n",
      "Step #100, epoch #100, avg. train loss: 2144308.00000\n",
      "Step #200, epoch #200, avg. train loss: 1453000.62500\n",
      "Step #100, epoch #100, avg. train loss: 2230117.25000\n",
      "Step #200, epoch #200, avg. train loss: 1506359.50000\n",
      "Step #100, epoch #25, avg. train loss: 2807328.25000\n",
      "Step #200, epoch #50, avg. train loss: 1588354.12500\n",
      "Step #100, epoch #25, avg. train loss: 2721802.25000\n",
      "Step #200, epoch #50, avg. train loss: 1549189.75000\n",
      "Step #100, epoch #25, avg. train loss: 2766289.00000\n",
      "Step #200, epoch #50, avg. train loss: 1481195.00000\n",
      "Step #100, epoch #50, avg. train loss: 4025034.25000\n",
      "Step #200, epoch #100, avg. train loss: 1580167.50000\n",
      "Step #100, epoch #50, avg. train loss: 3637886.50000\n",
      "Step #200, epoch #100, avg. train loss: 1584343.50000\n",
      "Step #100, epoch #50, avg. train loss: 3695559.75000\n",
      "Step #200, epoch #100, avg. train loss: 1588626.37500\n",
      "Step #100, epoch #100, avg. train loss: 2811081.25000\n",
      "Step #200, epoch #200, avg. train loss: 1525405.12500\n",
      "Step #100, epoch #100, avg. train loss: 2853059.50000\n",
      "Step #200, epoch #200, avg. train loss: 1492970.12500\n",
      "Step #100, epoch #100, avg. train loss: 2825678.75000\n",
      "Step #200, epoch #200, avg. train loss: 1517653.00000\n",
      "Step #100, epoch #100, avg. train loss: 2914512.25000\n",
      "Step #200, epoch #200, avg. train loss: 1576257.75000\n",
      "Step #100, epoch #100, avg. train loss: 2958729.25000\n",
      "Step #200, epoch #200, avg. train loss: 1574134.50000\n",
      "Step #100, epoch #100, avg. train loss: 2906724.75000\n",
      "Step #200, epoch #200, avg. train loss: 1520304.50000\n",
      "Step #100, epoch #20, avg. train loss: 2179443.25000\n",
      "Step #200, epoch #40, avg. train loss: 1527319.25000\n",
      "Step #100, epoch #20, avg. train loss: 2082480.75000\n",
      "Step #200, epoch #40, avg. train loss: 1494890.50000\n",
      "Step #100, epoch #20, avg. train loss: 2169096.75000\n",
      "Step #200, epoch #40, avg. train loss: 1581933.12500\n",
      "Step #100, epoch #100, avg. train loss: 2085072.50000\n",
      "Step #200, epoch #200, avg. train loss: 1620156.50000\n",
      "Step #100, epoch #100, avg. train loss: 2004156.00000\n",
      "Step #200, epoch #200, avg. train loss: 1535952.12500\n",
      "Step #100, epoch #100, avg. train loss: 2097793.50000\n",
      "Step #200, epoch #200, avg. train loss: 1619359.00000\n",
      "Step #100, epoch #14, avg. train loss: 2663252.25000\n",
      "Step #200, epoch #28, avg. train loss: 1802373.87500\n",
      "Step #100, epoch #14, avg. train loss: 2610404.75000\n",
      "Step #200, epoch #28, avg. train loss: 1702317.00000\n",
      "Step #100, epoch #14, avg. train loss: 2648862.25000\n",
      "Step #200, epoch #28, avg. train loss: 1823997.12500\n",
      "Step #100, epoch #11, avg. train loss: 3379761.50000\n",
      "Step #200, epoch #22, avg. train loss: 1592345.50000\n",
      "Step #100, epoch #11, avg. train loss: 3487321.00000\n",
      "Step #200, epoch #22, avg. train loss: 1464954.75000\n",
      "Step #100, epoch #11, avg. train loss: 3297300.25000\n",
      "Step #200, epoch #22, avg. train loss: 1689780.62500\n",
      "Step #100, epoch #100, avg. train loss: 2901391.75000\n",
      "Step #200, epoch #200, avg. train loss: 1518635.50000\n",
      "Step #100, epoch #100, avg. train loss: 2808427.25000\n",
      "Step #200, epoch #200, avg. train loss: 1591881.75000\n",
      "Step #100, epoch #100, avg. train loss: 2798250.25000\n",
      "Step #200, epoch #200, avg. train loss: 1589594.12500\n",
      "Step #100, epoch #100, avg. train loss: 9244666.00000\n",
      "Step #200, epoch #200, avg. train loss: 5813792.00000\n",
      "Step #100, epoch #100, avg. train loss: 9495366.00000\n",
      "Step #200, epoch #200, avg. train loss: 5745442.00000\n",
      "Step #100, epoch #100, avg. train loss: 8975621.00000\n",
      "Step #200, epoch #200, avg. train loss: 5431677.00000\n",
      "Step #100, epoch #100, avg. train loss: 2891851.50000\n",
      "Step #200, epoch #200, avg. train loss: 1537357.75000\n",
      "Step #100, epoch #100, avg. train loss: 2845622.50000\n",
      "Step #200, epoch #200, avg. train loss: 1478577.75000\n",
      "Step #100, epoch #100, avg. train loss: 2751519.25000\n",
      "Step #200, epoch #200, avg. train loss: 1520911.00000\n",
      "Step #100, epoch #100, avg. train loss: 2241294.75000\n",
      "Step #200, epoch #200, avg. train loss: 1693475.37500\n",
      "Step #100, epoch #100, avg. train loss: 2173879.25000\n",
      "Step #200, epoch #200, avg. train loss: 1615917.62500\n",
      "Step #100, epoch #100, avg. train loss: 2249506.75000\n",
      "Step #200, epoch #200, avg. train loss: 1714100.37500\n",
      "Step #100, epoch #50, avg. train loss: 3051673.50000\n",
      "Step #200, epoch #100, avg. train loss: 1711288.75000\n",
      "Step #100, epoch #50, avg. train loss: 3197346.50000\n",
      "Step #200, epoch #100, avg. train loss: 1534151.00000\n",
      "Step #100, epoch #50, avg. train loss: 3132722.00000\n",
      "Step #200, epoch #100, avg. train loss: 1476549.12500\n",
      "Step #100, epoch #50, avg. train loss: 2650188.25000\n",
      "Step #200, epoch #100, avg. train loss: 1523474.12500\n",
      "Step #100, epoch #50, avg. train loss: 2555215.00000\n",
      "Step #200, epoch #100, avg. train loss: 1500111.37500\n",
      "Step #100, epoch #50, avg. train loss: 2692046.50000\n",
      "Step #200, epoch #100, avg. train loss: 1532207.50000\n",
      "Step #100, epoch #50, avg. train loss: 2595897.50000\n",
      "Step #200, epoch #100, avg. train loss: 1541997.75000\n",
      "Step #100, epoch #50, avg. train loss: 2466300.25000\n",
      "Step #200, epoch #100, avg. train loss: 1527477.62500\n",
      "Step #100, epoch #50, avg. train loss: 2632485.50000\n",
      "Step #200, epoch #100, avg. train loss: 1503534.75000\n",
      "Step #100, epoch #100, avg. train loss: 2291621.50000\n",
      "Step #200, epoch #200, avg. train loss: 1546094.87500\n",
      "Step #100, epoch #100, avg. train loss: 2241245.50000\n",
      "Step #200, epoch #200, avg. train loss: 1515885.12500\n",
      "Step #100, epoch #100, avg. train loss: 2283438.00000\n",
      "Step #200, epoch #200, avg. train loss: 1524147.62500\n",
      "Step #100, epoch #100, avg. train loss: 2835148.75000\n",
      "Step #200, epoch #200, avg. train loss: 1542565.62500\n",
      "Step #100, epoch #100, avg. train loss: 2749315.25000\n",
      "Step #200, epoch #200, avg. train loss: 1475074.87500\n",
      "Step #100, epoch #100, avg. train loss: 2785101.75000\n",
      "Step #200, epoch #200, avg. train loss: 1534053.50000\n",
      "Step #100, epoch #16, avg. train loss: 3068504.25000\n",
      "Step #200, epoch #33, avg. train loss: 1491954.25000\n",
      "Step #100, epoch #16, avg. train loss: 3006975.75000\n",
      "Step #200, epoch #33, avg. train loss: 1560184.75000\n",
      "Step #100, epoch #16, avg. train loss: 3250640.25000\n",
      "Step #200, epoch #33, avg. train loss: 1582781.00000\n",
      "Step #100, epoch #100, avg. train loss: 2221925.00000\n",
      "Step #200, epoch #200, avg. train loss: 1550134.87500\n",
      "Step #100, epoch #100, avg. train loss: 2138936.25000\n",
      "Step #200, epoch #200, avg. train loss: 1461015.25000\n",
      "Step #100, epoch #100, avg. train loss: 2211655.00000\n",
      "Step #200, epoch #200, avg. train loss: 1468425.75000\n",
      "Step #100, epoch #50, avg. train loss: 2175611.50000\n",
      "Step #200, epoch #100, avg. train loss: 1616809.62500\n",
      "Step #100, epoch #50, avg. train loss: 2089646.37500\n",
      "Step #200, epoch #100, avg. train loss: 1554480.50000\n",
      "Step #100, epoch #50, avg. train loss: 2202873.75000\n",
      "Step #200, epoch #100, avg. train loss: 1573565.50000\n",
      "Step #100, epoch #100, avg. train loss: 2791100.50000\n",
      "Step #200, epoch #200, avg. train loss: 1585662.50000\n",
      "Step #100, epoch #100, avg. train loss: 2787063.00000\n",
      "Step #200, epoch #200, avg. train loss: 1561442.37500\n",
      "Step #100, epoch #100, avg. train loss: 2740289.25000\n",
      "Step #200, epoch #200, avg. train loss: 1457282.37500\n",
      "Step #100, epoch #16, avg. train loss: 2228199.00000\n",
      "Step #200, epoch #33, avg. train loss: 1586319.37500\n",
      "Step #100, epoch #16, avg. train loss: 2099580.25000\n",
      "Step #200, epoch #33, avg. train loss: 1448625.50000\n",
      "Step #100, epoch #16, avg. train loss: 2244643.50000\n",
      "Step #200, epoch #33, avg. train loss: 1650398.37500\n",
      "Step #100, epoch #50, avg. train loss: 2298205.25000\n",
      "Step #200, epoch #100, avg. train loss: 1709081.25000\n",
      "Step #100, epoch #50, avg. train loss: 2238952.75000\n",
      "Step #200, epoch #100, avg. train loss: 1618206.25000\n",
      "Step #100, epoch #50, avg. train loss: 2316738.25000\n",
      "Step #200, epoch #100, avg. train loss: 1703375.37500\n",
      "Step #100, epoch #50, avg. train loss: 2116507.25000\n",
      "Step #200, epoch #100, avg. train loss: 1621389.87500\n",
      "Step #100, epoch #50, avg. train loss: 2033419.62500\n",
      "Step #200, epoch #100, avg. train loss: 1539270.25000\n",
      "Step #100, epoch #50, avg. train loss: 2142791.00000\n",
      "Step #200, epoch #100, avg. train loss: 1592418.50000\n",
      "Step #100, epoch #33, avg. train loss: 2473707.00000\n",
      "Step #200, epoch #66, avg. train loss: 1571678.87500\n",
      "Step #100, epoch #33, avg. train loss: 2355487.00000\n",
      "Step #200, epoch #66, avg. train loss: 1510994.12500\n",
      "Step #100, epoch #33, avg. train loss: 2463198.25000\n",
      "Step #200, epoch #66, avg. train loss: 1528436.62500\n",
      "Step #100, epoch #100, avg. train loss: 2054462.37500\n",
      "Step #200, epoch #200, avg. train loss: 1551486.12500\n",
      "Step #100, epoch #100, avg. train loss: 1987847.00000\n",
      "Step #200, epoch #200, avg. train loss: 1483055.25000\n",
      "Step #100, epoch #100, avg. train loss: 2064923.62500\n",
      "Step #200, epoch #200, avg. train loss: 1529639.00000\n",
      "Step #100, epoch #50, avg. train loss: 2238006.25000\n",
      "Step #200, epoch #100, avg. train loss: 1547229.62500\n",
      "Step #100, epoch #50, avg. train loss: 2195465.00000\n",
      "Step #200, epoch #100, avg. train loss: 1536037.50000\n",
      "Step #100, epoch #50, avg. train loss: 2250105.00000\n",
      "Step #200, epoch #100, avg. train loss: 1656287.87500\n",
      "Step #100, epoch #50, avg. train loss: 2212232.50000\n",
      "Step #200, epoch #100, avg. train loss: 1759104.75000\n",
      "Step #100, epoch #50, avg. train loss: 2133186.50000\n",
      "Step #200, epoch #100, avg. train loss: 1633304.50000\n",
      "Step #100, epoch #50, avg. train loss: 2218127.75000\n",
      "Step #200, epoch #100, avg. train loss: 1736598.87500\n",
      "Step #100, epoch #100, avg. train loss: 2306317.75000\n",
      "Step #200, epoch #200, avg. train loss: 1590846.12500\n",
      "Step #100, epoch #100, avg. train loss: 2247648.25000\n",
      "Step #200, epoch #200, avg. train loss: 1541386.87500\n",
      "Step #100, epoch #100, avg. train loss: 2299433.00000\n",
      "Step #200, epoch #200, avg. train loss: 1565796.37500\n",
      "Step #100, epoch #100, avg. train loss: 2149216.75000\n",
      "Step #200, epoch #200, avg. train loss: 1580768.12500\n",
      "Step #100, epoch #100, avg. train loss: 2064039.87500\n",
      "Step #200, epoch #200, avg. train loss: 1495666.87500\n",
      "Step #100, epoch #100, avg. train loss: 2160713.00000\n",
      "Step #200, epoch #200, avg. train loss: 1610774.75000\n",
      "Step #100, epoch #16, avg. train loss: 3085054.50000\n",
      "Step #200, epoch #33, avg. train loss: 1616505.25000\n",
      "Step #100, epoch #16, avg. train loss: 2995182.00000\n",
      "Step #200, epoch #33, avg. train loss: 1576499.25000\n",
      "Step #100, epoch #16, avg. train loss: 3085478.00000\n",
      "Step #200, epoch #33, avg. train loss: 1544004.75000\n",
      "Step #100, epoch #100, avg. train loss: 2718468.75000\n",
      "Step #200, epoch #200, avg. train loss: 1746365.87500\n",
      "Step #100, epoch #100, avg. train loss: 2682365.75000\n",
      "Step #200, epoch #200, avg. train loss: 1660595.25000\n",
      "Step #100, epoch #100, avg. train loss: 2697753.50000\n",
      "Step #200, epoch #200, avg. train loss: 1766617.62500\n",
      "Step #100, epoch #50, avg. train loss: 4959176.50000\n",
      "Step #200, epoch #100, avg. train loss: 1797802.50000\n",
      "Step #100, epoch #50, avg. train loss: 5051244.00000\n",
      "Step #200, epoch #100, avg. train loss: 1715901.12500\n",
      "Step #100, epoch #50, avg. train loss: 4841877.00000\n",
      "Step #200, epoch #100, avg. train loss: 1821805.87500\n",
      "Step #100, epoch #12, avg. train loss: 2222197.00000\n",
      "Step #200, epoch #25, avg. train loss: 1771135.62500\n",
      "Step #100, epoch #12, avg. train loss: 2145693.50000\n",
      "Step #200, epoch #25, avg. train loss: 1654238.12500\n",
      "Step #100, epoch #12, avg. train loss: 2221093.25000\n",
      "Step #200, epoch #25, avg. train loss: 1786906.37500\n",
      "Step #100, epoch #100, avg. train loss: 2512490.50000\n",
      "Step #200, epoch #200, avg. train loss: 1671465.12500\n",
      "Step #100, epoch #100, avg. train loss: 2584520.00000\n",
      "Step #200, epoch #200, avg. train loss: 1651038.75000\n",
      "Step #100, epoch #100, avg. train loss: 2411097.00000\n",
      "Step #200, epoch #200, avg. train loss: 1597197.50000\n",
      "Step #100, epoch #16, avg. train loss: 3101426.00000\n",
      "Step #200, epoch #33, avg. train loss: 1561636.00000\n",
      "Step #100, epoch #16, avg. train loss: 2933553.25000\n",
      "Step #200, epoch #33, avg. train loss: 1496597.75000\n",
      "Step #100, epoch #16, avg. train loss: 2927400.25000\n",
      "Step #200, epoch #33, avg. train loss: 1646348.12500\n",
      "Step #100, epoch #100, avg. train loss: 3013208.75000\n",
      "Step #200, epoch #200, avg. train loss: 1597762.50000\n",
      "Step #100, epoch #100, avg. train loss: 3087595.50000\n",
      "Step #200, epoch #200, avg. train loss: 1541731.62500\n",
      "Step #100, epoch #100, avg. train loss: 3046320.25000\n",
      "Step #200, epoch #200, avg. train loss: 1662917.87500\n",
      "Step #100, epoch #50, avg. train loss: 2130788.25000\n",
      "Step #200, epoch #100, avg. train loss: 1632548.12500\n",
      "Step #100, epoch #50, avg. train loss: 2046793.87500\n",
      "Step #200, epoch #100, avg. train loss: 1540155.00000\n",
      "Step #100, epoch #50, avg. train loss: 2174051.75000\n",
      "Step #200, epoch #100, avg. train loss: 1639106.37500\n",
      "Step #100, epoch #50, avg. train loss: 4398579.50000\n",
      "Step #200, epoch #100, avg. train loss: 1811250.25000\n",
      "Step #100, epoch #50, avg. train loss: 4491974.00000\n",
      "Step #200, epoch #100, avg. train loss: 1730491.37500\n",
      "Step #100, epoch #50, avg. train loss: 4308926.00000\n",
      "Step #200, epoch #100, avg. train loss: 1824224.37500\n",
      "Step #100, epoch #100, avg. train loss: 3276576.00000\n",
      "Step #200, epoch #200, avg. train loss: 1557172.50000\n",
      "Step #100, epoch #100, avg. train loss: 3181480.75000\n",
      "Step #200, epoch #200, avg. train loss: 1550818.87500\n",
      "Step #100, epoch #100, avg. train loss: 3182280.75000\n",
      "Step #200, epoch #200, avg. train loss: 1531153.87500\n",
      "Step #100, epoch #50, avg. train loss: 2900249.00000\n",
      "Step #200, epoch #100, avg. train loss: 1751527.50000\n",
      "Step #100, epoch #50, avg. train loss: 2892250.00000\n",
      "Step #200, epoch #100, avg. train loss: 1673666.75000\n",
      "Step #100, epoch #50, avg. train loss: 2854160.00000\n",
      "Step #200, epoch #100, avg. train loss: 1796859.62500\n",
      "Step #100, epoch #100, avg. train loss: 2130042.75000\n",
      "Step #200, epoch #200, avg. train loss: 1580502.37500\n",
      "Step #100, epoch #100, avg. train loss: 2052953.62500\n",
      "Step #200, epoch #200, avg. train loss: 1475098.25000\n",
      "Step #100, epoch #100, avg. train loss: 2139913.00000\n",
      "Step #200, epoch #200, avg. train loss: 1531393.12500\n",
      "Step #100, epoch #100, avg. train loss: 2509122.50000\n",
      "Step #200, epoch #200, avg. train loss: 1663056.37500\n",
      "Step #100, epoch #100, avg. train loss: 2519650.75000\n",
      "Step #200, epoch #200, avg. train loss: 1642188.62500\n",
      "Step #100, epoch #100, avg. train loss: 2385456.75000\n",
      "Step #200, epoch #200, avg. train loss: 1537468.75000\n",
      "Step #100, epoch #100, avg. train loss: 2135420.75000\n",
      "Step #200, epoch #200, avg. train loss: 1545876.12500\n",
      "Step #100, epoch #100, avg. train loss: 2077563.87500\n",
      "Step #200, epoch #200, avg. train loss: 1552543.87500\n",
      "Step #100, epoch #100, avg. train loss: 2140456.75000\n",
      "Step #200, epoch #200, avg. train loss: 1542283.37500\n",
      "Step #100, epoch #100, avg. train loss: 2928322.25000\n",
      "Step #200, epoch #200, avg. train loss: 1624079.37500\n",
      "Step #100, epoch #100, avg. train loss: 2760290.25000\n",
      "Step #200, epoch #200, avg. train loss: 1490785.00000\n",
      "Step #100, epoch #100, avg. train loss: 2786997.75000\n",
      "Step #200, epoch #200, avg. train loss: 1536012.50000\n",
      "Step #100, epoch #100, avg. train loss: 2096509.75000\n",
      "Step #200, epoch #200, avg. train loss: 1597336.12500\n",
      "Step #100, epoch #100, avg. train loss: 2017671.62500\n",
      "Step #200, epoch #200, avg. train loss: 1611856.37500\n",
      "Step #100, epoch #100, avg. train loss: 2101877.25000\n",
      "Step #200, epoch #200, avg. train loss: 1646322.25000\n",
      "Step #100, epoch #50, avg. train loss: 2397695.75000\n",
      "Step #200, epoch #100, avg. train loss: 1554298.12500\n",
      "Step #100, epoch #50, avg. train loss: 2319520.25000\n",
      "Step #200, epoch #100, avg. train loss: 1507328.37500\n",
      "Step #100, epoch #50, avg. train loss: 2390797.25000\n",
      "Step #200, epoch #100, avg. train loss: 1567309.62500\n",
      "Step #100, epoch #25, avg. train loss: 2680423.75000\n",
      "Step #200, epoch #50, avg. train loss: 1572460.62500\n",
      "Step #100, epoch #25, avg. train loss: 2690130.25000\n",
      "Step #200, epoch #50, avg. train loss: 1472309.87500\n",
      "Step #100, epoch #25, avg. train loss: 2782836.50000\n",
      "Step #200, epoch #50, avg. train loss: 1536726.12500\n",
      "Step #100, epoch #50, avg. train loss: 2339450.25000\n",
      "Step #200, epoch #100, avg. train loss: 1496841.87500\n",
      "Step #100, epoch #50, avg. train loss: 2269449.25000\n",
      "Step #200, epoch #100, avg. train loss: 1468637.87500\n",
      "Step #100, epoch #50, avg. train loss: 2400267.00000\n",
      "Step #200, epoch #100, avg. train loss: 1520821.12500\n",
      "Step #100, epoch #25, avg. train loss: 2265937.00000\n",
      "Step #200, epoch #50, avg. train loss: 1681593.25000\n",
      "Step #100, epoch #25, avg. train loss: 2186185.25000\n",
      "Step #200, epoch #50, avg. train loss: 1649496.50000\n",
      "Step #100, epoch #25, avg. train loss: 2246091.00000\n",
      "Step #200, epoch #50, avg. train loss: 1666779.25000\n",
      "Step #100, epoch #50, avg. train loss: 2993994.50000\n",
      "Step #200, epoch #100, avg. train loss: 1472318.75000\n",
      "Step #100, epoch #50, avg. train loss: 2878908.50000\n",
      "Step #200, epoch #100, avg. train loss: 1454633.25000\n",
      "Step #100, epoch #50, avg. train loss: 3021691.50000\n",
      "Step #200, epoch #100, avg. train loss: 1448300.12500\n",
      "Step #100, epoch #12, avg. train loss: 2489311.00000\n",
      "Step #200, epoch #25, avg. train loss: 1794762.50000\n",
      "Step #100, epoch #12, avg. train loss: 2456251.00000\n",
      "Step #200, epoch #25, avg. train loss: 1725814.25000\n",
      "Step #100, epoch #12, avg. train loss: 2491609.50000\n",
      "Step #200, epoch #25, avg. train loss: 1853760.50000\n",
      "Step #100, epoch #100, avg. train loss: 2892066.50000\n",
      "Step #200, epoch #200, avg. train loss: 1516972.00000\n",
      "Step #100, epoch #100, avg. train loss: 2831895.25000\n",
      "Step #200, epoch #200, avg. train loss: 1525562.37500\n",
      "Step #100, epoch #100, avg. train loss: 2876754.25000\n",
      "Step #200, epoch #200, avg. train loss: 1568849.00000\n",
      "Step #100, epoch #16, avg. train loss: 2314721.50000\n",
      "Step #200, epoch #33, avg. train loss: 1579759.25000\n",
      "Step #100, epoch #16, avg. train loss: 2269527.75000\n",
      "Step #200, epoch #33, avg. train loss: 1528755.50000\n",
      "Step #100, epoch #16, avg. train loss: 2268828.25000\n",
      "Step #200, epoch #33, avg. train loss: 1535662.25000\n",
      "Step #100, epoch #33, avg. train loss: 2297909.00000\n",
      "Step #200, epoch #66, avg. train loss: 1524975.25000\n",
      "Step #100, epoch #33, avg. train loss: 2223094.75000\n",
      "Step #200, epoch #66, avg. train loss: 1522028.75000\n",
      "Step #100, epoch #33, avg. train loss: 2279292.25000\n",
      "Step #200, epoch #66, avg. train loss: 1534229.62500\n",
      "Step #100, epoch #100, avg. train loss: 2833053.00000\n",
      "Step #200, epoch #200, avg. train loss: 1535570.12500\n",
      "Step #100, epoch #100, avg. train loss: 2858621.00000\n",
      "Step #200, epoch #200, avg. train loss: 1482445.75000\n",
      "Step #100, epoch #100, avg. train loss: 2814408.00000\n",
      "Step #200, epoch #200, avg. train loss: 1535234.12500\n",
      "Step #100, epoch #50, avg. train loss: 2202412.00000\n",
      "Step #200, epoch #100, avg. train loss: 1661282.75000\n",
      "Step #100, epoch #50, avg. train loss: 2184831.00000\n",
      "Step #200, epoch #100, avg. train loss: 1646011.00000\n",
      "Step #100, epoch #50, avg. train loss: 2201310.00000\n",
      "Step #200, epoch #100, avg. train loss: 1717142.37500\n",
      "Step #100, epoch #100, avg. train loss: 2696460.25000\n",
      "Step #200, epoch #200, avg. train loss: 1656488.00000\n",
      "Step #100, epoch #100, avg. train loss: 2578622.50000\n",
      "Step #200, epoch #200, avg. train loss: 1511534.12500\n",
      "Step #100, epoch #100, avg. train loss: 2632851.25000\n",
      "Step #200, epoch #200, avg. train loss: 1536514.75000\n",
      "Step #100, epoch #100, avg. train loss: 2419957.00000\n",
      "Step #200, epoch #200, avg. train loss: 1575593.12500\n",
      "Step #100, epoch #100, avg. train loss: 2323510.00000\n",
      "Step #200, epoch #200, avg. train loss: 1541423.50000\n",
      "Step #100, epoch #100, avg. train loss: 2440269.00000\n",
      "Step #200, epoch #200, avg. train loss: 1554069.00000\n",
      "Step #100, epoch #100, avg. train loss: 2218191.75000\n",
      "Step #200, epoch #200, avg. train loss: 1525272.75000\n",
      "Step #100, epoch #100, avg. train loss: 2138728.75000\n",
      "Step #200, epoch #200, avg. train loss: 1512622.25000\n",
      "Step #100, epoch #100, avg. train loss: 2241186.50000\n",
      "Step #200, epoch #200, avg. train loss: 1496301.75000\n",
      "Step #100, epoch #100, avg. train loss: 2274753.00000\n",
      "Step #200, epoch #200, avg. train loss: 1660309.75000\n",
      "Step #100, epoch #100, avg. train loss: 2212930.50000\n",
      "Step #200, epoch #200, avg. train loss: 1602597.25000\n",
      "Step #100, epoch #100, avg. train loss: 2273522.50000\n",
      "Step #200, epoch #200, avg. train loss: 1696980.75000\n",
      "Step #100, epoch #100, avg. train loss: 3610570.25000\n",
      "Step #200, epoch #200, avg. train loss: 1660688.37500\n",
      "Step #100, epoch #100, avg. train loss: 3535058.50000\n",
      "Step #200, epoch #200, avg. train loss: 1511715.25000\n",
      "Step #100, epoch #100, avg. train loss: 3662594.50000\n",
      "Step #200, epoch #200, avg. train loss: 1580360.62500\n",
      "Step #100, epoch #100, avg. train loss: 2111408.25000\n",
      "Step #200, epoch #200, avg. train loss: 1473029.75000\n",
      "Step #100, epoch #100, avg. train loss: 2044501.75000\n",
      "Step #200, epoch #200, avg. train loss: 1432208.00000\n",
      "Step #100, epoch #100, avg. train loss: 2125705.75000\n",
      "Step #200, epoch #200, avg. train loss: 1570006.37500\n",
      "Step #100, epoch #100, avg. train loss: 2818763.00000\n",
      "Step #200, epoch #200, avg. train loss: 1511659.37500\n",
      "Step #100, epoch #100, avg. train loss: 2808585.00000\n",
      "Step #200, epoch #200, avg. train loss: 1489924.62500\n",
      "Step #100, epoch #100, avg. train loss: 2839598.00000\n",
      "Step #200, epoch #200, avg. train loss: 1501886.25000\n",
      "Step #100, epoch #50, avg. train loss: 2973101.50000\n",
      "Step #200, epoch #100, avg. train loss: 1511009.25000\n",
      "Step #100, epoch #50, avg. train loss: 2925193.00000\n",
      "Step #200, epoch #100, avg. train loss: 1521307.37500\n",
      "Step #100, epoch #50, avg. train loss: 3073848.75000\n",
      "Step #200, epoch #100, avg. train loss: 1515350.75000\n",
      "Step #100, epoch #100, avg. train loss: 2261703.75000\n",
      "Step #200, epoch #200, avg. train loss: 1571337.12500\n",
      "Step #100, epoch #100, avg. train loss: 2201174.00000\n",
      "Step #200, epoch #200, avg. train loss: 1529584.75000\n",
      "Step #100, epoch #100, avg. train loss: 2253796.25000\n",
      "Step #200, epoch #200, avg. train loss: 1530748.50000\n",
      "Step #100, epoch #100, avg. train loss: 2211383.25000\n",
      "Step #200, epoch #200, avg. train loss: 1505159.87500\n",
      "Step #100, epoch #100, avg. train loss: 2166422.25000\n",
      "Step #200, epoch #200, avg. train loss: 1537642.75000\n",
      "Step #100, epoch #100, avg. train loss: 2220670.75000\n",
      "Step #200, epoch #200, avg. train loss: 1504148.12500\n",
      "Step #100, epoch #100, avg. train loss: 3523610.50000\n",
      "Step #200, epoch #200, avg. train loss: 1648281.12500\n",
      "Step #100, epoch #100, avg. train loss: 3621963.75000\n",
      "Step #200, epoch #200, avg. train loss: 1447386.25000\n",
      "Step #100, epoch #100, avg. train loss: 3484498.50000\n",
      "Step #200, epoch #200, avg. train loss: 1509967.50000\n",
      "Step #100, epoch #33, avg. train loss: 2971555.50000\n",
      "Step #200, epoch #66, avg. train loss: 1808159.37500\n",
      "Step #100, epoch #33, avg. train loss: 2984709.75000\n",
      "Step #200, epoch #66, avg. train loss: 1690248.12500\n",
      "Step #100, epoch #33, avg. train loss: 2914436.50000\n",
      "Step #200, epoch #66, avg. train loss: 1800292.50000\n",
      "Step #100, epoch #100, avg. train loss: 2587584.50000\n",
      "Step #200, epoch #200, avg. train loss: 1633824.62500\n",
      "Step #100, epoch #100, avg. train loss: 2944734.75000\n",
      "Step #200, epoch #200, avg. train loss: 1657293.00000\n",
      "Step #100, epoch #100, avg. train loss: 2503422.00000\n",
      "Step #200, epoch #200, avg. train loss: 1596123.50000\n",
      "Step #100, epoch #14, avg. train loss: 4005785.00000\n",
      "Step #200, epoch #28, avg. train loss: 1453639.62500\n",
      "Step #100, epoch #14, avg. train loss: 3625823.75000\n",
      "Step #200, epoch #28, avg. train loss: 1490479.87500\n",
      "Step #100, epoch #14, avg. train loss: 3888960.25000\n",
      "Step #200, epoch #28, avg. train loss: 1658333.87500\n",
      "Step #100, epoch #100, avg. train loss: 2156872.00000\n",
      "Step #200, epoch #200, avg. train loss: 1533679.62500\n",
      "Step #100, epoch #100, avg. train loss: 2082453.00000\n",
      "Step #200, epoch #200, avg. train loss: 1435176.75000\n",
      "Step #100, epoch #100, avg. train loss: 2158964.75000\n",
      "Step #200, epoch #200, avg. train loss: 1513101.50000\n",
      "Step #100, epoch #5, avg. train loss: 2618329.25000\n",
      "Step #200, epoch #11, avg. train loss: 1770877.00000\n",
      "Step #100, epoch #5, avg. train loss: 2496939.50000\n",
      "Step #200, epoch #11, avg. train loss: 1589882.12500\n",
      "Step #100, epoch #5, avg. train loss: 2609072.75000\n",
      "Step #200, epoch #11, avg. train loss: 1635120.00000\n",
      "Step #100, epoch #100, avg. train loss: 2283311.25000\n",
      "Step #200, epoch #200, avg. train loss: 1658392.75000\n",
      "Step #100, epoch #100, avg. train loss: 2220135.25000\n",
      "Step #200, epoch #200, avg. train loss: 1603604.75000\n",
      "Step #100, epoch #100, avg. train loss: 2286090.50000\n",
      "Step #200, epoch #200, avg. train loss: 1699061.75000\n",
      "Step #100, epoch #25, avg. train loss: 2163795.25000\n",
      "Step #200, epoch #50, avg. train loss: 1613936.00000\n",
      "Step #100, epoch #25, avg. train loss: 2098673.75000\n",
      "Step #200, epoch #50, avg. train loss: 1652322.50000\n",
      "Step #100, epoch #25, avg. train loss: 2207386.00000\n",
      "Step #200, epoch #50, avg. train loss: 1614902.75000\n",
      "Step #100, epoch #100, avg. train loss: 2140551.25000\n",
      "Step #200, epoch #200, avg. train loss: 1479386.50000\n",
      "Step #100, epoch #100, avg. train loss: 2070156.37500\n",
      "Step #200, epoch #200, avg. train loss: 1501138.25000\n",
      "Step #100, epoch #100, avg. train loss: 2160576.75000\n",
      "Step #200, epoch #200, avg. train loss: 1588553.00000\n",
      "Step #100, epoch #50, avg. train loss: 2150187.25000\n",
      "Step #200, epoch #100, avg. train loss: 1638269.50000\n",
      "Step #100, epoch #50, avg. train loss: 2103826.00000\n",
      "Step #200, epoch #100, avg. train loss: 1512711.87500\n",
      "Step #100, epoch #50, avg. train loss: 2152503.25000\n",
      "Step #200, epoch #100, avg. train loss: 1636638.87500\n",
      "Step #100, epoch #11, avg. train loss: 3142690.50000\n",
      "Step #200, epoch #22, avg. train loss: 1634510.37500\n",
      "Step #100, epoch #11, avg. train loss: 3126596.75000\n",
      "Step #200, epoch #22, avg. train loss: 1490312.62500\n",
      "Step #100, epoch #11, avg. train loss: 3224712.00000\n",
      "Step #200, epoch #22, avg. train loss: 1563462.37500\n",
      "Step #100, epoch #7, avg. train loss: 2315319.25000\n",
      "Step #200, epoch #15, avg. train loss: 1614237.25000\n",
      "Step #100, epoch #7, avg. train loss: 2239454.50000\n",
      "Step #200, epoch #15, avg. train loss: 1632789.50000\n",
      "Step #100, epoch #7, avg. train loss: 2359879.50000\n",
      "Step #200, epoch #15, avg. train loss: 1746494.75000\n",
      "Step #100, epoch #100, avg. train loss: 2527291.50000\n",
      "Step #200, epoch #200, avg. train loss: 1672940.37500\n",
      "Step #100, epoch #100, avg. train loss: 2547484.50000\n",
      "Step #200, epoch #200, avg. train loss: 1645677.62500\n",
      "Step #100, epoch #100, avg. train loss: 2399438.75000\n",
      "Step #200, epoch #200, avg. train loss: 1553222.75000\n",
      "Step #100, epoch #33, avg. train loss: 2852116.25000\n",
      "Step #200, epoch #66, avg. train loss: 1495366.37500\n",
      "Step #100, epoch #33, avg. train loss: 2844068.75000\n",
      "Step #200, epoch #66, avg. train loss: 1479313.50000\n",
      "Step #100, epoch #33, avg. train loss: 2979408.00000\n",
      "Step #200, epoch #66, avg. train loss: 1469176.62500\n",
      "Step #100, epoch #100, avg. train loss: 2052799.25000\n",
      "Step #200, epoch #200, avg. train loss: 1562490.50000\n",
      "Step #100, epoch #100, avg. train loss: 1987964.62500\n",
      "Step #200, epoch #200, avg. train loss: 1515634.87500\n",
      "Step #100, epoch #100, avg. train loss: 2067834.87500\n",
      "Step #200, epoch #200, avg. train loss: 1544262.75000\n",
      "Step #100, epoch #100, avg. train loss: 2187219.75000\n",
      "Step #200, epoch #200, avg. train loss: 1547311.00000\n",
      "Step #100, epoch #100, avg. train loss: 2111863.00000\n",
      "Step #200, epoch #200, avg. train loss: 1509155.25000\n",
      "Step #100, epoch #100, avg. train loss: 2195056.50000\n",
      "Step #200, epoch #200, avg. train loss: 1535222.50000\n",
      "Step #100, epoch #50, avg. train loss: 2198379.00000\n",
      "Step #200, epoch #100, avg. train loss: 1663731.25000\n",
      "Step #100, epoch #50, avg. train loss: 2142186.50000\n",
      "Step #200, epoch #100, avg. train loss: 1519442.12500\n",
      "Step #100, epoch #50, avg. train loss: 2232654.50000\n",
      "Step #200, epoch #100, avg. train loss: 1631332.12500\n",
      "Step #100, epoch #12, avg. train loss: 2871958.50000\n",
      "Step #200, epoch #25, avg. train loss: 1601647.25000\n",
      "Step #100, epoch #12, avg. train loss: 2487296.75000\n",
      "Step #200, epoch #25, avg. train loss: 1630375.50000\n",
      "Step #100, epoch #12, avg. train loss: 2527504.75000\n",
      "Step #200, epoch #25, avg. train loss: 1701512.62500\n",
      "Step #100, epoch #100, avg. train loss: 2370540.75000\n",
      "Step #200, epoch #200, avg. train loss: 1598091.25000\n",
      "Step #100, epoch #100, avg. train loss: 2283949.50000\n",
      "Step #200, epoch #200, avg. train loss: 1551681.87500\n",
      "Step #100, epoch #100, avg. train loss: 2387036.25000\n",
      "Step #200, epoch #200, avg. train loss: 1587635.25000\n",
      "Step #100, epoch #25, avg. train loss: 2740854.00000\n",
      "Step #200, epoch #50, avg. train loss: 1644929.75000\n",
      "Step #100, epoch #25, avg. train loss: 3043141.50000\n",
      "Step #200, epoch #50, avg. train loss: 1509012.50000\n",
      "Step #100, epoch #25, avg. train loss: 2926983.25000\n",
      "Step #200, epoch #50, avg. train loss: 1543062.37500\n",
      "Step #100, epoch #100, avg. train loss: 2138228.75000\n",
      "Step #200, epoch #200, avg. train loss: 1616823.87500\n",
      "Step #100, epoch #100, avg. train loss: 2066852.37500\n",
      "Step #200, epoch #200, avg. train loss: 1540348.12500\n",
      "Step #100, epoch #100, avg. train loss: 2141914.75000\n",
      "Step #200, epoch #200, avg. train loss: 1612340.00000\n",
      "Step #100, epoch #100, avg. train loss: 2878587.00000\n",
      "Step #200, epoch #200, avg. train loss: 1620270.50000\n",
      "Step #100, epoch #100, avg. train loss: 2715331.25000\n",
      "Step #200, epoch #200, avg. train loss: 1538638.87500\n",
      "Step #100, epoch #100, avg. train loss: 2856771.25000\n",
      "Step #200, epoch #200, avg. train loss: 1520608.50000\n",
      "Step #100, epoch #7, avg. train loss: 3234720.75000\n",
      "Step #200, epoch #15, avg. train loss: 1587505.75000\n",
      "Step #100, epoch #7, avg. train loss: 2823051.00000\n",
      "Step #200, epoch #15, avg. train loss: 1589357.12500\n",
      "Step #100, epoch #7, avg. train loss: 2853668.75000\n",
      "Step #200, epoch #15, avg. train loss: 1609597.87500\n",
      "Step #100, epoch #50, avg. train loss: 2148302.00000\n",
      "Step #200, epoch #100, avg. train loss: 1588132.12500\n",
      "Step #100, epoch #50, avg. train loss: 2060569.75000\n",
      "Step #200, epoch #100, avg. train loss: 1467317.62500\n",
      "Step #100, epoch #50, avg. train loss: 2145957.50000\n",
      "Step #200, epoch #100, avg. train loss: 1544724.75000\n",
      "Step #100, epoch #100, avg. train loss: 2868936.00000\n",
      "Step #200, epoch #200, avg. train loss: 1601921.50000\n",
      "Step #100, epoch #100, avg. train loss: 2783252.50000\n",
      "Step #200, epoch #200, avg. train loss: 1582649.62500\n",
      "Step #100, epoch #100, avg. train loss: 2876795.50000\n",
      "Step #200, epoch #200, avg. train loss: 1602817.00000\n",
      "Step #100, epoch #33, avg. train loss: 2988201.25000\n",
      "Step #200, epoch #66, avg. train loss: 1561474.25000\n",
      "Step #100, epoch #33, avg. train loss: 2873166.50000\n",
      "Step #200, epoch #66, avg. train loss: 1491694.37500\n",
      "Step #100, epoch #33, avg. train loss: 3021893.50000\n",
      "Step #200, epoch #66, avg. train loss: 1569914.37500\n",
      "Step #100, epoch #50, avg. train loss: 2323887.25000\n",
      "Step #200, epoch #100, avg. train loss: 1662442.75000\n",
      "Step #100, epoch #50, avg. train loss: 2259484.25000\n",
      "Step #200, epoch #100, avg. train loss: 1535064.00000\n",
      "Step #100, epoch #50, avg. train loss: 2392732.25000\n",
      "Step #200, epoch #100, avg. train loss: 1524544.37500\n",
      "Step #100, epoch #100, avg. train loss: 3810459.75000\n",
      "Step #200, epoch #200, avg. train loss: 1486917.12500\n",
      "Step #100, epoch #100, avg. train loss: 3737062.50000\n",
      "Step #200, epoch #200, avg. train loss: 1501454.25000\n",
      "Step #100, epoch #100, avg. train loss: 3815311.00000\n",
      "Step #200, epoch #200, avg. train loss: 1532823.50000\n",
      "Step #100, epoch #50, avg. train loss: 2570927.25000\n",
      "Step #200, epoch #100, avg. train loss: 1573324.00000\n",
      "Step #100, epoch #50, avg. train loss: 2524125.25000\n",
      "Step #200, epoch #100, avg. train loss: 1445796.12500\n",
      "Step #100, epoch #50, avg. train loss: 2595487.75000\n",
      "Step #200, epoch #100, avg. train loss: 1524689.75000\n",
      "Step #100, epoch #100, avg. train loss: 2132995.00000\n",
      "Step #200, epoch #200, avg. train loss: 1523233.62500\n",
      "Step #100, epoch #100, avg. train loss: 2057083.25000\n",
      "Step #200, epoch #200, avg. train loss: 1448989.75000\n",
      "Step #100, epoch #100, avg. train loss: 2100847.25000\n",
      "Step #200, epoch #200, avg. train loss: 1444852.50000\n",
      "Step #100, epoch #100, avg. train loss: 2323175.75000\n",
      "Step #200, epoch #200, avg. train loss: 1452941.87500\n",
      "Step #100, epoch #100, avg. train loss: 2250916.75000\n",
      "Step #200, epoch #200, avg. train loss: 1507520.75000\n",
      "Step #100, epoch #100, avg. train loss: 2348395.75000\n",
      "Step #200, epoch #200, avg. train loss: 1493201.00000\n",
      "Step #100, epoch #50, avg. train loss: 2167924.75000\n",
      "Step #200, epoch #100, avg. train loss: 1531603.37500\n",
      "Step #100, epoch #50, avg. train loss: 2084714.12500\n",
      "Step #200, epoch #100, avg. train loss: 1584650.12500\n",
      "Step #100, epoch #50, avg. train loss: 2164495.50000\n",
      "Step #200, epoch #100, avg. train loss: 1552375.50000\n",
      "Step #100, epoch #50, avg. train loss: 2569333.25000\n",
      "Step #200, epoch #100, avg. train loss: 1554750.12500\n",
      "Step #100, epoch #50, avg. train loss: 2461970.25000\n",
      "Step #200, epoch #100, avg. train loss: 1516114.25000\n",
      "Step #100, epoch #50, avg. train loss: 2555370.50000\n",
      "Step #200, epoch #100, avg. train loss: 1548905.50000\n",
      "Step #100, epoch #33, avg. train loss: 2515989.50000\n",
      "Step #200, epoch #66, avg. train loss: 1607334.75000\n",
      "Step #100, epoch #33, avg. train loss: 2366782.00000\n",
      "Step #200, epoch #66, avg. train loss: 1511711.50000\n",
      "Step #100, epoch #33, avg. train loss: 2443263.75000\n",
      "Step #200, epoch #66, avg. train loss: 1528426.12500\n",
      "Step #100, epoch #100, avg. train loss: 3678796.50000\n",
      "Step #200, epoch #200, avg. train loss: 1743613.12500\n",
      "Step #100, epoch #100, avg. train loss: 3696261.75000\n",
      "Step #200, epoch #200, avg. train loss: 1655841.00000\n",
      "Step #100, epoch #100, avg. train loss: 3633495.00000\n",
      "Step #200, epoch #200, avg. train loss: 1787830.37500\n",
      "Step #100, epoch #100, avg. train loss: 2910077.50000\n",
      "Step #200, epoch #200, avg. train loss: 1531591.62500\n",
      "Step #100, epoch #100, avg. train loss: 2827706.50000\n",
      "Step #200, epoch #200, avg. train loss: 1462679.87500\n",
      "Step #100, epoch #100, avg. train loss: 2869084.50000\n",
      "Step #200, epoch #200, avg. train loss: 1507121.00000\n",
      "Step #100, epoch #50, avg. train loss: 2162553.50000\n",
      "Step #200, epoch #100, avg. train loss: 1593697.75000\n",
      "Step #100, epoch #50, avg. train loss: 2087208.62500\n",
      "Step #200, epoch #100, avg. train loss: 1588855.25000\n",
      "Step #100, epoch #50, avg. train loss: 2166746.00000\n",
      "Step #200, epoch #100, avg. train loss: 1551410.25000\n",
      "Step #100, epoch #50, avg. train loss: 2379588.75000\n",
      "Step #200, epoch #100, avg. train loss: 1523213.50000\n",
      "Step #100, epoch #50, avg. train loss: 2296207.25000\n",
      "Step #200, epoch #100, avg. train loss: 1497193.25000\n",
      "Step #100, epoch #50, avg. train loss: 2337471.75000\n",
      "Step #200, epoch #100, avg. train loss: 1529461.25000\n",
      "Step #100, epoch #100, avg. train loss: 3190399.75000\n",
      "Step #200, epoch #200, avg. train loss: 1535912.62500\n",
      "Step #100, epoch #100, avg. train loss: 3118178.00000\n",
      "Step #200, epoch #200, avg. train loss: 1471436.62500\n",
      "Step #100, epoch #100, avg. train loss: 3098319.00000\n",
      "Step #200, epoch #200, avg. train loss: 1695189.75000\n",
      "Step #100, epoch #25, avg. train loss: 2707796.50000\n",
      "Step #200, epoch #50, avg. train loss: 1564363.87500\n",
      "Step #100, epoch #25, avg. train loss: 2649437.50000\n",
      "Step #200, epoch #50, avg. train loss: 1602637.62500\n",
      "Step #100, epoch #25, avg. train loss: 2789871.25000\n",
      "Step #200, epoch #50, avg. train loss: 1563340.12500\n",
      "Step #100, epoch #50, avg. train loss: 3462448.75000\n",
      "Step #200, epoch #100, avg. train loss: 1537969.12500\n",
      "Step #100, epoch #50, avg. train loss: 3435075.00000\n",
      "Step #200, epoch #100, avg. train loss: 1547914.87500\n",
      "Step #100, epoch #50, avg. train loss: 3329575.75000\n",
      "Step #200, epoch #100, avg. train loss: 1470694.50000\n",
      "Step #100, epoch #50, avg. train loss: 2258886.25000\n",
      "Step #200, epoch #100, avg. train loss: 1640335.50000\n",
      "Step #100, epoch #50, avg. train loss: 2122085.00000\n",
      "Step #200, epoch #100, avg. train loss: 1572734.50000\n",
      "Step #100, epoch #50, avg. train loss: 2165437.50000\n",
      "Step #200, epoch #100, avg. train loss: 1594797.87500\n",
      "Step #100, epoch #50, avg. train loss: 11577661.00000\n",
      "Step #200, epoch #100, avg. train loss: 11437409.00000\n",
      "Step #100, epoch #50, avg. train loss: 11884671.00000\n",
      "Step #200, epoch #100, avg. train loss: 11748206.00000\n",
      "Step #100, epoch #50, avg. train loss: 11267846.00000\n",
      "Step #200, epoch #100, avg. train loss: 11131690.00000\n",
      "Step #100, epoch #100, avg. train loss: 2448931.25000\n",
      "Step #200, epoch #200, avg. train loss: 1551794.25000\n",
      "Step #100, epoch #100, avg. train loss: 2369926.50000\n",
      "Step #200, epoch #200, avg. train loss: 1476148.37500\n",
      "Step #100, epoch #100, avg. train loss: 2447337.50000\n",
      "Step #200, epoch #200, avg. train loss: 1523370.25000\n",
      "Step #100, epoch #100, avg. train loss: 2937920.75000\n",
      "Step #200, epoch #200, avg. train loss: 1646591.87500\n",
      "Step #100, epoch #100, avg. train loss: 2776947.25000\n",
      "Step #200, epoch #200, avg. train loss: 1501282.87500\n",
      "Step #100, epoch #100, avg. train loss: 2841018.50000\n",
      "Step #200, epoch #200, avg. train loss: 1507854.37500\n",
      "Step #100, epoch #100, avg. train loss: 3571515.50000\n",
      "Step #200, epoch #200, avg. train loss: 1549084.62500\n",
      "Step #100, epoch #100, avg. train loss: 3450729.50000\n",
      "Step #200, epoch #200, avg. train loss: 1547085.25000\n",
      "Step #100, epoch #100, avg. train loss: 3555749.50000\n",
      "Step #200, epoch #200, avg. train loss: 1551070.87500\n",
      "Step #100, epoch #50, avg. train loss: 2142531.25000\n",
      "Step #200, epoch #100, avg. train loss: 1595176.50000\n",
      "Step #100, epoch #50, avg. train loss: 2051337.75000\n",
      "Step #200, epoch #100, avg. train loss: 1515278.12500\n",
      "Step #100, epoch #50, avg. train loss: 2144477.50000\n",
      "Step #200, epoch #100, avg. train loss: 1574428.75000\n",
      "Step #100, epoch #50, avg. train loss: 3145976.00000\n",
      "Step #200, epoch #100, avg. train loss: 1553613.12500\n",
      "Step #100, epoch #50, avg. train loss: 3138319.00000\n",
      "Step #200, epoch #100, avg. train loss: 1464266.37500\n",
      "Step #100, epoch #50, avg. train loss: 3034708.25000\n",
      "Step #200, epoch #100, avg. train loss: 1543739.87500\n",
      "Step #100, epoch #100, avg. train loss: 2841300.50000\n",
      "Step #200, epoch #200, avg. train loss: 1538708.37500\n",
      "Step #100, epoch #100, avg. train loss: 2740141.75000\n",
      "Step #200, epoch #200, avg. train loss: 1528901.75000\n",
      "Step #100, epoch #100, avg. train loss: 2756411.25000\n",
      "Step #200, epoch #200, avg. train loss: 1598423.50000\n",
      "Step #100, epoch #50, avg. train loss: 2114253.00000\n",
      "Step #200, epoch #100, avg. train loss: 1626714.50000\n",
      "Step #100, epoch #50, avg. train loss: 2017483.62500\n",
      "Step #200, epoch #100, avg. train loss: 1535673.00000\n",
      "Step #100, epoch #50, avg. train loss: 2146093.00000\n",
      "Step #200, epoch #100, avg. train loss: 1673618.12500\n",
      "Step #100, epoch #16, avg. train loss: 2125843.00000\n",
      "Step #200, epoch #33, avg. train loss: 1690917.00000\n",
      "Step #100, epoch #16, avg. train loss: 2023530.75000\n",
      "Step #200, epoch #33, avg. train loss: 1650808.50000\n",
      "Step #100, epoch #16, avg. train loss: 2124343.25000\n",
      "Step #200, epoch #33, avg. train loss: 1749619.62500\n",
      "Step #100, epoch #100, avg. train loss: 2267868.00000\n",
      "Step #200, epoch #200, avg. train loss: 1585359.62500\n",
      "Step #100, epoch #100, avg. train loss: 2203054.50000\n",
      "Step #200, epoch #200, avg. train loss: 1515985.25000\n",
      "Step #100, epoch #100, avg. train loss: 2272642.75000\n",
      "Step #200, epoch #200, avg. train loss: 1584884.50000\n",
      "Step #100, epoch #33, avg. train loss: 2116821.50000\n",
      "Step #200, epoch #66, avg. train loss: 1512177.87500\n",
      "Step #100, epoch #33, avg. train loss: 2053488.50000\n",
      "Step #200, epoch #66, avg. train loss: 1437490.12500\n",
      "Step #100, epoch #33, avg. train loss: 2135485.00000\n",
      "Step #200, epoch #66, avg. train loss: 1504124.37500\n",
      "Step #100, epoch #2, avg. train loss: 2260073.75000\n",
      "Step #200, epoch #5, avg. train loss: 1906110.50000\n",
      "Step #100, epoch #2, avg. train loss: 2116598.50000\n",
      "Step #200, epoch #5, avg. train loss: 1698099.62500\n",
      "Step #100, epoch #2, avg. train loss: 2297101.25000\n",
      "Step #200, epoch #5, avg. train loss: 1774232.75000\n",
      "Step #100, epoch #9, avg. train loss: 2729721.50000\n",
      "Step #200, epoch #18, avg. train loss: 1593288.00000\n",
      "Step #100, epoch #9, avg. train loss: 2632967.25000\n",
      "Step #200, epoch #18, avg. train loss: 1564954.25000\n",
      "Step #100, epoch #9, avg. train loss: 2650757.25000\n",
      "Step #200, epoch #18, avg. train loss: 1581394.37500\n",
      "Step #100, epoch #33, avg. train loss: 3075551.25000\n",
      "Step #200, epoch #66, avg. train loss: 1507244.37500\n",
      "Step #100, epoch #33, avg. train loss: 3123836.25000\n",
      "Step #200, epoch #66, avg. train loss: 1452610.37500\n",
      "Step #100, epoch #33, avg. train loss: 2997150.50000\n",
      "Step #200, epoch #66, avg. train loss: 1492282.50000\n",
      "Step #100, epoch #50, avg. train loss: 2874349.75000\n",
      "Step #200, epoch #100, avg. train loss: 1580481.87500\n",
      "Step #100, epoch #50, avg. train loss: 2838158.50000\n",
      "Step #200, epoch #100, avg. train loss: 1546349.87500\n",
      "Step #100, epoch #50, avg. train loss: 2858863.25000\n",
      "Step #200, epoch #100, avg. train loss: 1605559.37500\n",
      "Step #100, epoch #50, avg. train loss: 2623582.75000\n",
      "Step #200, epoch #100, avg. train loss: 1554655.50000\n",
      "Step #100, epoch #50, avg. train loss: 2569865.00000\n",
      "Step #200, epoch #100, avg. train loss: 1482605.12500\n",
      "Step #100, epoch #50, avg. train loss: 2617751.00000\n",
      "Step #200, epoch #100, avg. train loss: 1517270.50000\n",
      "Step #100, epoch #100, avg. train loss: 2114894.00000\n",
      "Step #200, epoch #200, avg. train loss: 1692085.87500\n",
      "Step #100, epoch #100, avg. train loss: 2026765.50000\n",
      "Step #200, epoch #200, avg. train loss: 1549496.75000\n",
      "Step #100, epoch #100, avg. train loss: 2106233.75000\n",
      "Step #200, epoch #200, avg. train loss: 1629167.25000\n",
      "Step #100, epoch #50, avg. train loss: 2138113.50000\n",
      "Step #200, epoch #100, avg. train loss: 1692912.50000\n",
      "Step #100, epoch #50, avg. train loss: 2023400.62500\n",
      "Step #200, epoch #100, avg. train loss: 1565547.25000\n",
      "Step #100, epoch #50, avg. train loss: 2133998.50000\n",
      "Step #200, epoch #100, avg. train loss: 1671552.12500\n",
      "Step #100, epoch #50, avg. train loss: 2409638.00000\n",
      "Step #200, epoch #100, avg. train loss: 1473160.75000\n",
      "Step #100, epoch #50, avg. train loss: 2326376.00000\n",
      "Step #200, epoch #100, avg. train loss: 1491120.12500\n",
      "Step #100, epoch #50, avg. train loss: 2362273.00000\n",
      "Step #200, epoch #100, avg. train loss: 1588257.87500\n",
      "Step #100, epoch #100, avg. train loss: 3457074.50000\n",
      "Step #200, epoch #200, avg. train loss: 1561951.37500\n",
      "Step #100, epoch #100, avg. train loss: 3367228.75000\n",
      "Step #200, epoch #200, avg. train loss: 1578783.62500\n",
      "Step #100, epoch #100, avg. train loss: 3448439.00000\n",
      "Step #200, epoch #200, avg. train loss: 1553674.37500\n",
      "Step #100, epoch #100, avg. train loss: 2101113.75000\n",
      "Step #200, epoch #200, avg. train loss: 1694185.25000\n",
      "Step #100, epoch #100, avg. train loss: 2027552.00000\n",
      "Step #200, epoch #200, avg. train loss: 1504184.50000\n",
      "Step #100, epoch #100, avg. train loss: 2093730.12500\n",
      "Step #200, epoch #200, avg. train loss: 1639032.37500\n",
      "Step #100, epoch #100, avg. train loss: 2211948.75000\n",
      "Step #200, epoch #200, avg. train loss: 1507838.50000\n",
      "Step #100, epoch #100, avg. train loss: 2191026.50000\n",
      "Step #200, epoch #200, avg. train loss: 1482857.00000\n",
      "Step #100, epoch #100, avg. train loss: 2221208.25000\n",
      "Step #200, epoch #200, avg. train loss: 1504973.00000\n",
      "Step #100, epoch #50, avg. train loss: 2856554.25000\n",
      "Step #200, epoch #100, avg. train loss: 1537402.75000\n",
      "Step #100, epoch #50, avg. train loss: 2771588.75000\n",
      "Step #200, epoch #100, avg. train loss: 1601733.75000\n",
      "Step #100, epoch #50, avg. train loss: 2798375.75000\n",
      "Step #200, epoch #100, avg. train loss: 1535239.62500\n",
      "Step #100, epoch #100, avg. train loss: 2783275.75000\n",
      "Step #200, epoch #200, avg. train loss: 1491260.12500\n",
      "Step #100, epoch #100, avg. train loss: 2719948.50000\n",
      "Step #200, epoch #200, avg. train loss: 1532852.62500\n",
      "Step #100, epoch #100, avg. train loss: 2778434.00000\n",
      "Step #200, epoch #200, avg. train loss: 1527493.25000\n",
      "Step #100, epoch #50, avg. train loss: 2629805.50000\n",
      "Step #200, epoch #100, avg. train loss: 1555691.25000\n",
      "Step #100, epoch #50, avg. train loss: 3247841.00000\n",
      "Step #200, epoch #100, avg. train loss: 1633809.25000\n",
      "Step #100, epoch #50, avg. train loss: 2466332.50000\n",
      "Step #200, epoch #100, avg. train loss: 1535369.00000\n",
      "Step #100, epoch #100, avg. train loss: 11782281.00000\n",
      "Step #200, epoch #200, avg. train loss: 11267601.00000\n",
      "Step #100, epoch #100, avg. train loss: 12124259.00000\n",
      "Step #200, epoch #200, avg. train loss: 11597622.00000\n",
      "Step #100, epoch #100, avg. train loss: 11481376.00000\n",
      "Step #200, epoch #200, avg. train loss: 10977158.00000\n",
      "Step #100, epoch #100, avg. train loss: 2108795.75000\n",
      "Step #200, epoch #200, avg. train loss: 1634818.25000\n",
      "Step #100, epoch #100, avg. train loss: 2024041.50000\n",
      "Step #200, epoch #200, avg. train loss: 1576726.12500\n",
      "Step #100, epoch #100, avg. train loss: 2123208.00000\n",
      "Step #200, epoch #200, avg. train loss: 1620722.50000\n",
      "Step #100, epoch #50, avg. train loss: 2118286.00000\n",
      "Step #200, epoch #100, avg. train loss: 1647674.25000\n",
      "Step #100, epoch #50, avg. train loss: 2065868.50000\n",
      "Step #200, epoch #100, avg. train loss: 1512977.87500\n",
      "Step #100, epoch #50, avg. train loss: 2138431.75000\n",
      "Step #200, epoch #100, avg. train loss: 1611994.25000\n",
      "Step #100, epoch #100, avg. train loss: 2206370.00000\n",
      "Step #200, epoch #200, avg. train loss: 1693147.50000\n",
      "Step #100, epoch #100, avg. train loss: 2131615.75000\n",
      "Step #200, epoch #200, avg. train loss: 1599976.12500\n",
      "Step #100, epoch #100, avg. train loss: 2214953.00000\n",
      "Step #200, epoch #200, avg. train loss: 1712169.25000\n",
      "Step #100, epoch #50, avg. train loss: 2271775.00000\n",
      "Step #200, epoch #100, avg. train loss: 1605265.25000\n",
      "Step #100, epoch #50, avg. train loss: 2325746.50000\n",
      "Step #200, epoch #100, avg. train loss: 1588357.12500\n",
      "Step #100, epoch #50, avg. train loss: 2352311.00000\n",
      "Step #200, epoch #100, avg. train loss: 1650239.62500\n",
      "Step #100, epoch #50, avg. train loss: 2413718.50000\n",
      "Step #200, epoch #100, avg. train loss: 1514962.25000\n",
      "Step #100, epoch #50, avg. train loss: 2138731.50000\n",
      "Step #200, epoch #100, avg. train loss: 1560513.12500\n",
      "Step #100, epoch #50, avg. train loss: 2316080.75000\n",
      "Step #200, epoch #100, avg. train loss: 1548945.62500\n",
      "Step #100, epoch #100, avg. train loss: 2167495.00000\n",
      "Step #200, epoch #200, avg. train loss: 1525838.12500\n",
      "Step #100, epoch #100, avg. train loss: 2087798.37500\n",
      "Step #200, epoch #200, avg. train loss: 1484311.25000\n",
      "Step #100, epoch #100, avg. train loss: 2177380.75000\n",
      "Step #200, epoch #200, avg. train loss: 1510779.50000\n",
      "Step #100, epoch #100, avg. train loss: 2225739.00000\n",
      "Step #200, epoch #200, avg. train loss: 1503201.25000\n",
      "Step #100, epoch #100, avg. train loss: 2182888.00000\n",
      "Step #200, epoch #200, avg. train loss: 1371183.87500\n",
      "Step #100, epoch #100, avg. train loss: 2237519.25000\n",
      "Step #200, epoch #200, avg. train loss: 1498684.37500\n",
      "Step #100, epoch #100, avg. train loss: 2276726.50000\n",
      "Step #200, epoch #200, avg. train loss: 1465965.75000\n",
      "Step #100, epoch #100, avg. train loss: 2213293.25000\n",
      "Step #200, epoch #200, avg. train loss: 1409946.25000\n",
      "Step #100, epoch #100, avg. train loss: 2282907.25000\n",
      "Step #200, epoch #200, avg. train loss: 1459207.62500\n",
      "Step #100, epoch #50, avg. train loss: 2912058.50000\n",
      "Step #200, epoch #100, avg. train loss: 1625113.50000\n",
      "Step #100, epoch #50, avg. train loss: 2841796.75000\n",
      "Step #200, epoch #100, avg. train loss: 1524364.50000\n",
      "Step #100, epoch #50, avg. train loss: 2943983.75000\n",
      "Step #200, epoch #100, avg. train loss: 1573377.00000\n",
      "Step #100, epoch #100, avg. train loss: 2897627.50000\n",
      "Step #200, epoch #200, avg. train loss: 1582685.12500\n",
      "Step #100, epoch #100, avg. train loss: 2784476.25000\n",
      "Step #200, epoch #200, avg. train loss: 1514504.75000\n",
      "Step #100, epoch #100, avg. train loss: 2920754.25000\n",
      "Step #200, epoch #200, avg. train loss: 1505383.50000\n",
      "Step #100, epoch #100, avg. train loss: 2096804.75000\n",
      "Step #200, epoch #200, avg. train loss: 1530308.00000\n",
      "Step #100, epoch #100, avg. train loss: 2024169.62500\n",
      "Step #200, epoch #200, avg. train loss: 1477345.87500\n",
      "Step #100, epoch #100, avg. train loss: 2103711.75000\n",
      "Step #200, epoch #200, avg. train loss: 1478459.25000\n",
      "Step #100, epoch #50, avg. train loss: 2301949.25000\n",
      "Step #200, epoch #100, avg. train loss: 1586855.37500\n",
      "Step #100, epoch #50, avg. train loss: 2215523.25000\n",
      "Step #200, epoch #100, avg. train loss: 1530166.12500\n",
      "Step #100, epoch #50, avg. train loss: 2265165.50000\n",
      "Step #200, epoch #100, avg. train loss: 1678231.87500\n",
      "Step #100, epoch #100, avg. train loss: 2689957.00000\n",
      "Step #200, epoch #200, avg. train loss: 1513447.50000\n",
      "Step #100, epoch #100, avg. train loss: 2609942.00000\n",
      "Step #200, epoch #200, avg. train loss: 1467849.25000\n",
      "Step #100, epoch #100, avg. train loss: 2624416.00000\n",
      "Step #200, epoch #200, avg. train loss: 1755061.62500\n",
      "Step #100, epoch #100, avg. train loss: 3911519.75000\n",
      "Step #200, epoch #200, avg. train loss: 1560773.50000\n",
      "Step #100, epoch #100, avg. train loss: 3633138.50000\n",
      "Step #200, epoch #200, avg. train loss: 1557872.12500\n",
      "Step #100, epoch #100, avg. train loss: 3778182.00000\n",
      "Step #200, epoch #200, avg. train loss: 1548971.25000\n",
      "Step #100, epoch #50, avg. train loss: 2798962.00000\n",
      "Step #200, epoch #100, avg. train loss: 1493816.50000\n",
      "Step #100, epoch #50, avg. train loss: 2797584.75000\n",
      "Step #200, epoch #100, avg. train loss: 1525575.00000\n",
      "Step #100, epoch #50, avg. train loss: 2803442.50000\n",
      "Step #200, epoch #100, avg. train loss: 1550067.00000\n",
      "Step #100, epoch #100, avg. train loss: 2205203.00000\n",
      "Step #200, epoch #200, avg. train loss: 1575655.62500\n",
      "Step #100, epoch #100, avg. train loss: 2135093.50000\n",
      "Step #200, epoch #200, avg. train loss: 1433171.37500\n",
      "Step #100, epoch #100, avg. train loss: 2197569.75000\n",
      "Step #200, epoch #200, avg. train loss: 1540559.87500\n",
      "Step #100, epoch #50, avg. train loss: 3364850.50000\n",
      "Step #200, epoch #100, avg. train loss: 1795274.25000\n",
      "Step #100, epoch #50, avg. train loss: 3322370.25000\n",
      "Step #200, epoch #100, avg. train loss: 1724987.50000\n",
      "Step #100, epoch #50, avg. train loss: 3292601.50000\n",
      "Step #200, epoch #100, avg. train loss: 1809187.25000\n",
      "Step #100, epoch #50, avg. train loss: 2765407.25000\n",
      "Step #200, epoch #100, avg. train loss: 1779147.62500\n",
      "Step #100, epoch #50, avg. train loss: 2735250.25000\n",
      "Step #200, epoch #100, avg. train loss: 1710274.12500\n",
      "Step #100, epoch #50, avg. train loss: 2725551.75000\n",
      "Step #200, epoch #100, avg. train loss: 1806583.87500\n",
      "Step #100, epoch #100, avg. train loss: 2212937.50000\n",
      "Step #200, epoch #200, avg. train loss: 1507428.37500\n",
      "Step #100, epoch #100, avg. train loss: 2183057.00000\n",
      "Step #200, epoch #200, avg. train loss: 1516941.62500\n",
      "Step #100, epoch #100, avg. train loss: 2222179.25000\n",
      "Step #200, epoch #200, avg. train loss: 1498465.25000\n",
      "Step #100, epoch #33, avg. train loss: 4234015.50000\n",
      "Step #200, epoch #66, avg. train loss: 1563969.87500\n",
      "Step #100, epoch #33, avg. train loss: 3750425.50000\n",
      "Step #200, epoch #66, avg. train loss: 1553904.62500\n",
      "Step #100, epoch #33, avg. train loss: 3641040.25000\n",
      "Step #200, epoch #66, avg. train loss: 1548097.62500\n",
      "Step #100, epoch #100, avg. train loss: 2305632.75000\n",
      "Step #200, epoch #200, avg. train loss: 1556933.00000\n",
      "Step #100, epoch #100, avg. train loss: 2219876.25000\n",
      "Step #200, epoch #200, avg. train loss: 1500208.50000\n",
      "Step #100, epoch #100, avg. train loss: 2319826.50000\n",
      "Step #200, epoch #200, avg. train loss: 1533104.00000\n",
      "Step #100, epoch #100, avg. train loss: 2508763.50000\n",
      "Step #200, epoch #200, avg. train loss: 1665937.50000\n",
      "Step #100, epoch #100, avg. train loss: 2642310.50000\n",
      "Step #200, epoch #200, avg. train loss: 1653038.87500\n",
      "Step #100, epoch #100, avg. train loss: 2427811.00000\n",
      "Step #200, epoch #200, avg. train loss: 1603035.62500\n",
      "Step #100, epoch #100, avg. train loss: 2170862.50000\n",
      "Step #200, epoch #200, avg. train loss: 1528407.50000\n",
      "Step #100, epoch #100, avg. train loss: 2073337.00000\n",
      "Step #200, epoch #200, avg. train loss: 1456482.25000\n",
      "Step #100, epoch #100, avg. train loss: 2139841.75000\n",
      "Step #200, epoch #200, avg. train loss: 1507401.12500\n",
      "Step #100, epoch #100, avg. train loss: 2083815.37500\n",
      "Step #200, epoch #200, avg. train loss: 1591561.12500\n",
      "Step #100, epoch #100, avg. train loss: 2017495.62500\n",
      "Step #200, epoch #200, avg. train loss: 1567913.00000\n",
      "Step #100, epoch #100, avg. train loss: 2090515.50000\n",
      "Step #200, epoch #200, avg. train loss: 1500983.50000\n",
      "Step #100, epoch #100, avg. train loss: 2107466.50000\n",
      "Step #200, epoch #200, avg. train loss: 1550723.25000\n",
      "Step #100, epoch #100, avg. train loss: 2035681.50000\n",
      "Step #200, epoch #200, avg. train loss: 1555015.87500\n",
      "Step #100, epoch #100, avg. train loss: 2124734.50000\n",
      "Step #200, epoch #200, avg. train loss: 1536962.25000\n",
      "Step #100, epoch #11, avg. train loss: 2366601.50000\n",
      "Step #200, epoch #22, avg. train loss: 1604701.25000\n",
      "Step #100, epoch #11, avg. train loss: 2281443.75000\n",
      "Step #200, epoch #22, avg. train loss: 1559685.25000\n",
      "Step #100, epoch #11, avg. train loss: 2315816.75000\n",
      "Step #200, epoch #22, avg. train loss: 1746619.00000\n",
      "Step #100, epoch #100, avg. train loss: 7314724.50000\n",
      "Step #200, epoch #200, avg. train loss: 1894461.00000\n",
      "Step #100, epoch #100, avg. train loss: 7529321.00000\n",
      "Step #200, epoch #200, avg. train loss: 1825006.12500\n",
      "Step #100, epoch #100, avg. train loss: 7119834.00000\n",
      "Step #200, epoch #200, avg. train loss: 1906324.12500\n",
      "Step #100, epoch #20, avg. train loss: 2750839.75000\n",
      "Step #200, epoch #40, avg. train loss: 1619485.62500\n",
      "Step #100, epoch #20, avg. train loss: 2631716.50000\n",
      "Step #200, epoch #40, avg. train loss: 1550903.25000\n",
      "Step #100, epoch #20, avg. train loss: 2627685.00000\n",
      "Step #200, epoch #40, avg. train loss: 1514702.75000\n",
      "Step #100, epoch #50, avg. train loss: 2118841.50000\n",
      "Step #200, epoch #100, avg. train loss: 1541780.37500\n",
      "Step #100, epoch #50, avg. train loss: 2050702.75000\n",
      "Step #200, epoch #100, avg. train loss: 1538201.25000\n",
      "Step #100, epoch #50, avg. train loss: 2161427.00000\n",
      "Step #200, epoch #100, avg. train loss: 1544537.62500\n",
      "Step #100, epoch #100, avg. train loss: 2176184.25000\n",
      "Step #200, epoch #200, avg. train loss: 1554076.75000\n",
      "Step #100, epoch #100, avg. train loss: 2096833.00000\n",
      "Step #200, epoch #200, avg. train loss: 1489704.12500\n",
      "Step #100, epoch #100, avg. train loss: 2185764.00000\n",
      "Step #200, epoch #200, avg. train loss: 1536859.62500\n",
      "Step #100, epoch #50, avg. train loss: 3345608.25000\n",
      "Step #200, epoch #100, avg. train loss: 1563813.62500\n",
      "Step #100, epoch #50, avg. train loss: 3209408.00000\n",
      "Step #200, epoch #100, avg. train loss: 1576379.87500\n",
      "Step #100, epoch #50, avg. train loss: 3243820.50000\n",
      "Step #200, epoch #100, avg. train loss: 1535108.12500\n",
      "Step #100, epoch #33, avg. train loss: 2253354.25000\n",
      "Step #200, epoch #66, avg. train loss: 1576223.37500\n",
      "Step #100, epoch #33, avg. train loss: 2175198.00000\n",
      "Step #200, epoch #66, avg. train loss: 1522155.25000\n",
      "Step #100, epoch #33, avg. train loss: 2237840.75000\n",
      "Step #200, epoch #66, avg. train loss: 1518693.87500\n",
      "Step #100, epoch #9, avg. train loss: 11132495.00000\n",
      "Step #200, epoch #18, avg. train loss: 10653960.00000\n",
      "Step #100, epoch #9, avg. train loss: 11524686.00000\n",
      "Step #200, epoch #18, avg. train loss: 11032196.00000\n",
      "Step #100, epoch #9, avg. train loss: 10831571.00000\n",
      "Step #200, epoch #18, avg. train loss: 10474476.00000\n",
      "Step #100, epoch #33, avg. train loss: 2144302.00000\n",
      "Step #200, epoch #66, avg. train loss: 1716496.00000\n",
      "Step #100, epoch #33, avg. train loss: 2088111.37500\n",
      "Step #200, epoch #66, avg. train loss: 1682711.37500\n",
      "Step #100, epoch #33, avg. train loss: 2167171.75000\n",
      "Step #200, epoch #66, avg. train loss: 1712664.50000\n",
      "Step #100, epoch #25, avg. train loss: 3089231.75000\n",
      "Step #200, epoch #50, avg. train loss: 1521394.12500\n",
      "Step #100, epoch #25, avg. train loss: 3066513.50000\n",
      "Step #200, epoch #50, avg. train loss: 1568748.75000\n",
      "Step #100, epoch #25, avg. train loss: 2915282.50000\n",
      "Step #200, epoch #50, avg. train loss: 1525196.00000\n",
      "Step #100, epoch #100, avg. train loss: 2507749.00000\n",
      "Step #200, epoch #200, avg. train loss: 1661749.12500\n",
      "Step #100, epoch #100, avg. train loss: 2515497.00000\n",
      "Step #200, epoch #200, avg. train loss: 1640684.37500\n",
      "Step #100, epoch #100, avg. train loss: 2386141.75000\n",
      "Step #200, epoch #200, avg. train loss: 1532684.62500\n",
      "Step #100, epoch #100, avg. train loss: 2106260.00000\n",
      "Step #200, epoch #200, avg. train loss: 1630985.87500\n",
      "Step #100, epoch #100, avg. train loss: 2011185.87500\n",
      "Step #200, epoch #200, avg. train loss: 1380386.50000\n",
      "Step #100, epoch #100, avg. train loss: 2097620.25000\n",
      "Step #200, epoch #200, avg. train loss: 1538918.50000\n",
      "Step #100, epoch #50, avg. train loss: 2181481.25000\n",
      "Step #200, epoch #100, avg. train loss: 1528179.00000\n",
      "Step #100, epoch #50, avg. train loss: 2072424.62500\n",
      "Step #200, epoch #100, avg. train loss: 1595986.25000\n",
      "Step #100, epoch #50, avg. train loss: 2200695.00000\n",
      "Step #200, epoch #100, avg. train loss: 1548379.50000\n",
      "Step #100, epoch #100, avg. train loss: 2076655.87500\n",
      "Step #200, epoch #200, avg. train loss: 1620424.50000\n",
      "Step #100, epoch #100, avg. train loss: 1993825.75000\n",
      "Step #200, epoch #200, avg. train loss: 1523005.12500\n",
      "Step #100, epoch #100, avg. train loss: 2063266.87500\n",
      "Step #200, epoch #200, avg. train loss: 1502524.00000\n",
      "Step #100, epoch #100, avg. train loss: 2137011.75000\n",
      "Step #200, epoch #200, avg. train loss: 1509069.50000\n",
      "Step #100, epoch #100, avg. train loss: 2059607.37500\n",
      "Step #200, epoch #200, avg. train loss: 1441506.25000\n",
      "Step #100, epoch #100, avg. train loss: 2123628.25000\n",
      "Step #200, epoch #200, avg. train loss: 1493529.75000\n",
      "Step #100, epoch #33, avg. train loss: 2954721.00000\n",
      "Step #200, epoch #66, avg. train loss: 1497073.12500\n",
      "Step #100, epoch #33, avg. train loss: 2902105.25000\n",
      "Step #200, epoch #66, avg. train loss: 1454165.25000\n",
      "Step #100, epoch #33, avg. train loss: 2957911.00000\n",
      "Step #200, epoch #66, avg. train loss: 1454038.87500\n",
      "Step #100, epoch #25, avg. train loss: 2642186.25000\n",
      "Step #200, epoch #50, avg. train loss: 1666600.62500\n",
      "Step #100, epoch #25, avg. train loss: 2579860.50000\n",
      "Step #200, epoch #50, avg. train loss: 1620053.50000\n",
      "Step #100, epoch #25, avg. train loss: 2528195.50000\n",
      "Step #200, epoch #50, avg. train loss: 1571178.50000\n",
      "Step #100, epoch #12, avg. train loss: 2201651.50000\n",
      "Step #200, epoch #25, avg. train loss: 1696759.25000\n",
      "Step #100, epoch #12, avg. train loss: 2102235.25000\n",
      "Step #200, epoch #25, avg. train loss: 1554039.87500\n",
      "Step #100, epoch #12, avg. train loss: 2155016.75000\n",
      "Step #200, epoch #25, avg. train loss: 1657383.00000\n",
      "Step #100, epoch #20, avg. train loss: 4557288.50000\n",
      "Step #200, epoch #40, avg. train loss: 1619575.25000\n",
      "Step #100, epoch #20, avg. train loss: 2508932.00000\n",
      "Step #200, epoch #40, avg. train loss: 1647437.50000\n",
      "Step #100, epoch #20, avg. train loss: 2456441.50000\n",
      "Step #200, epoch #40, avg. train loss: 1515902.75000\n",
      "Step #100, epoch #6, avg. train loss: 3069136.25000\n",
      "Step #200, epoch #13, avg. train loss: 1629507.25000\n",
      "Step #100, epoch #6, avg. train loss: 2925634.50000\n",
      "Step #200, epoch #13, avg. train loss: 1557849.00000\n",
      "Step #100, epoch #6, avg. train loss: 2854324.50000\n",
      "Step #200, epoch #13, avg. train loss: 1555676.75000\n",
      "Step #100, epoch #100, avg. train loss: 2215303.75000\n",
      "Step #200, epoch #200, avg. train loss: 1645090.87500\n",
      "Step #100, epoch #100, avg. train loss: 2154318.75000\n",
      "Step #200, epoch #200, avg. train loss: 1605282.75000\n",
      "Step #100, epoch #100, avg. train loss: 2217403.00000\n",
      "Step #200, epoch #200, avg. train loss: 1678559.00000\n",
      "Step #100, epoch #33, avg. train loss: 4455939.50000\n",
      "Step #200, epoch #66, avg. train loss: 1516144.37500\n",
      "Step #100, epoch #33, avg. train loss: 4128223.25000\n",
      "Step #200, epoch #66, avg. train loss: 1492036.00000\n",
      "Step #100, epoch #33, avg. train loss: 3779531.00000\n",
      "Step #200, epoch #66, avg. train loss: 1456599.50000\n",
      "Step #100, epoch #50, avg. train loss: 2084245.12500\n",
      "Step #200, epoch #100, avg. train loss: 1662093.62500\n",
      "Step #100, epoch #50, avg. train loss: 1997787.25000\n",
      "Step #200, epoch #100, avg. train loss: 1584693.12500\n",
      "Step #100, epoch #50, avg. train loss: 2089424.37500\n",
      "Step #200, epoch #100, avg. train loss: 1645998.75000\n",
      "Step #100, epoch #50, avg. train loss: 2146123.00000\n",
      "Step #200, epoch #100, avg. train loss: 1550671.25000\n",
      "Step #100, epoch #50, avg. train loss: 2100578.50000\n",
      "Step #200, epoch #100, avg. train loss: 1485543.62500\n",
      "Step #100, epoch #50, avg. train loss: 2285113.75000\n",
      "Step #200, epoch #100, avg. train loss: 1620223.00000\n",
      "Step #100, epoch #14, avg. train loss: 3217493.75000\n",
      "Step #200, epoch #28, avg. train loss: 1666599.00000\n",
      "Step #100, epoch #14, avg. train loss: 2390697.00000\n",
      "Step #200, epoch #28, avg. train loss: 1630125.25000\n",
      "Step #100, epoch #14, avg. train loss: 2547216.50000\n",
      "Step #200, epoch #28, avg. train loss: 1637396.50000\n",
      "Step #100, epoch #100, avg. train loss: 2768493.50000\n",
      "Step #200, epoch #200, avg. train loss: 1536362.75000\n",
      "Step #100, epoch #100, avg. train loss: 2700779.75000\n",
      "Step #200, epoch #200, avg. train loss: 1486359.37500\n",
      "Step #100, epoch #100, avg. train loss: 2910716.50000\n",
      "Step #200, epoch #200, avg. train loss: 1610829.00000\n",
      "Step #100, epoch #100, avg. train loss: 2773826.00000\n",
      "Step #200, epoch #200, avg. train loss: 1553849.62500\n",
      "Step #100, epoch #100, avg. train loss: 2722179.00000\n",
      "Step #200, epoch #200, avg. train loss: 1486532.50000\n",
      "Step #100, epoch #100, avg. train loss: 2872321.00000\n",
      "Step #200, epoch #200, avg. train loss: 1523672.12500\n",
      "Step #100, epoch #100, avg. train loss: 2087699.37500\n",
      "Step #200, epoch #200, avg. train loss: 1629085.75000\n",
      "Step #100, epoch #100, avg. train loss: 2007457.50000\n",
      "Step #200, epoch #200, avg. train loss: 1544718.12500\n",
      "Step #100, epoch #100, avg. train loss: 2100573.50000\n",
      "Step #200, epoch #200, avg. train loss: 1616040.62500\n",
      "Step #100, epoch #50, avg. train loss: 2193781.50000\n",
      "Step #200, epoch #100, avg. train loss: 1694781.62500\n",
      "Step #100, epoch #50, avg. train loss: 2125685.75000\n",
      "Step #200, epoch #100, avg. train loss: 1662058.37500\n",
      "Step #100, epoch #50, avg. train loss: 2199337.50000\n",
      "Step #200, epoch #100, avg. train loss: 1708433.75000\n",
      "Step #100, epoch #100, avg. train loss: 2284584.75000\n",
      "Step #200, epoch #200, avg. train loss: 1478874.12500\n",
      "best CV score from grid search: 0.309222\n",
      "corresponding parameters: {'learning_rate': 0.5292940189016049, 'hidden_units': [15, 15], 'batch_size': 607}\n",
      "Score: 0.190222\n"
     ]
    }
   ],
   "source": [
    "# DNN-Regressor tuned with RandomizesSearch\n",
    "\n",
    "# Parameters\n",
    "param_dist = {  'hidden_units': [[13,13], [14,14], [15,15]], \n",
    "                'learning_rate': sp_uniform(0.0,1.0), \n",
    "                'batch_size': sp_randint(1,729)\n",
    "             }\n",
    "\n",
    "n_iter_search = 100\n",
    "\n",
    "# MSE optimized\n",
    "#regressor_tuned_RS = RandomizedSearchCV(skflow.TensorFlowDNNRegressor (hidden_units = [10, 10]), param_distributions = param_dist, scoring = 'mean_squared_error', n_iter=n_iter_search)\n",
    "\n",
    "# R^2 optimized\n",
    "regressor_tuned_RS = RandomizedSearchCV(skflow.TensorFlowDNNRegressor (hidden_units = [10, 10]), param_distributions = param_dist, scoring = 'r2', n_iter=n_iter_search)\n",
    "\n",
    "# Fit\n",
    "regressor_tuned_RS.fit(X_train, y_train)\n",
    "\n",
    "# Best score and corresponding parameters.\n",
    "print('best CV score from grid search: {0:f}'.format(regressor_tuned_RS.best_score_))\n",
    "print('corresponding parameters: {}'.format(regressor_tuned_RS.best_params_))\n",
    "\n",
    "# source: https://github.com/tensorflow/skflow/pull/126/files\n",
    "\n",
    "# Predict and score\n",
    "predict = regressor_tuned_RS.predict(X_test)\n",
    "\n",
    "#score_regressor_tuned_RS = mean_squared_error(y_test, predict)\n",
    "score_regressor_tuned_RS = r2_score(y_test, predict)\n",
    "\n",
    "print('Score: {0:f}'.format(score_regressor_tuned_RS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Tuned DNN results: \n",
    " \n",
    "corresponding parameters: {'learning_rate': 0.7992653962585401, 'hidden_units': [13, 13], 'batch_size': 561}\n",
    "MSE: 3257365.518337\n",
    "\n",
    "corresponding parameters: {'learning_rate': 0.9620614315321504, 'hidden_units': [14, 14], 'batch_size': 413}\n",
    "MSE: 1991265.709509  \n",
    "\n",
    "corresponding parameters: {'learning_rate': 0.9874801602812813, 'hidden_units': [14, 14], 'batch_size': 445}\n",
    "MSE: 2543202.004386\n",
    "\n",
    "corresponding parameters: {'learning_rate': 0.9167557134938925, 'hidden_units': [14, 14], 'batch_size': 424}\n",
    "score: 0.404403   \n",
    "\n",
    "corresponding parameters: {'learning_rate': 0.7574216583764648, 'hidden_units': [14, 14], 'batch_size': 573}\n",
    "Score: 0.306644\n",
    "\n",
    "corresponding parameters: {'learning_rate': 0.7579695776853932, 'hidden_units': [14, 14], 'batch_size': 537}\n",
    "Score: 0.185412"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step #100, epoch #50, avg. train loss: 2990190.00000\n",
      "Step #100, epoch #50, avg. train loss: 2936366.75000\n",
      "Step #100, epoch #50, avg. train loss: 2965296.00000\n",
      "Step #100, epoch #50, avg. train loss: 2151554.75000\n",
      "Step #100, epoch #50, avg. train loss: 2188772.75000\n",
      "Step #100, epoch #50, avg. train loss: 2249670.50000\n",
      "Step #100, epoch #50, avg. train loss: 2445211.00000\n",
      "Step #100, epoch #50, avg. train loss: 2465338.25000\n",
      "Step #100, epoch #50, avg. train loss: 2569202.00000\n",
      "Step #100, epoch #50, avg. train loss: 4041653.75000\n",
      "Step #100, epoch #50, avg. train loss: 4274299.00000\n",
      "Step #100, epoch #50, avg. train loss: 4243271.50000\n",
      "Step #100, epoch #50, avg. train loss: 2273250.25000\n",
      "Step #100, epoch #50, avg. train loss: 2342465.50000\n",
      "Step #100, epoch #50, avg. train loss: 2299316.75000\n",
      "Step #100, epoch #50, avg. train loss: 2531373.50000\n",
      "Step #100, epoch #50, avg. train loss: 2552854.75000\n",
      "Step #100, epoch #50, avg. train loss: 2660086.50000\n",
      "Step #100, epoch #50, avg. train loss: 3178552.00000\n",
      "Step #100, epoch #50, avg. train loss: 3273081.00000\n",
      "Step #100, epoch #50, avg. train loss: 3154399.25000\n",
      "Step #100, epoch #50, avg. train loss: 2532773.00000\n",
      "Step #100, epoch #50, avg. train loss: 2614973.50000\n",
      "Step #100, epoch #50, avg. train loss: 2663519.75000\n",
      "Step #100, epoch #50, avg. train loss: 2223250.00000\n",
      "Step #100, epoch #50, avg. train loss: 2266170.00000\n",
      "Step #100, epoch #50, avg. train loss: 2360395.25000\n",
      "Step #100, epoch #100, avg. train loss: 2887510.75000\n",
      "Step #100, epoch #100, avg. train loss: 2832231.75000\n",
      "Step #100, epoch #100, avg. train loss: 2977816.25000\n",
      "Step #100, epoch #100, avg. train loss: 2038612.50000\n",
      "Step #100, epoch #100, avg. train loss: 2095591.00000\n",
      "Step #100, epoch #100, avg. train loss: 2232470.00000\n",
      "Step #100, epoch #100, avg. train loss: 2391018.50000\n",
      "Step #100, epoch #100, avg. train loss: 2394421.50000\n",
      "Step #100, epoch #100, avg. train loss: 2536719.25000\n",
      "Step #100, epoch #100, avg. train loss: 3894694.00000\n",
      "Step #100, epoch #100, avg. train loss: 3820483.50000\n",
      "Step #100, epoch #100, avg. train loss: 3953029.50000\n",
      "Step #100, epoch #100, avg. train loss: 2154020.75000\n",
      "Step #100, epoch #100, avg. train loss: 2175824.25000\n",
      "Step #100, epoch #100, avg. train loss: 2328483.75000\n",
      "Step #100, epoch #100, avg. train loss: 2497977.00000\n",
      "Step #100, epoch #100, avg. train loss: 2500790.00000\n",
      "Step #100, epoch #100, avg. train loss: 2634154.25000\n",
      "Step #100, epoch #100, avg. train loss: 2947922.50000\n",
      "Step #100, epoch #100, avg. train loss: 2852860.75000\n",
      "Step #100, epoch #100, avg. train loss: 3015932.50000\n",
      "Step #100, epoch #100, avg. train loss: 2364258.75000\n",
      "Step #100, epoch #100, avg. train loss: 2373208.50000\n",
      "Step #100, epoch #100, avg. train loss: 2515891.00000\n",
      "Step #100, epoch #100, avg. train loss: 2179425.00000\n",
      "Step #100, epoch #100, avg. train loss: 2185201.00000\n",
      "Step #100, epoch #100, avg. train loss: 2314622.25000\n",
      "Step #100, epoch #100, avg. train loss: 2887510.75000\n",
      "Step #100, epoch #100, avg. train loss: 2832231.75000\n",
      "Step #100, epoch #100, avg. train loss: 2977816.25000\n",
      "Step #100, epoch #100, avg. train loss: 2038612.50000\n",
      "Step #100, epoch #100, avg. train loss: 2095591.00000\n",
      "Step #100, epoch #100, avg. train loss: 2232470.00000\n",
      "Step #100, epoch #100, avg. train loss: 2391018.50000\n",
      "Step #100, epoch #100, avg. train loss: 2394421.50000\n",
      "Step #100, epoch #100, avg. train loss: 2536719.25000\n",
      "Step #100, epoch #100, avg. train loss: 3894694.00000\n",
      "Step #100, epoch #100, avg. train loss: 3820483.50000\n",
      "Step #100, epoch #100, avg. train loss: 3953029.50000\n",
      "Step #100, epoch #100, avg. train loss: 2154020.75000\n",
      "Step #100, epoch #100, avg. train loss: 2175824.25000\n",
      "Step #100, epoch #100, avg. train loss: 2328483.75000\n",
      "Step #100, epoch #100, avg. train loss: 2497977.00000\n",
      "Step #100, epoch #100, avg. train loss: 2500790.00000\n",
      "Step #100, epoch #100, avg. train loss: 2634154.25000\n",
      "Step #100, epoch #100, avg. train loss: 2947922.50000\n",
      "Step #100, epoch #100, avg. train loss: 2852860.75000\n",
      "Step #100, epoch #100, avg. train loss: 3015932.50000\n",
      "Step #100, epoch #100, avg. train loss: 2364258.75000\n",
      "Step #100, epoch #100, avg. train loss: 2373208.50000\n",
      "Step #100, epoch #100, avg. train loss: 2515891.00000\n",
      "Step #100, epoch #100, avg. train loss: 2179425.00000\n",
      "Step #100, epoch #100, avg. train loss: 2185201.00000\n",
      "Step #100, epoch #100, avg. train loss: 2314622.25000\n",
      "Step #100, epoch #50, avg. train loss: 3869716.75000\n",
      "best CV score from grid search: 0.117464\n",
      "corresponding parameters: {'steps': 100, 'learning_rate': 1.0, 'hidden_units': [13, 13], 'batch_size': 400}\n",
      "Score: 0.019807\n"
     ]
    }
   ],
   "source": [
    "# DNN-Regressor tuned with GS\n",
    "\n",
    "# param_grid\n",
    "param_grid = {'hidden_units': [[12,12], [13,13], [14,14]], \n",
    "              'steps': [100],\n",
    "              'learning_rate': [1.0, 0.5, 0.1],\n",
    "              'batch_size': [350, 400, 450]\n",
    "             }\n",
    "\n",
    "# MSE\n",
    "#regressor_tuned = GridSearchCV(skflow.TensorFlowDNNRegressor (hidden_units = [10, 10]), param_grid, scoring = 'mean_squared_error')\n",
    "\n",
    "#R^2\n",
    "regressor_tuned_GS = GridSearchCV(skflow.TensorFlowDNNRegressor (hidden_units = [10, 10]), param_grid, scoring = 'r2')\n",
    "\n",
    "# Fit\n",
    "regressor_tuned_GS.fit(X_train, y_train)\n",
    "\n",
    "# Best score and corresponding parameters.\n",
    "print('best CV score from grid search: {0:f}'.format(regressor_tuned_GS.best_score_))\n",
    "print('corresponding parameters: {}'.format(regressor_tuned_GS.best_params_))\n",
    "\n",
    "# source: https://github.com/tensorflow/skflow/pull/126/files\n",
    "\n",
    "# Predict and score\n",
    "predict = regressor_tuned_GS.predict(X_test)\n",
    "\n",
    "#score_regressor_tuned = mean_squared_error(y_test, predict)\n",
    "score_regressor_tuned_GS = r2_score(y_test, predict)\n",
    "\n",
    "print('Score: {0:f}'.format(score_regressor_tuned_GS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "SVR results:\n",
    "\n",
    "corresponding parameters: {'steps': 100, 'learning_rate': 1.0, 'hidden_units': [13, 13], 'batch_size': 400}\n",
    "MSE: 3275144.565188\n",
    "\n",
    "corresponding parameters: {'steps': 100, 'learning_rate': 1.0, 'hidden_units': [13, 13], 'batch_size': 400}\n",
    "MSE: 3275144.565188  \n",
    "\n",
    "corresponding parameters: {'steps': 100, 'learning_rate': 1.0, 'hidden_units': [12, 12], 'batch_size': 400}\n",
    "MSE: 2115469.864387  \n",
    "\n",
    "corresponding parameters: {'steps': 100, 'learning_rate': 1.0, 'hidden_units': [13, 13], 'batch_size': 400}\n",
    "Score: 0.284954\n",
    "\n",
    "corresponding parameters: {'steps': 100, 'learning_rate': 1.0, 'hidden_units': [13, 13], 'batch_size': 400}\n",
    "Score: 0.183576\n",
    "\n",
    "corresponding parameters: {'steps': 100, 'learning_rate': 1.0, 'hidden_units': [13, 13], 'batch_size': 400}\n",
    "Score: 0.019807"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'score_svr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-4fab4d748bb8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"SVR: %f\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mscore_svr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"SVR tuned: %f\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mscore_svr_tuned\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"DNN: %f\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mscore_regressor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"DNN tuned random: %f\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mscore_regressor_tuned_RS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'score_svr' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"SVR: %f\" % score_svr)\n",
    "print(\"SVR tuned: %f\" % score_svr_tuned)\n",
    "\n",
    "print(\"DNN: %f\" % score_regressor)\n",
    "print(\"DNN tuned random: %f\" % score_regressor_tuned_RS)\n",
    "print(\"DNN tuned grid: %f\" % score_regressor_tuned_GS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split\n",
    "The count of rented bikes (cnt) is just the sum of the features casual and registered. I build and train two seperate models to predict these features. And add them up afterwards. This should improve the projection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature columns:\n",
      "Index([u'instant', u'dteday', u'season', u'yr', u'mnth', u'holiday',\n",
      "       u'weekday', u'workingday', u'weathersit', u'temp', u'atemp', u'hum',\n",
      "       u'windspeed'],\n",
      "      dtype='object')\n",
      "\n",
      "Target column:\n",
      "casual\n",
      "\n",
      "GridSearchCV(cv=None, error_score='raise',\n",
      "       estimator=SVR(C=1, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
      "  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False),\n",
      "       fit_params={}, iid=True, n_jobs=1,\n",
      "       param_grid=[{'kernel': ['linear', 'rbf'], 'C': [1000]}],\n",
      "       pre_dispatch='2*n_jobs', refit=True, scoring='r2', verbose=0)\n",
      "\n",
      "Best parameter from grid search: {'kernel': 'linear', 'C': 1000}\n"
     ]
    }
   ],
   "source": [
    "#SVR for casual with with RandomizesSearch - for casual\n",
    "\n",
    "# Extracting\n",
    "feature_cols_cas = bike_data.columns[:-3]  # all columns but last are features\n",
    "target_col_cas = bike_data.columns[-3]  # last column is the target\n",
    "print \"Feature columns:\\n{}\\n\".format(feature_cols_cas)\n",
    "print \"Target column:\\n{}\\n\".format(target_col_cas)\n",
    "\n",
    "# Pre-processing\n",
    "X_cas = bike_data[feature_cols_cas.drop(['dteday'],['instant'])]  # feature values \n",
    "y_cas = bike_data[target_col_cas]  # corresponding targets\n",
    "\n",
    "# Split\n",
    "X_train_cas, X_test_cas, y_train_cas, y_test_cas = train_test_split(X_cas, y_cas)# test size is set to 0.25\n",
    "\n",
    "# Tuning SVR\n",
    "param_grid = [\n",
    "             {'C': [100, 1000, 10000],\n",
    "              'kernel': ['linear', 'rbf']}\n",
    "             ]\n",
    "\n",
    "#svr_tuned_cas = GridSearchCV(SVR (C=1), param_grid = param_grid, scoring = 'mean_squared_error')\n",
    "svr_tuned_cas = GridSearchCV(SVR (C=1), param_grid = param_grid, scoring = 'r2')\n",
    "\n",
    "# Fitting\n",
    "svr_tuned_cas.fit(X_train_cas, y_train_cas)\n",
    "\n",
    "print (svr_tuned_cas)\n",
    "print ('\\n' \"Best parameter from grid search: {}\".format(svr_tuned_cas.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature column(s):\n",
      "Index([u'instant', u'dteday', u'season', u'yr', u'mnth', u'holiday',\n",
      "       u'weekday', u'workingday', u'weathersit', u'temp', u'atemp', u'hum',\n",
      "       u'windspeed'],\n",
      "      dtype='object')\n",
      "\n",
      "Target column:\n",
      "registered\n",
      "\n",
      "GridSearchCV(cv=None, error_score='raise',\n",
      "       estimator=SVR(C=1, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
      "  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False),\n",
      "       fit_params={}, iid=True, n_jobs=1,\n",
      "       param_grid=[{'kernel': ['linear'], 'C': [100, 1000, 10000]}],\n",
      "       pre_dispatch='2*n_jobs', refit=True, scoring='r2', verbose=0)\n",
      "\n",
      "Best parameter from grid search:{'kernel': 'linear', 'C': 1000}\n"
     ]
    }
   ],
   "source": [
    "#SVR for casual with with RandomizesSearch - for registered\n",
    "\n",
    "# Extracting\n",
    "feature_cols_reg = bike_data.columns[:-3]  # all columns but last are features\n",
    "target_col_reg = bike_data.columns[-2]  # last column is the target\n",
    "print \"Feature column(s):\\n{}\\n\".format(feature_cols_reg)\n",
    "print \"Target column:\\n{}\\n\".format(target_col_reg)\n",
    "\n",
    "# Pre-processing\n",
    "X_reg = bike_data[feature_cols_reg.drop(['dteday'],['casual'])]  # feature values \n",
    "y_reg = bike_data[target_col_reg]  # corresponding targets\n",
    "\n",
    "# Split\n",
    "X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(X_reg, y_reg)# test size is set to 0.25\n",
    "\n",
    "# Tuning SVR\n",
    "param_grid = [\n",
    "             {'C': [100, 1000, 10000],\n",
    "              'kernel': ['linear', 'rbf']}\n",
    "             ]\n",
    "\n",
    "#svr_tuned_reg = GridSearchCV(SVR (C=1), param_grid = param_grid, scoring = 'mean_squared_error')\n",
    "svr_tuned_reg = GridSearchCV(SVR (C=1), param_grid = param_grid, scoring = 'r2')\n",
    "\n",
    "\n",
    "# Fitting \n",
    "svr_tuned_reg.fit(X_train_reg, y_train_reg)\n",
    "\n",
    "print (svr_tuned_reg)\n",
    "print ('\\n' \"Best parameter from grid search:{}\".format(svr_tuned_reg.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score cas: 0.713931\n",
      "Score reg: 0.832698\n",
      "Score sum: 999406.492174\n"
     ]
    }
   ],
   "source": [
    "# Prediction\n",
    "\n",
    "#print ('Score cas: {0:f}'.format(mean_squared_error(y_test_cas,svr_tuned_cas.predict(X_test_cas))))\n",
    "#print ('Score reg: {0:f}'.format(mean_squared_error(y_test_reg,svr_tuned_reg.predict(X_test_reg))))\n",
    "print ('Score cas: {0:f}'.format(r2_score(y_test_cas,svr_tuned_cas.predict(X_test_cas))))\n",
    "print ('Score reg: {0:f}'.format(r2_score(y_test_reg,svr_tuned_reg.predict(X_test_reg))))\n",
    "\n",
    "predict_sum = svr_tuned_cas.predict(X_test) + svr_tuned_reg.predict(X_test)\n",
    "\n",
    "#score = mean_squared_error(y_test, predict_sum)\n",
    "score = r2_score(y_test, predict_sum)\n",
    "\n",
    "print('Score sum: {0:f}'.format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
